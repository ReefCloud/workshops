[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "ReefCloud R/Statistics resources",
    "section": "",
    "text": "This tutorial series should be considered reference and background materials in support of preparation for more advanced statistical analyses with R. The topics covered progress from introductory and foundational through to more advanced and as such, the tutorials are intended to be consumed and worked through largely in the order laid out in the sidebar menu to the left."
  },
  {
    "objectID": "index.html#r-code",
    "href": "index.html#r-code",
    "title": "ReefCloud R/Statistics resources",
    "section": "2.1 R code",
    "text": "2.1 R code\nThroughout the tutorials, R code snippets will be presented in a block such as:\n\n## construct variables\nx &lt;- rep(1:5, times = 2)\ng &lt;- gl(n = 2, k = 5, labels = c('High', 'Low'))\ny &lt;- 2 + (3 * x) + (as.numeric(g) - 1) + rnorm(10, mean = 0, sd = 1)\n## compile into a data frame\ndat &lt;- data.frame(x, g, y)\n## print out data frame\ndat\n\n   x    g         y\n1  1 High  5.778012\n2  2 High  9.014321\n3  3 High  9.522493\n4  4 High 14.232110\n5  5 High 17.991336\n6  1  Low  6.735474\n7  2  Low  8.539348\n8  3  Low 13.999808\n9  4  Low 15.775489\n10 5  Low 17.462322\n\n\nThis format is partially reminiscent of the layout of code editors, albeit with a very opinionated color scheme.\n\nthe R code appears as the text over the faint yellow background.\nany output appears below the code (white background) and in red font\nthe light gray numbers in the left hand gutter represent the line numbers. These can be useful when trying to draw attention to a particular line of code\nthe light gray text in the R code block beginning with two hash symbols ‘##’ are comments\nin the upper right hand corner there is a clipboard symbol. Clicking on this symbol will copy the code to the clipboard to help you transfer the code to your own R session.\n\nOccasionally (and particularly within tables) code snippets may alternatively be presented without the line number gutter. In such cases, there tends to only be a single line of code and there are substantial space savings if the gutter is removed.\n\nx &lt;- rep(1:5, times = 2)"
  },
  {
    "objectID": "index.html#bash-code",
    "href": "index.html#bash-code",
    "title": "ReefCloud R/Statistics resources",
    "section": "2.2 Bash code",
    "text": "2.2 Bash code"
  },
  {
    "objectID": "index.html#plain-text",
    "href": "index.html#plain-text",
    "title": "ReefCloud R/Statistics resources",
    "section": "2.3 Plain text",
    "text": "2.3 Plain text\nThe contents of plain text files will similarly be presented either as:\n\nLorem ipsum dolor sit amet, consectetur adipiscing elit. \nMaecenas sed metus congue risus sagittis viverra. Etiam \nhendrerit orci arcu, et vehicula libero vulputate nec. \nAliquam placerat lacinia ex sit amet varius. Suspendisse \npotenti. Nam tristique fringilla lacus id tincidunt. Donec \nquis turpis tempus leo pharetra malesuada. Vivamus consequat \na quam nec vestibulum.\n\nor when necessary to save space:\n\nLorem ipsum dolor sit amet, consectetur adipiscing elit."
  },
  {
    "objectID": "01_introduction_to_r.html",
    "href": "01_introduction_to_r.html",
    "title": "Introduction to R",
    "section": "",
    "text": "The latest version of an R installation binary (or source code) can be downloaded from one of the Comprehensive R Archive Network (or CRAN) mirrors. Having selected one of the (Australian) mirrors, follow one of the sets of instructions below (depending on your operating system).\n\nWindowsMacOSxLinux\n\n\n\nDownload R:\n\nGo to the CRAN R-project website https://cran.r-project.org/ and click on “Download R for Windows”.\nSelect the “base” subdirectory\nSelect the “Download R-X.X.X for Windows” option (where X.X.X are a series of version and release numbers) to download.\n\nRun the installer: Double-click the downloaded .exe file and follow the installation wizard. Accept the default settings unless you have specific needs.\nOptional: Set R as the default: Check the checkbox to set R as the default for R scripts during installation. This allows you to run R scripts by double-clicking them.\nVerify installation:\n\nOpen a new command prompt (Start &gt; Run &gt; cmd) and type R. If the R console opens, the installation was successful.\nAlternatively, search for R in the Start menu\n\n\n\n\n\nDownload R:\n\nGo to the CRAN R-project website (https://cran.r-project.org/) and click on “Download R for macOS”.\nChoose the latest stable version that is appropriate for your architecture.\n\nOpen the disk image: Double-click the downloaded .pkg file and drag the R application icon to your Applications folder.\nVerify installation:\n\nOpen Terminal: Go to Applications &gt; Utilities and open Terminal.\nType R in the Terminal window. If the R console opens, the installation was successful.\n\n\n\n\n\nOpen Terminal: You can access Terminal through your application launcher or search bar.\nInstall R: The commands vary slightly depending on your Linux distribution. Here are common examples:\n\nDebian/Ubuntu: sudo apt install r-base\nFedora/CentOS: sudo yum install R\nArch Linux: sudo pacman -S R\n\n**Verify installation:* Type R in the Terminal window. If the R console opens, the installation was successful."
  },
  {
    "objectID": "01_introduction_to_r.html#the-r-environment-and-command-line",
    "href": "01_introduction_to_r.html#the-r-environment-and-command-line",
    "title": "Introduction to R",
    "section": "2.1 The R environment and command line",
    "text": "2.1 The R environment and command line\nUpon opening R, you are presented with the R Console along with the command prompt (&gt;). R is a command driven application (as opposed to a ‘point-and-click’ application) and despite the steep learning curve, there are many very good reasons for this.\nCommands that you type are evaluated once the Enter key has been pressed\nEnter the following command (5+1) at the command prompt (&gt;);\n\n5+1\n\n[1] 6\n\n\n\n\n\n\n\n\nNote\n\n\n\nI have suppressed the command prompt (&lt;) from almost all code blocks throughout these workshop and tutorial series to make it easier for you to cut and paste code into your own scripts or directly into R.\n\n\n\n\n\n\n\n\nTip\n\n\n\nIn this tutorial series, the R code to be entered appears to the right hand side of the vertical bar. The number of the left side of the bar is a line number. For single line code snippets, such as the example above, line numbers are not necessary. However, for multi-line code snippets, line numbers help for identifying and describing different parts of the code.\n\n\nThe above R code evaluates the command five plus one and returns the result (six).. The [1] before the 6 indicates that the object immediately to its right is the first element in the returned object. In this case there is only one object returned. However, when a large set of objects (e.g. numbers) are returned, each row will start with an index number thereby making it easier to count through the elements.\n\n\n\n\n\n\nImportant definitions\n\n\n\n\n\n\nObject\n\nAs an object oriented language, everything in R is an object. Data, functions even output are objects.\n\nVector\n\nA collection of one or more objects of the same type (e.g. all numbers or all characters).\n\nFunction\n\nA set of instructions carried out on one or more objects. Functions are typically wrappers for a sequence of instructions that perform specific and common tasks.\n\nParameter\n\nThe kind of information passed to a function.\n\nArgument\n\nThe specific information passed to a function.\n\nOperator\n\nA symbol that has a pre-defined meaning. Familiar operators include + - * and /.\n\nAssignment operators\n\n&lt;- Assigning a name to an object (left to right)\n\n\n-&gt; Assigning a name to an object (right to left)\n\n\n= Used when defining and specifying function arguments\n\nLogical operators (return TRUE or FALSE)\n\n&lt; Less than\n\n\n&gt; Greater than\n\n\n&lt;= Less than or equal\n\n\n&gt;= Greater than or equal\n\n\n== Is the left hand side equal to the right hand side (a query)\n\n\n!= Is the left hand side NOT equal to the right hand side (a query)\n\n\n&& Are BOTH left hand and right hand conditions TRUE\n\n\n|| Are EITHER the left hand OR right hand conditions TRUE\n\nPipe operator\n\n|&gt; piping the output of one operation to the input of the next\n\n\n\n\n\n\n2.1.1 Expressions, Assignment and Arithmetic\nInstead of evaluating a statement and printing the result directly to the console, the results of evaluations can be stored in an object via a process called ‘Assignment’. Assignment assigns a name to an object and stores the result of an evaluation in that object. The contents of an object can be viewed (printed) by typing the name of the object at the command prompt and hitting Enter.\n\nvar1 &lt;- 2 + 3\nvar1\n\n[1] 5\n\n\nOn line 1 above, the name var1 was assigned to the result of the sum of 2 and 3. On line 2, the contents of this object are printed to the screen.\nA single command (statement) can spread over multiple lines. If the Enter key is pressed before R considers the statement complete, the next line in the console will begin with the prompt + indicating that the statement is not complete. For this example, I will include the command prompt in order to demonstrate the above point.\n\n&gt; var2 &lt;-\n+   2 + 3\n&gt; var2\n\n[1] 5\n\n\nWhen the contents of an object are numbers, standard arithmetic applies;\n\nvar2 - 1\n\n[1] 4\n\nans1 &lt;- var1 * var2\nans1\n\n[1] 25\n\n\n\n\n\n\n\n\nTip\n\n\n\nGenerally, spaces are ignored in R. Hence, the above and the following are both equally valid.\n\nans1&lt;-var1*var2\nans1\n\n[1] 25\n\n\nNevertheless, the former version (with spaces) is much more readable.\n\n\nCompatible objects can be concatenated (joined together) to create objects with multiple entries. Object concatenation can be performed using the c() function.\n\nc(1, 2, 6)\n\n[1] 1 2 6\n\nc(var1, var2)\n\n[1] 5 5\n\n\n\n\n\n\n\n\nNote\n\n\n\nIn both examples above, objects were not assigned names. As a result, the expressions were evaluated and directly printed to the consol without being stored in any way. Doing so is useful for experimenting, however as the results are not stored, they cannot be used in subsequent actions.\n\n\nIn addition to the typical addition, subtraction, multiplication and division operators, there are a number of special operators, the simplest of which are the quotient or integer divide operator (%/%) and the remainder or modulus operator (%%).\n\n7 / 3\n\n[1] 2.333333\n\n7 %/% 3\n\n[1] 2\n\n7 %% 3\n\n[1] 1\n\n\n\n\n2.1.2 Operator precedence\nThe rules of operator precedence are listed (highest to lowest) in the following table. Additionally, expressions within parentheses ‘()’ always have highest precedence.\n\n\n\n\n\n\n\n\nOperator\nDescription\n\n\n\n\n[ [[\nindexing\n\n\n::\nnamespace\n\n\n$\ncomponent\n\n\n^\nexponentiation (evaluated right to left)\n\n\n-\n+ sign (unary)\n\n\n:\nsequence\n\n\n%special%\nspecial operators (e.g. %/%, %%, %*%, %in%)\n\n\n* /\nmultiplication and division\n\n\n+\n- addition and subtraction\n\n\n&gt; &lt; &gt;= &lt;= == !=\nordering and comparison\n\n\n!\nlogical negation (not)\n\n\n& &&\nlogical AND\n\n\n| ||\nlogical OR\n\n\n~\nformula\n\n\n-&gt; -&gt;&gt;\nassignment (left to right)\n\n\n=\nargument assignment (right to left)\n\n\n&lt;- &lt;&lt;-\nassignment (right to left)\n\n\n?\nhelp\n\n\n\n\n\n2.1.3 Command history\nEach time a command is entered at the R command prompt, the command is also added to a list known as the command history. The up and down arrow keys scroll backward and forward respectively through the session’s command history list and place the top most command at the current R command prompt. Scrolling through the command history enables previous commands to be rapidly re-executed, reviewed or modified and executed.\n\n\n2.1.4 Object names\nEverything created within R are objects. Objects are programming constructs that not only store values (the visible part of an object), they also define other properties of the object (such as the type of information contained in the object) and sometimes they also define certain routines that can be used to store, retrieve and manipulate data within the object.\nImportantly, all objects within R must have unique names to which they can be referred. Names given to any object in R can comprise virtually any sequence of letters and numbers providing that the following rules are adhered to:\n\nNames must begin with a letter (names beginning with numbers or operators are not permitted)\nNames cannot contain the following characters; space , - + * / # % & [ ] { } ( ) ~\n\nWhilst the above rules are necessary, the following naming conventions are also recommended:\n\nonly use lowercase letters and numbers\nuse underscores (_) to separate words (e.g. snake case)\ntry to use names that are both concise and meaningful.\n\nnames should reflect the content of the object. One of the powerful features of R is that there is virtually no limit to the number of objects (variables, datasets, results, models, etc) that can be in use at a time. However, without careful name management, objects can rapidly become misplaced or ambiguous. Therefore, the name of an object should reflect what it is, and what has happened to it. For example, the name log_fish_wts might be given to an object that contains log transformed fish weights. Moreover, many prefer to prefix the object name with a lowercase letter that denotes the type of data containing in the object. For example, d_mean_head_length might indicate that the object contains the mean head lengths stored as a double floating point (real numbers).\nalthough there are no restrictions on the length of names, shorter names are quicker to type and provide less scope for typographical errors and are therefore recommended (of course within the restrictions of the point above).\n\nwhere possible, avoid using names of common predefined functions and variables as this can provide a source of confusion for both you and R. For example, to represent the mean of a head length variable, use something like mean_head_length rather than mean (which is the name of a predefined function within R that calculates the mean of a set of numbers)."
  },
  {
    "objectID": "01_introduction_to_r.html#r-sessions-and-workspaces",
    "href": "01_introduction_to_r.html#r-sessions-and-workspaces",
    "title": "Introduction to R",
    "section": "2.2 R Sessions and Workspaces",
    "text": "2.2 R Sessions and Workspaces\nA number of objects have been created in the current session (a session encapsulates all the activity since the current instance of the R application was started). To review the names of all of the objects in the users current workspace (storage of user created objects);\n\nls()\n\n[1] \"ans1\"            \"has_annotations\" \"var1\"            \"var2\"           \n\n\nYou can also refine the scope of the ls() function to search for object names that match a pattern:\n\nls(pat = \"var\")\n\n[1] \"var1\" \"var2\"\n\nls(pat = \"a*1\")\n\n[1] \"ans1\" \"var1\"\n\n\nThe longer the session is running, the more objects will be created resulting in a very cluttered workspace. Unneeded objects can be removed using the rm() function. The rm() function only performs a side effect (deletes objects), if the function succeeds, it does not return any output. If it does return anything, it will be a warning or error.\n\nrm(var1, var2)   #remove the VAR1 and VAR2 objects\nrm(list = ls())  #remove all user defined objects\n\n\n\n\n\n\n\nNote\n\n\n\nIn the above examples, comments were appended to each line of code. Comments begin with a hash (#) character. Anything that follows a hash character will be ignored (until the end of the line).\nComments provide a convenient way to annotate your code so as to provide more explanation and clarity as to the intention and purpose of the associated code.\n\n\n\n2.2.1 Current working directory\nThe R working directory (location from which files/data are read and written) is by default, either the location of the R executable (or execution path in Linux) or the users home directory. The current working directory can be reviewed and changed (for the session) using the getwd() function and setwd() functions respectively. Note that R uses the Unix/Linux style directory subdivision markers. That is, R uses the forward slash / in path names rather than the regular \\ of Windows.\nWhen using setwd(), you can provide either an absolute path (the full path) or a relative path (relative to the current location). Obviously, you will get a different result to me when you issue the following:\n\ngetwd()                    #review the current working directory\n\n[1] \"/home/runner/work/workshops/workshops/tut\"\n\nsetwd(\"../\")               #change to the parent directory of the current working directory\nlist.files(path = getwd()) #list all files (and directories) in the current working directory\n\n[1] \"architects_daughter.zip\" \"data\"                   \n[3] \"doc\"                     \"docs\"                   \n[5] \"inconsolata.zip\"         \"Makefile\"               \n[7] \"tut\"                    \n\n\n\n\n2.2.2 Workspaces\nThroughout an R session, all objects (including loaded packages, see Section 6) that have been added are stored within the R global environment, called the workspace. Occasionally, it is desirable to save the workspace and thus all those objects (vectors, functions, etc) that were in use during a session so that they are available during subsequent sessions. This can be done using the save.image() function. Note, this will save the workspace to a file called .RData in the current working directory (usually the R startup directory), unless a file (filename and path) is supplied as an argument to the save.image() function. A previously saved workspace can be loaded by providing a full path and filename as an argument to the load() function.\nWhilst saving a workspace image can sometimes be convenient, it can also contribute greatly to organisational problems associated with large numbers of obsolete or undocumented objects. Instead, it is usually better to specifically store each of the objects you know you are going to want to have access to across sessions separately.\n\n\n2.2.3 Quitting elegantly\nTo quit R, issue the following command; Note in Windows and MacOSX, the application can also be terminated using the standard Exiting protocols.\n\nq()\n\nYou will then be asked whether or not you wish to save the current workspace. If you do, enter ‘Y’ otherwise enter ‘N’. Unless you have a very good reason to save the workspace, I would suggest that you do not. A workspace generated in a typical session will have numerous poorly named objects (objects created to temporarily store information whilst testing). Next time R starts, it could (likely will) restore this workspace thereby starting with a cluttered workspace, and becoming a potential source of confusion if you inadvertently refer to an object stored during a previous session. Moreover, if the workspace includes additional extension packages, these packages may also be loaded which will prevent them from being updated (often necessary when installing additional packages that depend on other packages)."
  },
  {
    "objectID": "01_introduction_to_r.html#functions",
    "href": "01_introduction_to_r.html#functions",
    "title": "Introduction to R",
    "section": "2.3 Functions",
    "text": "2.3 Functions\nAs wrappers for collections of commands used together to perform a task, functions provide a convenient way of interacting with all of these commands in sequence. Most functions require one or more inputs (parameters), and while a particular function can have multiple parameters, not all are necessarily required (some could have default values). Parameters are parsed to a function as arguments comprising the name of the parameter, an equals operator and the value of the parameter. Hence, arguments are specified as name/value pairs.\nConsider the seq() function, which generates a sequence of values (a vector) according to the values of the arguments. We can see that the default version of this function has the following definition:\n\nstr(seq.default)\n\nfunction (from = 1, to = 1, by = ((to - from)/(length.out - 1)), length.out = NULL, \n    along.with = NULL, ...)  \n\n\n\nif the seq() function is called without any arguments (e.g. seq()), it will return a single number 1. Using the default arguments for the function, it returns a vector starting at 1 (from   = 1), going up to 1 (to = 1) and thus having a length of 1.\nwe can alter this behavior by specifically providing values for the named arguments. The following generates a sequence of numbers from 2 to 10 incrementing by 1 (default):\n\nseq(from = 2, to = 10)\n\n[1]  2  3  4  5  6  7  8  9 10\n\n\nthe following generates a sequence of numbers from 2 to 10 incrementing by 2:\n\nseq(from = 2, to = 10, by = 2)\n\n[1]  2  4  6  8 10\n\n\nalternatively, instead of manipulating the increment space of the sequence, we could specify the desired length of the sequence:\n\nseq(from = 2, to = 10, length.out = 3)\n\n[1]  2  6 10\n\n\nnamed arguments need not include the full name of the parameter, so long as it is unambiguous which parameter is being referred to. For example, length.out could be shortened to just l since there are no other parameters of this function that start with ‘l’:\n\nseq(from = 2, to = 10, l = 4)\n\n[1]  2.000000  4.666667  7.333333 10.000000\n\n\nparameters can also be specified as unnamed arguments provided they are in the order specified in the function definition. For example to generate a sequence of numbers from 2 to 10 incrementing by 2:\n\nseq(2, 10, 2)\n\n[1]  2  4  6  8 10\n\n\nNote, although permittable, it is more difficult to unambiguously read/interpret the code and could easily be a source of bugs.\nnamed and unnamed arguments can be mixed, just remember the above rules about parameter order and unambiguous names:\n\nseq(2, 10, l = 4)\n\n[1]  2.000000  4.666667  7.333333 10.000000"
  },
  {
    "objectID": "01_introduction_to_r.html#function-overloading-polymorphism",
    "href": "01_introduction_to_r.html#function-overloading-polymorphism",
    "title": "Introduction to R",
    "section": "2.4 Function overloading (polymorphism)",
    "text": "2.4 Function overloading (polymorphism)\nMany routines can be applied to different sorts of data. That is, they are somewhat generic. For example, we could calculate the mean (arithmetic center) of a set of numbers or we could calculate the mean of a set of dates or times. Whilst the calculations in both cases are analogous to one another, they nevertheless differ sufficiently so as to warrant separate functions.\nWe could name the functions that calculate the mean of a set of numbers and the mean of a set of dates as mean_numbers and mean_dates respectively. Unfortunately, as this is a relatively common situation, the number of functions to learn rapidly expands. And from the perspective of writing a function that itself contains such a generic function, we would have to write multiple instances of the function in order to handle all the types of data we might want to accommodate.\nTo simplify the process of applying these generic functions, R provides yet another layer that is responsible for determining which of a series of overloaded functions is likely to be applicable according to the nature of the parameters and data parsed as arguments to the function. To see this in action, type mean followed by hitting the TAB key. The TAB key is used for auto-completion and therefore this procedure lists all the objects that begin with the letters ‘mean’.\n\nmean           mean.Date      mean.default   mean.difftime  mean.POSIXct   mean.POSIXlt\n\nIn addition to an object called mean, there are additional objects that are suffixed as a ‘.’ followed by a data type. In this case, the objects mean.default, mean.Date, mean.POSIXct, mean.POSIXlt and mean.difftime are functions that respectively calculate the mean of a set of numbers, dates, times, times, time and differences. The mean function determines which of the other functions is appropriate for the data parsed and then redirects to that appropriate function. Typically, this means that it is only necessary to remember the one generic function (in this case, mean()) as the specific functions are abstracted away.\n\n# mean of a series of numbers\nmean(c(1, 2, 3, 4))\n\n[1] 2.5\n\n# create a sequence of dates spaced 7 days apart between 29th Feb 2000 and 30th Apr 2000\nsample_dates &lt;- seq(from = as.Date(\"2000-02-29\"), to = as.Date(\"2000-04-30\"), by = \"7 days\")\n# print (view) these dates\nsample_dates\n\n[1] \"2000-02-29\" \"2000-03-07\" \"2000-03-14\" \"2000-03-21\" \"2000-03-28\"\n[6] \"2000-04-04\" \"2000-04-11\" \"2000-04-18\" \"2000-04-25\"\n\n# calculate the mean of these dates\nmean(sample_dates)\n\n[1] \"2000-03-28\"\n\n\nIn the above examples, we called the same function (mean) on both occasions. In the first instance, it was equivalent to calling the mean.default() function and in the second instance the mean.Date() function. Note that the seq() function is similarly overloaded.\nThe above example also illustrates another important behaviour of function arguments. Function calls can be nested within the arguments of other functions and function arguments are evaluated before the function runs. In this way, multiple steps to be truncated together (although for the sake of the codes’ readability and debugging, it is often better to break a problem up into smaller steps).\nIf a function argument itself contains a function (as was the case above with the from = and to = arguments, both of which called the as.Date() function which converts a character string into a date object), the value of the evaluated argument is parsed to the outside function. That is, evaluations are made from the inside to out. The above example, could have been further truncated to;\n\n# calculate the mean of a sequence of dates spaced 7 days apart between 29th Feb 2000 and 30th Apr 2000\nmean(seq(from = as.Date(\"2000-02-29\"), to = as.Date(\"2000-04-30\"), by = \"7 days\"))\n\n[1] \"2000-03-28\"\n\n\n\n2.4.1 The pipe character\nAs we can see from the example above, nested functions can be pretty awkward to read. As of version 4.1, R has had a pipe operator. The concept of piping dates back to the early UNIX days when separate programs were chained (‘piped’) together such that the output of one program became the input of the next and so on. This enabled each program to remain relatively simple, yet by piping sequences of programs together, rather complex results could be achieved.\nSimilarly the R pipe operator (|&gt;) enables nested functions to alternatively be expressed as a chain of functions:\n\n# calculate the mean of a sequence of dates spaced 7 days apart between 29th Feb 2000 and 30th Apr 2000\nseq(from = as.Date(\"2000-02-29\"), to = as.Date(\"2000-04-30\"), by = \"7 days\") |&gt; mean()\n\n[1] \"2000-03-28\"\n\n\nTo maximise code readability, it is good form to keep lines of code short (less than 80 characters). One way to do this is to place a line break after pipe characters. Moreover, a line break after each function argument allows us to have more topical and granular comments.\n\nseq(                              #take sequence of dates\n  from = as.Date(\"2000-02-29\"),   #from the 29th Feb 2000\n  to = as.Date(\"2000-04-30\"),     #to the 30th April 2000\n  by = \"7 days\") |&gt;               #incrementing by 7 days\n  mean()                          #and calculate the mean\n\n[1] \"2000-03-28\""
  },
  {
    "objectID": "01_introduction_to_r.html#external-functions",
    "href": "01_introduction_to_r.html#external-functions",
    "title": "Introduction to R",
    "section": "2.5 External functions",
    "text": "2.5 External functions\nAs R is a scripting language (rather than a compiled language), it has the potential to be very slow (since syntax checking, machine instruction interpretation, etc must all take place at runtime rather than at compile time). Consequently, many of the functions are actually containers (wrappers) for external code (link libraries) precompiled in either C or Fortran. In this way, the environment can benefit from the flexibility of a scripting language whilst still maintaining most of the speed of a compiled language. Tutorial ? will introduce how to install and load external libraries."
  },
  {
    "objectID": "01_introduction_to_r.html#vectors",
    "href": "01_introduction_to_r.html#vectors",
    "title": "Introduction to R",
    "section": "4.1 Vectors",
    "text": "4.1 Vectors\nVectors are a collection of one or more entries (values) of the same type (class) and are the basic storage unit in R. Vectors are one-dimensional arrays (have a single dimension - length) and can be thought of as a single column of data. Each entry in a vector has a unique index (like a row number) to enable reference to particular entries in the vector.\n\n4.1.1 Consecutive integers\nTo get a vector of consecutive integers, we can specify an expression of the form &lt;first integer&gt;:&lt;second integer&gt; where &lt;first integer&gt; and &lt;second integer&gt; represent the start and end of the sequence of integers respectively:\n\n5:10\n\n[1]  5  6  7  8  9 10\n\n5:-5\n\n [1]  5  4  3  2  1  0 -1 -2 -3 -4 -5\n\n\n\n\n4.1.2 The c() function\nThe c() function concatenates values together into a vector. To create a vector with the numbers 1, 4, 7, 21:\n\nc(1, 4, 7, 21)\n\n[1]  1  4  7 21\n\n\nAs an example, we could store the temperature recorded at 10 sites:\n\ntemperature &lt;- c(36.1, 30.6, 31, 36.3, 39.9, 6.5, 11.2, 12.8, 9.7, 15.9)\ntemperature\n\n [1] 36.1 30.6 31.0 36.3 39.9  6.5 11.2 12.8  9.7 15.9\n\n\nTo create a vector with the words ‘Fish’, ‘Rock’, ‘Tree’, ‘Git’:\n\nc('Fish', 'Rock', 'Tree', \"Git\")\n\n[1] \"Fish\" \"Rock\" \"Tree\" \"Git\" \n\n\n\n\n4.1.3 Regular or patterned sequences (rep())\nWe have already seen the use of the seq() function to create sequences of entries.\nSequences of repeated entries are supported with the rep() function:\n\nrep(4,5)\n\n[1] 4 4 4 4 4\n\nrep('Fish',5)\n\n[1] \"Fish\" \"Fish\" \"Fish\" \"Fish\" \"Fish\"\n\n\n\n\n4.1.4 The paste() function\nTo create a sequence of quadrat labels we could use the c() function as illustrated above, e.g.\n\nquadrats &lt;- c(\"Q1\",\"Q2\",\"Q3\",\"Q4\",\"Q5\",\"Q6\",\"Q7\",\"Q8\",\"Q9\",\"Q10\")\nquadrats\n\n [1] \"Q1\"  \"Q2\"  \"Q3\"  \"Q4\"  \"Q5\"  \"Q6\"  \"Q7\"  \"Q8\"  \"Q9\"  \"Q10\"\n\n\nA more elegant way of doing this is to use the paste() function:\n\nquadrats &lt;- paste(\"Q\", 1:10, sep = \"\")\nquadrats\n\n [1] \"Q1\"  \"Q2\"  \"Q3\"  \"Q4\"  \"Q5\"  \"Q6\"  \"Q7\"  \"Q8\"  \"Q9\"  \"Q10\"\n\n\nThis can be useful for naming vector elements. For example, we could use the names() function to name the elements of the temperature variable according to the quadrat labels.\n\nnames(temperature) &lt;- quadrats\ntemperature\n\n  Q1   Q2   Q3   Q4   Q5   Q6   Q7   Q8   Q9  Q10 \n36.1 30.6 31.0 36.3 39.9  6.5 11.2 12.8  9.7 15.9 \n\n\nThe paste() function can also be used in conjunction with other functions to generate lists of labels. For example, we could combine a vector in which the letters A, B, C, D and E (generated with the LETTERS constant) are each repeated twice consecutively (using the rep() function) with a vector that contains a 1 and a 2 to produce a character vector that labels sites in which the quadrats may have occurred.\n\nsite &lt;- paste(rep(LETTERS[1:5], each = 2), 1:2, sep = \"\")\nsite\n\n [1] \"A1\" \"A2\" \"B1\" \"B2\" \"C1\" \"C2\" \"D1\" \"D2\" \"E1\" \"E2\"\n\n\nOr, with the use of pipes:\n\nsite &lt;- rep(LETTERS[1:5], each = 2) |&gt;\n  paste(1:2, sep = \"\")\nsite\n\n [1] \"A1\" \"A2\" \"B1\" \"B2\" \"C1\" \"C2\" \"D1\" \"D2\" \"E1\" \"E2\"\n\n\nRather than specify that the components are not separated by any character (which is what we are doing above by indicating that the separator character should be ““), there is a version of paste() that does this automatically. It is paste0().\n\nsite &lt;- rep(LETTERS[1:5], each = 2) |&gt;\n  paste0(1:2)\nsite\n\n [1] \"A1\" \"A2\" \"B1\" \"B2\" \"C1\" \"C2\" \"D1\" \"D2\" \"E1\" \"E2\"\n\n\n\n\n\n\n\n\nMajor vector classes\n\n\n\n\n\n\n\n\n\n\nVector class\n\n\nExamples\n\n\n\n\n\n\ninteger(whole numbers)\n\n\n\n2:4\n\n[1] 2 3 4\n\nc(1, 3, 9)\n\n[1] 1 3 9\n\n\n\n\n\n\nnumeric(real numbers)\n\n\n\nc(8.4, 2.1)\n\n[1] 8.4 2.1\n\n\n\n\n\n\ncharacter(letters)\n\n\n\nc('A', 'ABC', 'def')\n\n[1] \"A\"   \"ABC\" \"def\"\n\n\n\n\n\n\nlogical(TRUE or FALSE)\n\n\n\n2:4 == 3\n\n[1] FALSE  TRUE FALSE\n\n\n\n\n\n\ndate(dates)\n\n\n\nc(as.Date(\"2000-02-29\"), as.Date(\"29/02/2000\",\"%d/%m/%Y\"))\n\n[1] \"2000-02-29\" \"2000-02-29\"\n\n\n\n\n\n\nPOSIXlt(date/time)\n\n\n\nstrptime('2011-03-27 01:30:00', format='%Y-%m-%d %H:%M:%S')\n\n[1] \"2011-03-27 01:30:00 UTC\"\n\n\n\n\n\n\n\n\n\n\n\n\n4.1.5 Factors\nFactors are more than a vector of characters. Factors have additional properties that are utilized during statistical analyses and graphical procedures. To illustrate the difference, we will create a vector to represent a categorical variable indicating the level of shading applied to 10 quadrats. Firstly, we will create a character vector:\n\nshade &lt;- rep(c(\"no\", \"full\"), each = 5)\nshade\n\n [1] \"no\"   \"no\"   \"no\"   \"no\"   \"no\"   \"full\" \"full\" \"full\" \"full\" \"full\"\n\n\nNow we convert this into a factor:\n\nshade &lt;- factor(shade)\nshade\n\n [1] no   no   no   no   no   full full full full full\nLevels: full no\n\n\nNotice the additional property (Levels) at the end of the output. Notice also that unless specified otherwise, the levels are ordered alphabetically. Whilst this does not impact on how the data appear in a vector, it does effect some statistical analyses, their interpretations as well as some tabular and graphical displays. If the alphabetical ordering does not reflect the natural order of the data, it is best to reorder the levels whilst defining the factor:\n\nshade &lt;- factor(shade, levels = c(\"no\", \"full\"))\nshade\n\n [1] no   no   no   no   no   full full full full full\nLevels: no full\n\n\nA more convenient way to create a balanced (equal number of replicates) factor is to use the gl() function. To create the shading factor from above:\n\nshade &lt;- gl(n = 2, k = 5, length = 10, labels = c(\"no\", \"full\"))\nshade\n\n [1] no   no   no   no   no   full full full full full\nLevels: no full\n\n\n\n\n4.1.6 Matrices\nMatrices have two dimensions (length and width). The entries (which must be all of the same length and type - class) are in rows and columns.\nWe could arrange the vector of shading into two columns:\n\nmatrix(temperature, nrow = 5)\n\n     [,1] [,2]\n[1,] 36.1  6.5\n[2,] 30.6 11.2\n[3,] 31.0 12.8\n[4,] 36.3  9.7\n[5,] 39.9 15.9\n\n\nSimilarly, We could arrange the vector of shading into two columns:\n\nmatrix(shade, nrow = 5)\n\n     [,1] [,2]  \n[1,] \"no\" \"full\"\n[2,] \"no\" \"full\"\n[3,] \"no\" \"full\"\n[4,] \"no\" \"full\"\n[5,] \"no\" \"full\"\n\n\nAs another example, we could store the X,Y coordinates for five quadrats within a grid. We start by generating separate vectors to represent the X and Y coordinates and then we bind them together using the cbind() function (which combines objects by columns):\n\nx &lt;- c(16.92, 24.03, 7.61, 15.49, 11.77)\ny&lt;- c(8.37, 12.93, 16.65, 12.2, 13.12)\nxy &lt;- cbind(x, y)\nxy\n\n         x     y\n[1,] 16.92  8.37\n[2,] 24.03 12.93\n[3,]  7.61 16.65\n[4,] 15.49 12.20\n[5,] 11.77 13.12\n\n\nWe could alternatively combine by rows using the rbind() function\n\nrbind(x, y)\n\n   [,1]  [,2]  [,3]  [,4]  [,5]\nx 16.92 24.03  7.61 15.49 11.77\ny  8.37 12.93 16.65 12.20 13.12\n\n\nWe could even alter the row names using an inbuilt vector of uppercase letters:\n\nrownames(xy) &lt;- LETTERS[1:5]\nxy\n\n      x     y\nA 16.92  8.37\nB 24.03 12.93\nC  7.61 16.65\nD 15.49 12.20\nE 11.77 13.12\n\n\nImportantly, all entries in a matrix must be of the same type. That is, they must all be numeric, or all be characters etc. If we attempt to mix a combination of data types in a matrix, then the data will all be converted into a type that can accommodate all the data. For example, if we attempt to bind together the numeric temperature data and the character site data into a matrix, then the result will be a matrix of characters (since while it is possible to covert numbers to strings, in this case the reverse is not possible).\n\ncbind(temperature, site)\n\n    temperature site\nQ1  \"36.1\"      \"A1\"\nQ2  \"30.6\"      \"A2\"\nQ3  \"31\"        \"B1\"\nQ4  \"36.3\"      \"B2\"\nQ5  \"39.9\"      \"C1\"\nQ6  \"6.5\"       \"C2\"\nQ7  \"11.2\"      \"D1\"\nQ8  \"12.8\"      \"D2\"\nQ9  \"9.7\"       \"E1\"\nQ10 \"15.9\"      \"E2\"\n\n\nOn the other hand, if we attempt to bind together the numeric temperature data and the factor shade data into a matrix, then the result will be a matrix of numbers (recall that factors are internally stored as integers, yet they have a levels property that acts rather like a lookup key).\n\ncbind(temperature, shade)\n\n    temperature shade\nQ1         36.1     1\nQ2         30.6     1\nQ3         31.0     1\nQ4         36.3     1\nQ5         39.9     1\nQ6          6.5     2\nQ7         11.2     2\nQ8         12.8     2\nQ9          9.7     2\nQ10        15.9     2\n\n\n\n\n4.1.7 Lists\nLists provide a way to group together multiple objects of different type and length. For example, whilst the contents of any single vector or matrix must all be of the one type and length (e.g. all numeric or all character), a list can contain any combination of vectors, matrices, scalars and of any type. Furthermore, the objects contained in a list do not need to be of the same lengths (c.f data frames). The output of most analyses are returned as lists.\nAs an example, we could group together the previously created isolated vectors and matrices into a single object that encapsulates the entire experiment:\n\nexperiment &lt;- list(\n  site = site,\n  quadrats = quadrats,\n  coordinates = xy,\n  shade = shade,\n  temperature = temperature\n)\nexperiment\n\n$site\n [1] \"A1\" \"A2\" \"B1\" \"B2\" \"C1\" \"C2\" \"D1\" \"D2\" \"E1\" \"E2\"\n\n$quadrats\n [1] \"Q1\"  \"Q2\"  \"Q3\"  \"Q4\"  \"Q5\"  \"Q6\"  \"Q7\"  \"Q8\"  \"Q9\"  \"Q10\"\n\n$coordinates\n      x     y\nA 16.92  8.37\nB 24.03 12.93\nC  7.61 16.65\nD 15.49 12.20\nE 11.77 13.12\n\n$shade\n [1] no   no   no   no   no   full full full full full\nLevels: no full\n\n$temperature\n  Q1   Q2   Q3   Q4   Q5   Q6   Q7   Q8   Q9  Q10 \n36.1 30.6 31.0 36.3 39.9  6.5 11.2 12.8  9.7 15.9 \n\n\nLists can be thought of as a set of objects bound into a single container. In the example above, the list object experiment contains a copy of the site, quadrats, coordinates, shade and temperature objects.\nImportantly, once a list has been created the objects within the list are not linked in any way to the original objects from which the list is formed. Consequently, any changes made to (for example) the temperature object will not be reflected in the content of the temperature object within the experiment list.\nTo access an object within a list, the $ operator is used as such:\n\nexperiment$temperature\n\n  Q1   Q2   Q3   Q4   Q5   Q6   Q7   Q8   Q9  Q10 \n36.1 30.6 31.0 36.3 39.9  6.5 11.2 12.8  9.7 15.9 \n\n\n\n\n4.1.8 Dataframes - data sets\nRarely are single biological variables collected in isolation. Rather, data are usually collected in sets of variables reflecting investigations of patterns between and/or among the different variables. Consequently, data sets are best organized into matrices of variables (vectors) all of the same lengths yet not necessarily of the same type. Hence, neither lists nor matrices represent natural storages for data sets. This is the role of data frames which are used to store a set of vectors of the same length (yet potentially different types) in a rectangular matrix.\nData frames are generated by combining multiple vectors together such that each vector becomes a separate column in the data frame. For a data frame to faithfully represent a data set, the sequence in which observations appear in the vectors must be the same for each vector, and each vector should have the same number of observations. For example, the first, second, third…etc entries in each vector must represent respectively, the observations collected from the first, second, third…etc sampling units.\nSince the focus of these tutorials is on the exploration, analysis and summary of data sets, and data sets are accommodated in R by data frames, the generation, importation, exportation, manipulation and management of data frames receives extensive coverage in many other subsequent tutorials.\nAs an simple example of a data frame, we could again group together the previously created isolated vectors into a single object that encapsulates a data set:\n\ndata &lt;- data.frame(\n  site = site,\n  quadrats = quadrats,\n  shade = shade,\n  temperature = temperature\n)\ndata\n\n    site quadrats shade temperature\nQ1    A1       Q1    no        36.1\nQ2    A2       Q2    no        30.6\nQ3    B1       Q3    no        31.0\nQ4    B2       Q4    no        36.3\nQ5    C1       Q5    no        39.9\nQ6    C2       Q6  full         6.5\nQ7    D1       Q7  full        11.2\nQ8    D2       Q8  full        12.8\nQ9    E1       Q9  full         9.7\nQ10   E2      Q10  full        15.9"
  },
  {
    "objectID": "01_introduction_to_r.html#object-information",
    "href": "01_introduction_to_r.html#object-information",
    "title": "Introduction to R",
    "section": "5.1 Object information",
    "text": "5.1 Object information\nAs indicated earlier, everything in R is an object. All objects have a type or class that encapsulates the sort of information stored in the object as well as determining how other functions interact with the object. The class of an object can be reviewed with the class() function:\n\nclass(temperature)\n\n[1] \"numeric\"\n\nclass(data)\n\n[1] \"data.frame\"\n\nclass(mean)\n\n[1] \"function\"\n\n\nThere is also a family of functions prefixed with is. that evaluate whether or not an object is of a particular class (or type) or not. The following table lists the common object query functions. All object query functions return a logical vector. Enter methods(is) for a more comprehensive list.\n\n\n\n\n\nFunction class\n\n\nReturns TRUE\n\n\nExamples\n\n\n\n\n\n\nis.numeric(x)\n\n\nif all elements of x are numeric or integers\n\n\n\nis.numeric(c(1, -3.5, temperature))\n\n[1] TRUE\n\n\n\n\n\n\nis.null(x)\n\n\nif x is null (the object has no length)\n\n\n\nis.null(NULL)\n\n[1] TRUE\n\n\n\n\n\n\nis.logical(x)\n\n\nif all elements of x are logical\n\n\n\nis.logical(c(TRUE, FALSE, 1))\n\n[1] FALSE\n\n\n\n\n\n\nis.character(x)\n\n\nif all elements of x are character strings\n\n\n\nis.character(c(\"A\", \"Plant\", quadrats))\n\n[1] TRUE\n\n\n\n\n\n\n\nis.vector(x)\n\n\nif the object x is a vector (has only a single dimension). Returns FALSE if object has attributes other than ‘names’.\n\n\nis.vector(temperature)\n\n[1] TRUE\n\n\n\n\n\n\nis.factor(x)\n\n\nif the object x is a factor\n\n\n\nis.factor(shade)\n\n[1] TRUE\n\n\n\n\n\n\nis.matrix(x)\n\n\nif the object x is a matrix (two dimensions, yet not adata.frame)\n\n\n\nis.matrix(xy)\n\n[1] TRUE\n\n\n\n\n\n\nis.list(x)\n\n\nif the object x is a list\n\n\n\nis.list(experiment)\n\n[1] TRUE\n\n\n\n\n\n\nis.data.frame(x)\n\n\nif the object x is a data.frame\n\n\n\nis.data.frame(data)\n\n[1] TRUE\n\n\n\n\n\n\nis.na(x)\n\n\nfor each missing (NA) element in x\n\n\n\nis.na(c(NA, 2))\n\n[1]  TRUE FALSE\n\n\n\n\n\n\n!\n\n\n(‘not’) operator as a prefix converts the above functions into ‘is.not’\n\n\n\n!is.factor(data)\n\n[1] TRUE\n\n\n\n\n\n\n\n\n5.1.1 Attributes\nMany R objects also have a set of attributes, the number and type of which are specific to each class of object. For example, a matrix object has a specific number of dimensions as well as row and column names. The attributes of an object can be viewed using the attributes() function:\n\nattributes(xy)\n\n$dim\n[1] 5 2\n\n$dimnames\n$dimnames[[1]]\n[1] \"A\" \"B\" \"C\" \"D\" \"E\"\n\n$dimnames[[2]]\n[1] \"x\" \"y\"\n\n\nSimilarly, the attr() function can be used to view and set individual attributes of an object, by specifying the name of the object and the name of the attribute (as a character string) as arguments. For example:\n\nattr(xy, \"dim\")\n\n[1] 5 2\n\nattr(xy, \"description\") &lt;- \"coordinates of quadrats\"\nxy\n\n      x     y\nA 16.92  8.37\nB 24.03 12.93\nC  7.61 16.65\nD 15.49 12.20\nE 11.77 13.12\nattr(,\"description\")\n[1] \"coordinates of quadrats\"\n\n\nNote that in the above example, the attribute ‘description’ is not a in-built attribute of a matrix. When a new attribute is set, this attribute is displayed along with the object. This provides a useful way of attaching a description (or other metadata) to an object, thereby reducing the risks of the object becoming unfamiliar."
  },
  {
    "objectID": "01_introduction_to_r.html#object-conversion",
    "href": "01_introduction_to_r.html#object-conversion",
    "title": "Introduction to R",
    "section": "5.2 Object conversion",
    "text": "5.2 Object conversion\nObjects can be converted or coerced into other objects using a family of functions with a as. prefix. Note that there are some obvious restrictions on these conversions as most objects cannot be completely accommodated by all other object types, and therefore some information (such as certain attributes) may be lost or modified during the conversion. Objects and elements that cannot be successfully coerced are returned as NA. The following table lists the common object coercion functions. Use methods(as) for a more comprehensive list.\n\n\n\n\n\nFunction\n\n\nConverts object to\n\n\n\n\n\n\nas.numeric(x)\n\n\na numeric vector (‘integer’ or ‘real’). Factors converted to integers.\n\n\n\n\nas.null(x)\n\n\na NULL\n\n\n\n\nas.logical(x)\n\n\na logical vector. A values of &gt;1 converted to TRUE otherwise FALSE.\n\n\n\n\nas.character(x)\n\n\na character (string) vector.\n\n\n\n\nas.vector(x)\n\n\na vector. All attributes (including names) are removed.\n\n\n\n\nas.factor(x)\n\n\na factor. This is an abbreviated (with respect to its argument set) version of the factor() function.\n\n\n\n\nas.matrix(x)\n\n\na matrix. Any non-numeric elements result in all matrix elements being converted to characters.\n\n\n\n\nas.list(x)\n\n\na list\n\n\n\n\nas.data.frame(x)\n\n\na data.frame. Matrix columns and list items are converted into separate vectors of the dataframe and character vectors are converted into factors. All previous attributes are removed.\n\n\n\n\nas.date(x)\n\n\na date"
  },
  {
    "objectID": "01_introduction_to_r.html#indexing",
    "href": "01_introduction_to_r.html#indexing",
    "title": "Introduction to R",
    "section": "5.3 Indexing",
    "text": "5.3 Indexing\nIndexing is the means by which data are filtered (subsetted) to include and exclude certain entries.\n\n5.3.1 Vector indexing\nSubsets of vectors are produced by appending an index vector (inclosed in square brackets []) to a vector name. There are four common forms of vector indexing used to extract a subset of vectors:\n\nVector of positive integers - a set of integers that indicate which elements of the vector should be included:\n\ntemperature[2]\n\n  Q2 \n30.6 \n\ntemperature[2:5]\n\n  Q2   Q3   Q4   Q5 \n30.6 31.0 36.3 39.9 \n\ntemperature[c(1, 5, 6, 9)]\n\n  Q1   Q5   Q6   Q9 \n36.1 39.9  6.5  9.7 \n\n\nVector of negative integers - a set of integers that indicate which elements of the vector should be excluded:\n\ntemperature[-2]\n\n  Q1   Q3   Q4   Q5   Q6   Q7   Q8   Q9  Q10 \n36.1 31.0 36.3 39.9  6.5 11.2 12.8  9.7 15.9 \n\ntemperature[c(1, 5, 6, 9) * -1]\n\n  Q2   Q3   Q4   Q7   Q8  Q10 \n30.6 31.0 36.3 11.2 12.8 15.9 \n\n\nVector of character strings (referencing names) - for vectors whose elements have been named, a vector of names can be used to select elements to include:\n\ntemperature[\"Q1\"]\n\n  Q1 \n36.1 \n\ntemperature[c(\"Q1\", \"Q4\")]\n\n  Q1   Q4 \n36.1 36.3 \n\n\nVector of logical values - a vector of logical values (TRUE or FALSE) the same length as the vector being subsetted. Entries corresponding to a logical TRUE are included, FALSE are excluded:\n\ntemperature[temperature &lt; 15]\n\n  Q6   Q7   Q8   Q9 \n 6.5 11.2 12.8  9.7 \n\ntemperature[shade == \"no\"]\n\n  Q1   Q2   Q3   Q4   Q5 \n36.1 30.6 31.0 36.3 39.9 \n\ntemperature[temperature &lt; 34 & shade == \"no\"]\n\n  Q2   Q3 \n30.6 31.0 \n\ntemperature[temperature &lt; 10 | shade == \"no\"]\n\n  Q1   Q2   Q3   Q4   Q5   Q6   Q9 \n36.1 30.6 31.0 36.3 39.9  6.5  9.7 \n\n\n\n\n\n5.3.2 Matrix indexing\nSimilar to vectors, matrices can be indexed using positive integers, negative integers, character strings and logical vectors. However, whereas vectors have a single dimension (length), matrices have two dimensions (length and width). Hence, indexing needs to reflect this. It is necessary to specify both the row and column number. Matrix indexing takes of the form of [row.indices, col.indices] where row.indices and col.indices respectively represent sequences of row and column indices. If a row or column index sequence is omitted, it is interpreted as the entire row or column respectively.\n\nxy[3, 2]\n\n[1] 16.65\n\nxy[3, ]\n\n    x     y \n 7.61 16.65 \n\nxy[, -2]\n\n    A     B     C     D     E \n16.92 24.03  7.61 15.49 11.77 \n\nxy[\"A\", 1:2]\n\n    x     y \n16.92  8.37 \n\nxy[, \"x\"]\n\n    A     B     C     D     E \n16.92 24.03  7.61 15.49 11.77 \n\nxy[xy[, \"x\"] &gt; 12, ]\n\n      x     y\nA 16.92  8.37\nB 24.03 12.93\nD 15.49 12.20\n\n\nIf you think that last example looks awkward you would not be alone. In a later tutorial, I will introduce an alternative way of manipulating data for data frames.\n\n\n5.3.3 List indexing\nLists consist of collections of objects that need not be of the same size or type. The objects within a list are indexed by appending an index vector (enclosed in single or double square brackets, [] or [[]]), to the list name. Single square brackets provide access to multiple list items (returned as a list), whereas double square brackets provide access to individual list items (returned according to the type of object represented by the list item). A single object within a list can also be referred to by appending a string character ($) followed by the name of the object to the list names (e.g. list$object). The elements of objects within a list are indexed according to the object type. Vector indices to objects within other objects (lists) are placed within their own square brackets outside the list square brackets: Recall the experiment list we generated earlier.\n\nexperiment\n\n$site\n [1] \"A1\" \"A2\" \"B1\" \"B2\" \"C1\" \"C2\" \"D1\" \"D2\" \"E1\" \"E2\"\n\n$quadrats\n [1] \"Q1\"  \"Q2\"  \"Q3\"  \"Q4\"  \"Q5\"  \"Q6\"  \"Q7\"  \"Q8\"  \"Q9\"  \"Q10\"\n\n$coordinates\n      x     y\nA 16.92  8.37\nB 24.03 12.93\nC  7.61 16.65\nD 15.49 12.20\nE 11.77 13.12\n\n$shade\n [1] no   no   no   no   no   full full full full full\nLevels: no full\n\n$temperature\n  Q1   Q2   Q3   Q4   Q5   Q6   Q7   Q8   Q9  Q10 \n36.1 30.6 31.0 36.3 39.9  6.5 11.2 12.8  9.7 15.9 \n\n\nThe following examples illustrate the common ways to subset (index) lists.\n\nA vector of positive numbers (single brackets) - that indicate which list items should be included:\n\nexperiment[c(1,3)]\n\n$site\n [1] \"A1\" \"A2\" \"B1\" \"B2\" \"C1\" \"C2\" \"D1\" \"D2\" \"E1\" \"E2\"\n\n$coordinates\n      x     y\nA 16.92  8.37\nB 24.03 12.93\nC  7.61 16.65\nD 15.49 12.20\nE 11.77 13.12\n\n\nA single positive number (double brackets) - that indicates which list item should be included:\n\nexperiment[[1]]\n\n [1] \"A1\" \"A2\" \"B1\" \"B2\" \"C1\" \"C2\" \"D1\" \"D2\" \"E1\" \"E2\"\n\n\nA single character string (double brackets) - that indicates which list item should be included:\n\nexperiment[['temperature']]\n\n  Q1   Q2   Q3   Q4   Q5   Q6   Q7   Q8   Q9  Q10 \n36.1 30.6 31.0 36.3 39.9  6.5 11.2 12.8  9.7 15.9 \n\n\nExtract the first element of each list item - returned as a matrix:\n\nsapply(experiment, \"[\" ,1)\n\n          site       quadrats    coordinates          shade temperature.Q1 \n          \"A1\"           \"Q1\"        \"16.92\"            \"1\"         \"36.1\" \n\n##notice that only one element of the coordinate pair is included\n##OR when the list items are not vectors\ndo.call(cbind, experiment)[1, ]\n\nWarning in (function (..., deparse.level = 1) : number of rows of result is not\na multiple of vector length (arg 1)\n\n\n       site    quadrats           x           y       shade temperature \n       \"A1\"        \"Q1\"     \"16.92\"      \"8.37\"         \"1\"      \"36.1\""
  },
  {
    "objectID": "01_introduction_to_r.html#pattern-matching-and-replacement",
    "href": "01_introduction_to_r.html#pattern-matching-and-replacement",
    "title": "Introduction to R",
    "section": "5.4 Pattern matching and replacement",
    "text": "5.4 Pattern matching and replacement\nAn important part of filtering is the ability to detect patterns on which to base selections or exclusions. Numerical and categorical filtering rules are generally fairly straight forward, however complex filtering rules can also be devised from character vectors. Furthermore, the ability to search and replace character strings within a character vector can also be very useful.\n\n5.4.1 grep - index of match\nThe grep() function searches within a vector for matches to a pattern and returns the index of all matching entries.\n\n## get the indexes of elements of the site vector that contain an 'A' \ngrep(pattern = \"A\", experiment$site)\n\n[1] 1 2\n\n## use the results of the grep as indexes to select only those 'site'\n## values that contain an 'A'\nexperiment$site[grep(pattern = \"a\", experiment$site)]\n\ncharacter(0)\n\n\nThe pattern can comprise any valid regular expression and is therefore very flexible:\n\n## get the indexes of values of the 'site' vector within the `data`\n## dataframe that contain either an 'A', 'B' or 'C' followed by a '1'\ngrep(\"[a-c]1\", data$site)\n\ninteger(0)\n\n## select only those rows of the `data` dataframe that correspond to a\n## 'site' value of either an 'A', 'B' or 'C' followed by a '1'\ndata[grep(\"[a-c]1\", data$site), ]\n\n[1] site        quadrats    shade       temperature\n&lt;0 rows&gt; (or 0-length row.names)\n\n\n\n\n5.4.2 regexpr - position and length of match\nRather than return the indexes of matching entries, the regexpr() function returns the position of the match within each string as well as the length of the pattern within each string (-1 values correspond to entries in which the pattern is not found).\n\naust &lt;- c(\"adelaide\", \"brisbane\", \"canberra\", \"darwin\", \"hobart\", \"melbourne\", \"perth\", \"sydney\")\naust\n\n[1] \"adelaide\"  \"brisbane\"  \"canberra\"  \"darwin\"    \"hobart\"    \"melbourne\"\n[7] \"perth\"     \"sydney\"   \n\n## get the position and length of string of characters containing an\n## 'a' and an 'e' separated by any number of characters\nregexpr(pattern=\"a.*e\", aust)\n\n[1]  1  6  2 -1 -1 -1 -1 -1\nattr(,\"match.length\")\n[1]  8  3  4 -1 -1 -1 -1 -1\nattr(,\"index.type\")\n[1] \"chars\"\nattr(,\"useBytes\")\n[1] TRUE\n\n\n\n\n5.4.3 gsub - pattern replacement\nThe gsub() function replaces all instances of an identified pattern within a character vector with an alternative set of characters. The similar sub() function replaces only the first instance.\n\ndata$shade\n\n [1] no   no   no   no   no   full full full full full\nLevels: no full\n\ngsub(\"no\", \"Not shaded\", data$shade)\n\n [1] \"Not shaded\" \"Not shaded\" \"Not shaded\" \"Not shaded\" \"Not shaded\"\n [6] \"full\"       \"full\"       \"full\"       \"full\"       \"full\"      \n\n\nIt is also possible to extend the functionality to accomodate perl-compatible regular expressions.\n\n## convert all the capital values entries into uppercase identify (and\n## store) all words (`\\\\w`) convert stored pattern (`\\\\1`) to uppercase\n## (`\\\\U`)\ngsub(\"(\\\\w)\", \"\\\\U\\\\1\", aust, perl = TRUE)\n\n[1] \"ADELAIDE\"  \"BRISBANE\"  \"CANBERRA\"  \"DARWIN\"    \"HOBART\"    \"MELBOURNE\"\n[7] \"PERTH\"     \"SYDNEY\"   \n\n\n\n\n5.4.4 substr - extracting substrings\nThe substr() function is used to extract parts of string (set of characters) entries within character vectors and thus is useful for making truncated labels (particularly for graphical summaries). For example, if we had a character vector containing the names of the Australian capital cities and required abbreviations (first 3 characters) for graph labels:\n\n## recall the AUST character vector that lists the Australian capital\n## cities\naust\n\n[1] \"adelaide\"  \"brisbane\"  \"canberra\"  \"darwin\"    \"hobart\"    \"melbourne\"\n[7] \"perth\"     \"sydney\"   \n\nsubstr(aust, start = 1, stop = 3)\n\n[1] \"ade\" \"bri\" \"can\" \"dar\" \"hob\" \"mel\" \"per\" \"syd\"\n\n\nAlternatively, we could use the abbreviate() function.\n\nabbreviate(aust, minlength = 3)\n\n adelaide  brisbane  canberra    darwin    hobart melbourne     perth    sydney \n    \"adl\"     \"brs\"     \"cnb\"     \"drw\"     \"hbr\"     \"mlb\"     \"prt\"     \"syd\" \n\n\n\n\n5.4.5 Value matching\nIn addition to the above matching procedures, it is possible to compare vectors via the usual set of binary operators (x&lt;y, x&gt;y, x≤y, x≥y, x==y and x!=y).\n\nshade == 'no'\n\n [1]  TRUE  TRUE  TRUE  TRUE  TRUE FALSE FALSE FALSE FALSE FALSE\n\ntemperature &gt; 32\n\n   Q1    Q2    Q3    Q4    Q5    Q6    Q7    Q8    Q9   Q10 \n TRUE FALSE FALSE  TRUE  TRUE FALSE FALSE FALSE FALSE FALSE \n\n\nNote, that the comparisons are made in an item-wise manner. That is, item one of the right hand vector is compared to item one of the left hand vector, and item two of each vector are compared to one another and so on. If the two vectors are not of equal length, the shorter vector is recycled (that is, it returns to the start of that vector and keeps going).\n\n## Compare 'Q1' to items 1,3,5,7,9 of quadrats and compare 'Q3' to\n## items 2,4,6,8,10.\nquadrats == c('Q1','Q3')\n\n [1]  TRUE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE\n\n\n\n\n\n\n\n\nWarning\n\n\n\nBe very cautious when using the binary operators x==y or x!=y to compare numeric vectors as they do not allow for rounding errors or finite representation of fractions and will almost always return FALSE even for values that appear identical. As an alternative, consider using a combination of all.equal() and identical():\n\n\n\n(0.6 - 0.4) == (0.4 - 0.2)\n\n[1] FALSE\n\nall.equal((0.6 - 0.4), (0.4 - 0.2))\n\n[1] TRUE\n\nidentical(all.equal((0.6 - 0.4), (0.4 - 0.2)), TRUE)\n\n[1] TRUE\n\n\nEach of the search and replace functions listed above uses only a single search item (albeit with pattern matching that can accommodate multiple patterns). The match() function searches for the first instance of items in the lookup vector (vector of values to be matched against) within the vector to be matched (first vector) returning the index of the first instance. Similarly, the special binary operator %in% indicates whether or not (TRUE or FALSE) an item of the matching vector is contained anywhere within the first vector. This latter mechanism makes a very useful filter.\n\n## match the items within the `shade` vector against a lookup character\n## vector containing only the string of \"no\" returning the index\n## within the lookup vector\nmatch(shade,\"no\")\n\n [1]  1  1  1  1  1 NA NA NA NA NA\n\n## match the items within the shade vector against a lookup character\n## vector containing only the string of \"no\" returning the index\n## within the lookup vector\nmatch(shade,\"no\")\n\n [1]  1  1  1  1  1 NA NA NA NA NA\n\n## same match as above, yet returning a logical vector corresponding\n## to whether each item in the first vector is matched or not\nshade %in% 'no'\n\n [1]  TRUE  TRUE  TRUE  TRUE  TRUE FALSE FALSE FALSE FALSE FALSE\n\n## match quadrats of 'Q1', 'Q4' and 'Q10'\nmatch(quadrats, c(\"Q1\",\"Q4\",\"Q10\"))\n\n [1]  1 NA NA  2 NA NA NA NA NA  3\n\nquadrats %in% c(\"Q1\",\"Q4\",\"Q10\")\n\n [1]  TRUE FALSE FALSE  TRUE FALSE FALSE FALSE FALSE FALSE  TRUE\n\n## use the resulting logical vector as a filter\ndata[quadrats %in% c(\"Q1\",\"Q4\",\"Q10\"),]\n\n    site quadrats shade temperature\nQ1    A1       Q1    no        36.1\nQ4    B2       Q4    no        36.3\nQ10   E2      Q10  full        15.9"
  },
  {
    "objectID": "01_introduction_to_r.html#sorting",
    "href": "01_introduction_to_r.html#sorting",
    "title": "Introduction to R",
    "section": "5.5 Sorting",
    "text": "5.5 Sorting\nThe sort() function is used to sort vector entries in increasing (or decreasing) order.\n\nsort(temperature)\n\n  Q6   Q9   Q7   Q8  Q10   Q2   Q3   Q1   Q4   Q5 \n 6.5  9.7 11.2 12.8 15.9 30.6 31.0 36.1 36.3 39.9 \n\nsort(temperature, decreasing = TRUE)\n\n  Q5   Q4   Q1   Q3   Q2  Q10   Q8   Q7   Q9   Q6 \n39.9 36.3 36.1 31.0 30.6 15.9 12.8 11.2  9.7  6.5 \n\n\nThe order() function is used to get the position of each entry in a vector if it were sorted in increasing (or decreasing) order.\n\norder(temperature)\n\n [1]  6  9  7  8 10  2  3  1  4  5\n\norder(temperature, decreasing = TRUE)\n\n [1]  5  4  1  3  2 10  8  7  9  6\n\n\nHence the smallest entry in the temperature vector was at position (index) 6 and so on.\nThe rank() function is used to get the ranking of each entry in a vector if it were sorted in increasing (or decreasing) order.\n\nrank(temperature)\n\n Q1  Q2  Q3  Q4  Q5  Q6  Q7  Q8  Q9 Q10 \n  8   6   7   9  10   1   3   4   2   5 \n\n\nIndicating that the first entry in the temperature vector was ranked eighth in increasing order. Ranks from decreasing order can be produced by then reversing the returned vector using the rev() function.\n\nrev(rank(temperature))\n\nQ10  Q9  Q8  Q7  Q6  Q5  Q4  Q3  Q2  Q1 \n  5   2   4   3   1  10   9   7   6   8 \n\n## or via pipe\nrank(temperature) |&gt; rev()\n\nQ10  Q9  Q8  Q7  Q6  Q5  Q4  Q3  Q2  Q1 \n  5   2   4   3   1  10   9   7   6   8"
  },
  {
    "objectID": "01_introduction_to_r.html#formatting-data",
    "href": "01_introduction_to_r.html#formatting-data",
    "title": "Introduction to R",
    "section": "5.6 Formatting data",
    "text": "5.6 Formatting data\n\n5.6.1 Rounding of numerical data\nThe ceiling() function rounds vector entries up to the nearest integer\n\nceiling(temperature)\n\n Q1  Q2  Q3  Q4  Q5  Q6  Q7  Q8  Q9 Q10 \n 37  31  31  37  40   7  12  13  10  16 \n\n\nThe floor() function rounds vector entries down to the nearest integer\n\nfloor(temperature)\n\n Q1  Q2  Q3  Q4  Q5  Q6  Q7  Q8  Q9 Q10 \n 36  30  31  36  39   6  11  12   9  15 \n\n\nThe trunc() function rounds vector entries to the nearest integer towards ‘0’ (zero)\n\nseq(from = -2, to = 2, by = 0.5)\n\n[1] -2.0 -1.5 -1.0 -0.5  0.0  0.5  1.0  1.5  2.0\n\ntrunc(seq(from = -2, to = 2, by = 0.5))\n\n[1] -2 -1 -1  0  0  0  1  1  2\n\n\nThe round() function rounds vector entries to the nearest numeric with the specified number of decimal places. Digits of 5 are rounded off to the nearest even digit.\n\nround(temperature)\n\n Q1  Q2  Q3  Q4  Q5  Q6  Q7  Q8  Q9 Q10 \n 36  31  31  36  40   6  11  13  10  16 \n\nround(seq(from = -2, to = 2, by = 0.5))\n\n[1] -2 -2 -1  0  0  0  1  2  2\n\nround(temperature/2.2, digits = 2)\n\n   Q1    Q2    Q3    Q4    Q5    Q6    Q7    Q8    Q9   Q10 \n16.41 13.91 14.09 16.50 18.14  2.95  5.09  5.82  4.41  7.23 \n\nround(temperature, digits = -1)\n\n Q1  Q2  Q3  Q4  Q5  Q6  Q7  Q8  Q9 Q10 \n 40  30  30  40  40  10  10  10  10  20 \n\n\n\n\n5.6.2 Notation and labelling of numeric or character data\nOccasionally (mainly for graphical displays), it is necessary to be able to adjust the other aspects of the formatting of vector entries. For example, you may wish to have numbers expressed in scientific notation (2.93e-04 rather than 0.000293) or insert commas every 3 digits left of the decimal point or even add prefixes or suffixes to numbers or words. These procedures are supported via a number of functions. The uses of each function are contrasted in the following table followed by common usage examples below.\n\n\n\n\n\n\n\nFunction\nDescription\n\n\n\n\npaste()\nConcatenate vectors after converting into characters\n\n\nformat()\nAdjust decimal places, justification, padding and width of string and whether to use scientific notation\n\n\nformatC()\nA version of format() that is compliant with ‘C’ style formatting.\n\n\nsprintf()\nA wrapper for the ‘C’ style formatting function of the same name = provides even greater flexibility (and complexity).\n\n\n\n\npaste()\nCombine multiple elements together along with other character strings.\n\npaste(\"Quadrat\", 1:3, sep = \":\")\n\n[1] \"Quadrat:1\" \"Quadrat:2\" \"Quadrat:3\"\n\n##create a joint label for site and quadrat combinations\npaste(site, quadrats, sep = \":\")\n\n [1] \"A1:Q1\"  \"A2:Q2\"  \"B1:Q3\"  \"B2:Q4\"  \"C1:Q5\"  \"C2:Q6\"  \"D1:Q7\"  \"D2:Q8\" \n [9] \"E1:Q9\"  \"E2:Q10\"\n\n## create a formula relating temperature to quadrat, site and shade\npaste(names(data)[4], paste(names(data)[-4], collapse = \"+\"), sep = \"~\")\n\n[1] \"temperature~site+quadrats+shade\"\n\n## or more neatly\npaste(names(data)[4],\n  paste(names(data)[-4], collapse = \"+\"),\n  sep = \"~\"\n)\n\n[1] \"temperature~site+quadrats+shade\"\n\n\n\n\nformat()\nOverloaded generic function for formatting objects (particularly numeric vectors). The most prominent features include:\n\nAutomatically adding leading or trailing spaces to create equal width labels (via trim =, width = and justify = )\nApplication of scientific notation (via scientific =)\nRounding of numbers (via digits = and nsmall =)\nApplies to each column in a dataframe separately\n\n\n## create equal width strings by adding padding to the start (left\n## side) of numbers\nformat(temperature)\n\n    Q1     Q2     Q3     Q4     Q5     Q6     Q7     Q8     Q9    Q10 \n\"36.1\" \"30.6\" \"31.0\" \"36.3\" \"39.9\" \" 6.5\" \"11.2\" \"12.8\" \" 9.7\" \"15.9\" \n\n## create labels with a minimum of 2 digits to the right hand side of\n## the decimal place\nformat(temperature, nsmall = 2)\n\n     Q1      Q2      Q3      Q4      Q5      Q6      Q7      Q8      Q9     Q10 \n\"36.10\" \"30.60\" \"31.00\" \"36.30\" \"39.90\" \" 6.50\" \"11.20\" \"12.80\" \" 9.70\" \"15.90\" \n\n## create labels that are rounded numbers\nformat(temperature, digits = 1)\n\n  Q1   Q2   Q3   Q4   Q5   Q6   Q7   Q8   Q9  Q10 \n\"36\" \"31\" \"31\" \"36\" \"40\" \" 6\" \"11\" \"13\" \"10\" \"16\" \n\n## create labels that are scientific representations of the numbers\nformat(temperature, scientific = TRUE)\n\n        Q1         Q2         Q3         Q4         Q5         Q6         Q7 \n\"3.61e+01\" \"3.06e+01\" \"3.10e+01\" \"3.63e+01\" \"3.99e+01\" \"6.50e+00\" \"1.12e+01\" \n        Q8         Q9        Q10 \n\"1.28e+01\" \"9.70e+00\" \"1.59e+01\" \n\n## apply formatting rules to a dataframe (notice the left\n## justification of Shade and the number of decimal places of\n## temperature)\nformat(data, justify = \"left\", nsmall = 2)\n\n    site quadrats shade temperature\nQ1    A1      Q1   no         36.10\nQ2    A2      Q2   no         30.60\nQ3    B1      Q3   no         31.00\nQ4    B2      Q4   no         36.30\nQ5    C1      Q5   no         39.90\nQ6    C2      Q6   full        6.50\nQ7    D1      Q7   full       11.20\nQ8    D2      Q8   full       12.80\nQ9    E1      Q9   full        9.70\nQ10   E2      Q10  full       15.90\n\n\n\n\nformatC()\nSimilar to the format() function, yet also allows ‘C’ style formatting specifications:\n\n‘d’ for integers\n‘f’ for reals in the standard xxx.xxx format\n‘e’, ‘E’ for reals in the scientific (n.ddde+nn) format\n‘g’, ‘G’ for reals in the scientific (n.ddde+nn) format when it saves space to do so\n‘s’ for strings\n\n\nseq(pi, pi * 10000, length = 5)\n\n[1]     3.141593  7856.337828 15709.534064 23562.730300 31415.926536\n\n## format to integers  \nformatC(seq(pi, pi * 10000, length = 5), format = \"d\")\n\n[1] \"3\"     \"7856\"  \"15709\" \"23562\" \"31415\"\n\n## scientific notation\nformatC(seq(pi, pi * 10000, length = 5), format = \"e\", digits = 2)\n\n[1] \"3.14e+00\" \"7.86e+03\" \"1.57e+04\" \"2.36e+04\" \"3.14e+04\"\n\n## scientific notation only if it saves space\nformatC(seq(pi, pi * 10000, length = 5), format = \"g\", digits = 2)\n\n[1] \"3.1\"     \"7.9e+03\" \"1.6e+04\" \"2.4e+04\" \"3.1e+04\"\n\n## floating point format with 1000's indicators\nformatC(seq(pi, pi * 10000, length = 5), format = \"f\", big.mark = \",\", digits = 2)\n\n[1] \"3.14\"      \"7,856.34\"  \"15,709.53\" \"23,562.73\" \"31,415.93\"\n\n\n\n\nsprintf()\nSimilar to the format() function, yet also allows ‘C’ style formatting specifications:\n\n‘d’ for integers\n‘f’ for reals in the standard xxx.xxx format\n‘e’, ‘E’ for reals in the scientific (n.ddde+nn) format\n‘g’, ‘G’ for reals in the scientific (n.ddde+nn) format when it saves space to do so\n‘s’ for strings\n\n\nPI &lt;- seq(pi, pi * 10000, length = 5)\nPI\n\n[1]     3.141593  7856.337828 15709.534064 23562.730300 31415.926536\n\n## format to integers\nsprintf(\"%.0f\", PI)\n\n[1] \"3\"     \"7856\"  \"15710\" \"23563\" \"31416\"\n\n## format to two decimal places and 6 characters to the left of the\n## decimal point (right justified)\nsprintf(\"%6.2f\", PI)\n\n[1] \"  3.14\"   \"7856.34\"  \"15709.53\" \"23562.73\" \"31415.93\"\n\n## scientific notation\nsprintf(\"%e\", PI)\n\n[1] \"3.141593e+00\" \"7.856338e+03\" \"1.570953e+04\" \"2.356273e+04\" \"3.141593e+04\"\n\n## scientific notation only when it saves space\nsprintf(\"%6.2g\", PI)\n\n[1] \"   3.1\"  \"7.9e+03\" \"1.6e+04\" \"2.4e+04\" \"3.1e+04\"\n\n## concatenating strings\nsprintf(\"%s-%s\", site, quadrats)\n\n [1] \"A1-Q1\"  \"A2-Q2\"  \"B1-Q3\"  \"B2-Q4\"  \"C1-Q5\"  \"C2-Q6\"  \"D1-Q7\"  \"D2-Q8\" \n [9] \"E1-Q9\"  \"E2-Q10\"\n\nsprintf(\"%s=%.2g\", 'val', PI)\n\n[1] \"val=3.1\"     \"val=7.9e+03\" \"val=1.6e+04\" \"val=2.4e+04\" \"val=3.1e+04\"\n\nsprintf(\"%s=%6.2g\", 'val', PI)\n\n[1] \"val=   3.1\"  \"val=7.9e+03\" \"val=1.6e+04\" \"val=2.4e+04\" \"val=3.1e+04\"\n\nsprintf('%11s', sprintf(\"%s=%.2g\", 'val', PI))\n\n[1] \"    val=3.1\" \"val=7.9e+03\" \"val=1.6e+04\" \"val=2.4e+04\" \"val=3.1e+04\""
  },
  {
    "objectID": "01_introduction_to_r.html#applying-functions-repetitively",
    "href": "01_introduction_to_r.html#applying-functions-repetitively",
    "title": "Introduction to R",
    "section": "5.7 Applying functions repetitively",
    "text": "5.7 Applying functions repetitively\nAs R is a programming language, it naturally has constructs for controlling flow via looping and conditional evaluation. R’s basic control-flow constructs is the topic of another tutorial. Despite the enormous flexibility gained via the usual control-flow constructs, recall that as R is a scripting language (rather than a compiled language), it is relatively slow. In particular, repetitive tasks (such as looping though a dataframe and applying the same function to different subsets of the data) are especially inefficient.\nThere are a number of functions in R that are designed to allow the repetitive application of a function thereby replacing the need to write loops.\n\n\n\n\n\n\n\n\nFunction\nDescription\n\n\n\n\nrep()\nDuplicates the result of a function multiple times\n\n\nreplicated()\nPerforms a function multiple times\n\n\napply()\nRepetitively apply a function over the margins of a matrix\n\n\ntapply()\nRepetitively apply a function to cells made up of unique combinations of factor levels\n\n\nlapply()\nRepetitively apply a function to the elements of a list of vector and return a list.\n\n\n\nThe replicate() function repeatedly performs the function specified in the second argument the number of times indicated by the first argument. The important distinction between the replicate() function and the rep() function described earlier, is that the former repeatedly performs the function whereas the later performs the function only once and then duplicates the result multiple times.\nSince most functions produce the same result each time they are performed, for many uses, both functions produce identical results. The one group of functions that do not produce identical results each time, are those involved in random number generation. Hence, the replicate() function is usually used in conjunction with random number generators (such as runif(), which will be described in greater detail in subsequent tutorial) to produce sets of random numbers. Consider first the difference between rep() and replicate():\n\nrep(runif(1), times = 5)\n\n[1] 0.6989921 0.6989921 0.6989921 0.6989921 0.6989921\n\nreplicate(n = 5, runif(1))\n\n[1] 0.9656330 0.9645978 0.8941959 0.9122629 0.8333949\n\n\nWhen the function being run within runif() itself produces a vector of length &gt; 1, the runif() function combines each of the vectors together as separate columns in a matrix:\n\nreplicate(n = 5, runif(5))\n\n          [,1]       [,2]      [,3]       [,4]       [,5]\n[1,] 0.6723270 0.79381782 0.7748949 0.87597052 0.14784992\n[2,] 0.4264546 0.05777239 0.2863099 0.65182712 0.71916413\n[3,] 0.4356704 0.76062533 0.7193469 0.04443515 0.22039021\n[4,] 0.6437318 0.08231589 0.9590831 0.07027877 0.71719302\n[5,] 0.1503932 0.04285238 0.1923634 0.69367204 0.02714582\n\n\n\n5.7.1 Apply functions along matrix margins\nThe apply() function applies a function to the margins (1=row margins and 2=column margins) of a matrix. For example, we might have a matrix that represents the abundance of three species of moth from three habitat types:\n\nmoth &lt;- cbind(SpA = c(25, 6, 3), SpB = c(12, 12, 3), SpC = c(7, 2, 19))\nrownames(moth) &lt;- paste(\"Habitat\", 1:3, sep = \"\")\nmoth\n\n         SpA SpB SpC\nHabitat1  25  12   7\nHabitat2   6  12   2\nHabitat3   3   3  19\n\n\nThe apply() function could be used to calculate the column means (mean abundance of each species across habitat types):\n\napply(moth, MARGIN = 2, FUN = mean)\n\n      SpA       SpB       SpC \n11.333333  9.000000  9.333333 \n\n\n\n\n5.7.2 Pivot tables\nThe tapply() function applies a function to a vector separately for each level of a factorial variable. For example, if we wanted to calculate the mean temperature for each level of the shade variable:\n\ntapply(temperature, INDEX = shade, FUN = mean)\n\n   no  full \n34.78 11.22 \n\n## calculate the mean temperature per shade and quadrat number combination\n## quadrat number is just the last digit of the quadrats vector\n## extracted via substr(site, 2, 2)\ntapply(temperature, list(shade, quadnum = substr(site, 2, 2)), mean)\n\n      quadnum\n              1        2\n  no   35.66667 33.45000\n  full 10.45000 11.73333\n\n\n\n\n5.7.3 Apply a function over a list\nThe lapply() and sapply() functions apply a function separately to each of the objects in a list and return a list and vector/matrix respectively. For example, to find out the length of each of the objects within the experiment list:\n\nlapply(experiment, length)\n\n$site\n[1] 10\n\n$quadrats\n[1] 10\n\n$coordinates\n[1] 10\n\n$shade\n[1] 10\n\n$temperature\n[1] 10\n\nsapply(experiment, length)\n\n       site    quadrats coordinates       shade temperature \n         10          10          10          10          10"
  },
  {
    "objectID": "01_introduction_to_r.html#listing-installed-packages",
    "href": "01_introduction_to_r.html#listing-installed-packages",
    "title": "Introduction to R",
    "section": "6.1 Listing installed packages",
    "text": "6.1 Listing installed packages\nThe installed.packages() function tabulates a list of all the currently installed packages available on your system along with the package path (where is resides on your system) and version number. Additional fields can be requested (including “Priority”, “Depends”, “Imports”, “LinkingTo”, “Suggests”, “Enhances”, “OS_type”, “License” and “Built”).\n\ninstalled.packages()\ninstalled.packages(fields=c(\"Package\", \"LibPath\", \"Version\", \"Depends\",\"Built\"))\n\n\n\n\n\n\n\nNote\n\n\n\nIn the above, I have intentionally supressed the output so as not to flood the output (I have a very large number of packages installed on my machine).\n\n\nYet more information can be obtained for any single package with the packageDescription() and library functions - the latter provides all the information of the former and then includes a descriptive index of all the functions and datasets defined within the package.\n\npackageDescription('MASS')\n\nPackage: MASS\nPriority: recommended\nVersion: 7.3-60\nDate: 2023-05-02\nRevision: $Rev: 3621 $\nDepends: R (&gt;= 4.0), grDevices, graphics, stats, utils\nImports: methods\nSuggests: lattice, nlme, nnet, survival\nAuthors@R: c(person(\"Brian\", \"Ripley\", role = c(\"aut\", \"cre\", \"cph\"),\n        email = \"ripley@stats.ox.ac.uk\"), person(\"Bill\", \"Venables\",\n        role = \"ctb\"), person(c(\"Douglas\", \"M.\"), \"Bates\", role =\n        \"ctb\"), person(\"Kurt\", \"Hornik\", role = \"trl\", comment =\n        \"partial port ca 1998\"), person(\"Albrecht\", \"Gebhardt\", role =\n        \"trl\", comment = \"partial port ca 1998\"), person(\"David\",\n        \"Firth\", role = \"ctb\"))\nDescription: Functions and datasets to support Venables and Ripley,\n        \"Modern Applied Statistics with S\" (4th edition, 2002).\nTitle: Support Functions and Datasets for Venables and Ripley's MASS\nLazyData: yes\nByteCompile: yes\nLicense: GPL-2 | GPL-3\nURL: http://www.stats.ox.ac.uk/pub/MASS4/\nContact: &lt;MASS@stats.ox.ac.uk&gt;\nNeedsCompilation: yes\nPackaged: 2023-05-02 16:42:41 UTC; ripley\nAuthor: Brian Ripley [aut, cre, cph], Bill Venables [ctb], Douglas M.\n        Bates [ctb], Kurt Hornik [trl] (partial port ca 1998), Albrecht\n        Gebhardt [trl] (partial port ca 1998), David Firth [ctb]\nMaintainer: Brian Ripley &lt;ripley@stats.ox.ac.uk&gt;\nRepository: CRAN\nDate/Publication: 2023-05-04 07:32:21 UTC\nBuilt: R 4.3.2; x86_64-pc-linux-gnu; 2023-11-01 22:36:06 UTC; unix\n\n-- File: /opt/R/4.3.2/lib/R/library/MASS/Meta/package.rds \n\nlibrary(help='MASS')"
  },
  {
    "objectID": "01_introduction_to_r.html#installing-packages",
    "href": "01_introduction_to_r.html#installing-packages",
    "title": "Introduction to R",
    "section": "6.2 Installing packages",
    "text": "6.2 Installing packages\nThe R community contains some of the brightest and most generous mathematician, statisticians and practitioners who continue to actively develop and maintain concepts and routines. Most of these routines end up being packaged as a collection of functions and then hosted on one or more publicly available sites so that others can benefit from their efforts.\nThe locations of collections of packages are called repositories or ‘repos’ for short. There four main repositories are CRAN, Bioconductor, R-Forge and github. By default, R is only ‘tuned in’ to CRAN. That is any package queries or actions pertain just to the CRAN repositories.\nTo get a tabulated list of all the packages available on CRAN (warning there are over 5000 packages, so this will be a large table - I will suppress the output):\n\navailable.packages()\n\n\n6.2.1 Comprehensive R Archive Network - CRAN\nCRAN is a repository of R packages mirrored across 90 sites throughout the world. Packages are installed from CRAN using the install.packages() function. The first (and only mandatory) argument to the install.packages() function is the name of the package(s) to install (pkgs =). If no other arguments are provided, the install.packages() function will search CRAN for the specified package(s) and install it along with any of its dependencies that are not yet installed on your system.\nNote, unless you have started the session with administrator (root) privileges, the packages will be installed within a path of your home folder. Whilst this is not necessarily a bad thing, it does mean that the package is not globally available to all users on your system (not that it is common to have multiple users of a single system these days). Moreover, it means that R packages reside in multiple locations across your system. The packages that came with your R install will be in one location (or a couple or related locations) and the packages that you have installed will be in another location.\nTo see the locations currently used on your system, you can issue the following statement.\n\n.libPaths()\n\n[1] \"/home/runner/work/_temp/Library\" \"/opt/R/4.3.2/lib/R/site-library\"\n[3] \"/opt/R/4.3.2/lib/R/library\"     \n\n\nTo install a specific package (and its dependencies). The package that I have chosen to demonstrate this with (remotes) is a package that enables R packages to be installed from git repositories (such as github, and will be featured in a later subsection).\n\ninstall.packages(\"remotes\")\n\nYou will be prompted to select a mirror site. In the absence of any other criterion, just select the mirror that is closed geographically to you. The terminal will then provide feedback about the progress and status of the install process. By indicating a specific repository, you can avoid being prompted for a mirror. For example, I chose to use a CRAN mirror at Melbourne University (Australia), and therefore the following statement gives me direct access\n\ninstall.packages(\"remotes\", repos = \"http://cran.csiro.au\")\n\nFinally, you could provide a vector of repository names if you were unsure which repository was likely to contain the package you were after. This can also be useful if your preferred mirror regularly experiences downtime - the alternative mirror (second in the vector) is used only when the first fails.\n\n\n6.2.2 Bioconductor\nBioconductor is an open source and open development project devoted to genomic data analysis tools, most of which are available as R packages. Whilst initially the packages focused primarily on the manipulation and analysis of DNA microarrays, as the scope of the projects has expanded, so too has the functional scope of the packages there hosted.\n\nsource(\"http://bioconductor.org/biocLite.R\")\nbiocLite(\"limma\")\n\nOr to install multiple packages from Bioconductor\n\nsource(\"http://bioconductor.org/biocLite.R\")\nbiocLite(c(\"GenomicFeatures\", \"AnnotationDbi\"))\n\n\n\n6.2.3 R-Forge\nUnlike both CRAN and Bioconductor (which are essentially package repositories), R-Forge is an entire R package development platform. Package development is supported through a range of services including:\n\nversion control (SVN) - allowing multiple collaborators to maintain current and historical versions of files by facilitating simultaneous editing, conflict resolution and rolling back\ndaily package checking and building - so packages are always up to date\nbug tracking and feature request tools\nmailing lists and message boards\nfull backup and archival system\n\nAnd all of this within a mature content management system like web environment. Installing packages from R-Forge is the same as it is for CRAN, just that the path of the root repository needs to be specified with the repos= argument.\n\ninstall.packages(\"lme4.0\", repos = \"http://R-Forge.R-project.org\")\n\n\n\n6.2.4 Github (via remotes)\nGithub builds upon the philosophy of the development platform promoted by the Source Forge family (including R-Forge) by adding the ability to fork a project. Forking is when the direction of a project is split so that multiple new opportunities can be explored without jeopardizing the stability and integrity of the parent source. If the change in direction proves valuable, the project (package) can either become a new package or else feedback into the development of the original package.\nHadley Wickham and Co have yet again come up with a set of outrageously useful tools (remotes package). This package is a set of functions that simplify (albeit slightly dictatorially) the processes of installing packages from remote and local repositories (Github, Gitlab, Bitbucket etc)\nIn order to make use of this package to install packages from github, the remotes package must itself be installed (we did this earlier). It is recommended that this install take place from CRAN (as outline above). Thereafter, the remotes package can be included in the search path and the install_github function used to retrieve and install a nominated package or packages from Github.\n\nremotes::install_github(\"ggplot2\")\n\nAs described above, Github is a development platform and therefore it is also a source of ‘bleeding edge’ development versions of packages. Whilst the development versions are less likely to be as stable or even as statistically rigorous as the final release versions, they do offer the very latest ideas and routines. They provide the very latest snapshot of where the developers are currently at.\nMost of the time users only want the stable release versions of a package. However there are times when having the ability to try out new developments as they happen can be very rewarding. The install_dev() function allows for the installation of the development version of a package.\nThe more complex devtools package (also by Hadley Wickham et al) provides a set of functions that simplify (albeit slightly dictatorially) the processes of package authoring, building, releasing and installing. Within the devtools package, the dev_mode() function provides a switch that can be used to toggle your system in and out of development mode. When in development mode, installed packages are quarantined within a separate path (R-dev) to prevent them overriding or conflicting with the stable versions that are critical for your regular analyses.\n\n## switch to development mode\ndevtools::dev_mode(on = TRUE)\n##install the development version of ggplot2\ndevtools::install_github(\"ggplot2\")\n## use the development version of ggplot2 \nlibrary(ggplot2)\n## switch development mode off\ndevtools::dev_mode(on = FALSE)\n## stable version of ggplot2 is now engaged\n\n\n\n6.2.5 Manual download and install\nPackages are made available on the various repositories in compressed form and differ between Windows, MacOSX and Linux versions. Those web repositories all have functionality for navigating or searching through the repositories for specific packages. The packages (compressed files) can be directly downloaded from these sites.\nAdditionally, some packages are not available on the various repositories and firewalls and proxies can sometimes prevent R from accessing the repositories directly. In these cases, packages must be manually downloaded and installed.\nThere are a number of ways to install a package that resides locally. Note, do not uncompress the packages.\n\nFrom the command line (outside of R).\n\n\nR CMD INSTALL packagename \n\nwhere packagename is replaced by the path and name of the compressed package.\n\nUsing the install.packages() function by specifying repos = NULL.\n\n\ninstall.packages('packagename', repos=NULL)\n\nwhere packagename is replaced by the path (if not in the current working directory) and name of the compressed package.\n\nVia the Windows RGui, select the Install package(s) from local zip files… option of the Packages menu and select the compressed package."
  },
  {
    "objectID": "01_introduction_to_r.html#updating-packages",
    "href": "01_introduction_to_r.html#updating-packages",
    "title": "Introduction to R",
    "section": "6.3 Updating packages",
    "text": "6.3 Updating packages\nAn integral component of package management is being able to maintain an up to date system. Many packages are regularly updated so as to adopt new ideas and functionality. Indeed, it is the speed of functional evolution that sets R apart from most other statistical environments.\nAlong with the install.packages() function, there are three other functions to help manage and maintain the packages on your system.\n\nold.packages() compares the versions of packages you have installed with the versions of those packages available in the current repositories. It tabulates the names, install paths and versions of old packages on your system.\n\nold.packages()\n\nAlternative repositories (than CRAN) can be indicated via the repos   = argument.\n\nold.packages(repos = \"http://R-Forge.R-project.org\")\n## or even multiple repos\nold.packages(repos = c(\"http://cran.csiro.au\", \"http://R-Forge.R-project.org\"))\n\nnew.packages() provides a tabulated list of all the packages on the repository that are either not in your local install, or else are of a newer version. Note, with over 4000 packages available on CRAN, unless the repos= parameter is pointing to somewhere very specific (and with a narrow subset of packages) this function is rarely of much use.\n\nnew.packages()\n\nupdate.packages() downloads and installs packages for which newer versions of those packages identified as ‘old’ by the old.packages() function. Just like old.packages(), alternative or multiple repositories can be specified.\n\nupdate.packages()\n## or from alternative multiple repos\nupdate.packages(repos = c(\"http://cran.csiro.au\", \"http://R-Forge.R-project.org\"))"
  },
  {
    "objectID": "01_introduction_to_r.html#package-management-pak",
    "href": "01_introduction_to_r.html#package-management-pak",
    "title": "Introduction to R",
    "section": "6.4 Package management (pak)",
    "text": "6.4 Package management (pak)\nPackage management can be a relatively complex task. These days packages are sourced from a variety and mixture of locations (CRAN, Github etc). Furthermore, most packages have a complex network of dependencies (that is, they depend on other packages). The fine folk over at Rstudio have developed a package called pak that aims to provide a unified and simplified interface to package management.\nThis next-generation package installer offers several key advantages for the technical R user:\n\nParallel downloads: pak leverages multi-core processing to download multiple packages simultaneously, significantly reducing installation time.\nIntelligent dependency resolution: pak automatically resolves package dependencies, installing the necessary versions in the correct order, ensuring a seamless experience.\nExpanded package sources: pak supports installation from diverse repositories like Bioconductor and even GitHub URLs, providing access to a broader range of cutting-edge tools.\nFine-grained control: pak gives you the power to specify them explicitly, offering greater control over your R environment.\nExtensible architecture: pak exposes an API for building custom extensions and integrating seamlessly with your data science workflows.\n\nBefore we can take advantage of pak package management, it must first be installed from CRAN using the traditional package installation method.\n\ninstall.packages(\"pak\")\n\n\n6.4.1 Dependencies\nFor any given package, we can see the dependencies. To illustrate, I will focus on the Matrix package.\n\npak::pkg_deps(\"Matrix\")\n\nℹ Loading metadata database\n\n\n✔ Loading metadata database ... done\n\n\n\n\n\n# A data frame: 2 × 36\n  ref     type  direct directpkg status package version license needscompilation\n  &lt;chr&gt;   &lt;chr&gt; &lt;lgl&gt;  &lt;lgl&gt;     &lt;chr&gt;  &lt;chr&gt;   &lt;chr&gt;   &lt;chr&gt;   &lt;lgl&gt;           \n1 lattice stan… FALSE  FALSE     OK     lattice 0.22-5  GPL (&gt;… TRUE            \n2 Matrix  stan… TRUE   TRUE      OK     Matrix  1.6-5   GPL (&gt;… TRUE            \n# ℹ 27 more variables: priority &lt;chr&gt;, md5sum &lt;chr&gt;, sha256 &lt;chr&gt;,\n#   filesize &lt;int&gt;, built &lt;chr&gt;, platform &lt;chr&gt;, rversion &lt;chr&gt;,\n#   repotype &lt;chr&gt;, repodir &lt;chr&gt;, target &lt;chr&gt;, deps &lt;list&gt;, mirror &lt;chr&gt;,\n#   sources &lt;list&gt;, remote &lt;list&gt;, error &lt;list&gt;, metadata &lt;list&gt;,\n#   dep_types &lt;list&gt;, params &lt;list&gt;, sysreqs &lt;chr&gt;, cache_status &lt;chr&gt;,\n#   sysreqs_packages &lt;list&gt;, sysreqs_pre_install &lt;chr&gt;,\n#   sysreqs_post_install &lt;chr&gt;, sysreqs_install &lt;chr&gt;, lib_status &lt;chr&gt;, …\n\n\nAfter some database checking, the above function returns a tibble (like a data frame, yet with some special properties that include truncated output) containing a row for each dependency. In this example, the tibble has just two rows (one for the Matrix package, and the other for its only dependency, the Lattice package). To save space, the many columns have been truncated, yet listed below the tibble.\nAlternatively, we could view the dependencies as a tree.\n\npak::pkg_deps_tree(\"Matrix\")\n\nMatrix 1.6-1.1 -&gt; 1.6-5 [upd][bld][cmp][dl] (2.88 MB)\n└─lattice 0.21-9 -&gt; 0.22-5 [upd][bld][cmp][dl] (599.04 kB)\n\nKey:  [upd] update | [dl] download | [bld] build | [cmp] compile\n\n\nWe can see from the above that the Matrix package depends on the Lattice package.\n\n\n6.4.2 Installing packages\nTo install a package:\n\nfrom CRAN or Bioconductor: just provide the package name as an argument\n\npak::pkg_install(\"tidyverse\")\n\nfrom Github: provide the package name in the form of user/repo. You can also nominate a specific branch (user/repo@branch) or tag (user/repo@tag).\n\npak::pkg_install(\"tidyverse/dplyr\")\n\n\nSimilarly, pak::pkg_install() can be used for package updating. If the package has not yet been installed, the package will be installed, yet if the package has already been installed, then it will instead be updated (unless it is already the most up to date version).\nIf the upgrade = TRUE argument is supplied, then all the dependencies will also be updated.\n\n\n6.4.3 Removing packages\nPackage can be removed using the pak::pkg_remove() function."
  },
  {
    "objectID": "01_introduction_to_r.html#namespaces",
    "href": "01_introduction_to_r.html#namespaces",
    "title": "Introduction to R",
    "section": "6.5 Namespaces",
    "text": "6.5 Namespaces\nEarly on in this tutorial, I presented a set of rules and recommendations for object naming. One recommendation that I stressed was to avoid using names for objects that are the names of common functions (like mean) so as to (hopefully) avoid conflicting with any of the functions built in to R.\nHaving made these recommendations, I will now say that R is not overly fragile and is sufficiently cleaver to enable it to resolve many naming conflicts. Object names are context specific (see also object overloading above).\nWhen the name of an object is supplied that could be used to refer to multiple objects (for example, if you had created an object called mean there would be two objects named mean - your object and the inbuilt function), R first attempts to determine which object you are likely to have been referring to.\nObjects are defined and apply within certain contexts or namespaces. Namespaces defined the context (environment) in which an object is available. Objects created within functions, remain local to those functions. Hence if an object is created within a function, it is not available outside that function.\nThe namespace provides a context in which R should look for an object (such as a function). Functions defined within packages are available for use, when the library is loaded. This is essentially adding the libraries namespace to the list of contexts to that R should search within when you confront it with an expression.\nAlternatively, we can prefix the function name with the package name (its namespace) thereby explicitly indicating the context in which the function is defined and thus, the function will be found.\nFor example, lets say we wanted to create sparse diagonal matrix (a matrix with values in the diagonals and blanks in the off diagonals. There is a function called Diagonal in the Matrix package. We could expose this function (and all others in the package via the library function or we could just prefix the function name with the package name.\n\n## call the Diagonal function (however it wont be found)\nDiagonal(3)\n\nError in Diagonal(3): could not find function \"Diagonal\"\n\n## call the diagonal function from the Matrix package\nMatrix::Diagonal(3)\n\n3 x 3 diagonal matrix of class \"ddiMatrix\"\n     [,1] [,2] [,3]\n[1,]    1    .    .\n[2,]    .    1    .\n[3,]    .    .    1\n\n\nSimilarly, prefixing the namespace to the function name allows us to explicitly nominate exactly which function we want to use in the event that there are two functions of the same name in different packages."
  },
  {
    "objectID": "02_editors.html",
    "href": "02_editors.html",
    "title": "Code Editors",
    "section": "",
    "text": "1 Introduction\nIn the previous tutorial, we installed R and began exploring the language. If this was your very first time using R and perhaps your first exposure to any programming language, it is likely that you worked through the tutorial using either the R Gui (if on windows) or the terminal application in MacOSX or Linux.\nWhilst these tools to provide direct interaction with the R engine, they do little to support your efforts to develop code, documentation and sophisticated analysis outputs. This is where code editors come in.\nCode editors are a specialized software tools designed for creating and modifying source code of computer programs. They provide essential features such as syntax highlighting, code completion, and error checking, enhancing the efficiency and accuracy of programming tasks. Code editors are essential for developers, offering a streamlined environment for writing, editing, and organizing code, facilitating the software development process.\nChoosing an appropriate code editor is crucial for efficient R development. Each editor offers unique features and interfaces, catering to different preferences and workflows. This guide will walk you through some of the popular choices, including RStudio, Visual Studio Code, Emacs, Neovim, and Sublime Text, helping you make an informed decision.\nOf these, particular emphasis will be placed on RStudio. This is primarily because it is specifically designed to be an Intergrated Development Environment (IDE) for R. It is developed by active members of the R community for the R community. Furthermore, because it is a dedicated R IDE, it works straight out of the box with little to no configuration necessary. By contrast, the other editors are general code editors and thus must be specifically configured to provide R based functionality.\n\n\n2 Editors\n\nRStudioVisual Studio CodeEmacsNeoVimSublime Text\n\n\n\n2.0.1 Overview\nRStudio stands out as a widely used and dedicated Integrated Development Environment (IDE) designed for R development. Its user-friendly interface and comprehensive features make it a popular choice among R users.\n\n\n2.0.2 Installation\n\nInstalling RStudio on Windows:Installing RStudio on macOS:Installing RStudio on Linux:\n\n\n\nDownload R:\n\nRStudio requires R to be installed. If you have not already done so, download and install R from the official CRAN website.\n\nDownload RStudio:\n\nVisit the RStudio Download page and select the “RStudio Desktop” version compatible with your Windows operating system.\n\nInstall RStudio:\n\nRun the downloaded RStudio installer and follow the installation wizard.\nAccept the default settings unless you have specific preferences.\n\nLaunch RStudio:\n\nAfter installation, launch RStudio from the Start menu or desktop shortcut.\n\n\n\n\n\nDownload R:\n\nIf you have not already done so, download and install R on macOS from the official CRAN website.\n\nDownload RStudio:\n\nNavigate to the RStudio Download page and choose the “RStudio Desktop” version for macOS.\n\nInstall RStudio:\n\nRun the downloaded RStudio package, and macOS will guide you through the installation process.\n\nLaunch RStudio:\n\nOpen RStudio from the Applications folder or use Spotlight to search for it.\n\n\n\n\n\nDownload R:\n\nIf you have not already done so, install R on your Linux distribution using the package manager. For example, on Ubuntu, run:\n\n\n\nsudo apt-get install r-base\n\n\nDownload RStudio:\n\nVisit the RStudio Download page and choose the appropriate RStudio Desktop version for your Linux distribution.\n\nInstall RStudio:\n\nRun the downloaded RStudio package, and follow any additional instructions based on your Linux distribution.\n\nLaunch RStudio:\n\nOpen a terminal and type rstudio to launch RStudio.\n\n\n\n\n\n\n\n2.0.3 Key Features\nRStudio offers an integrated scripting and console environment, extensive support for RMarkdown, and streamlined package management capabilities.\nI strongly encourage you to look over the RStudio user guide - particularly the Getting Started section.\n\n\n\n\n2.0.4 Overview\nVisual Studio Code (VSCode) is a versatile and extensible code editor known for its speed and efficiency. While not exclusively designed for R, it offers excellent support for the language through extensions.\n\n\n2.0.5 Installation\n\nDownload Visual Studio Code:\n\nVisit the Visual Studio Code Download page and choose the version suitable for your operating system (Windows, macOS, or Linux).\nFollow the installation instructions for your specific operating system.\n\nInstall Visual Studio Code:\n\nRun the downloaded installer and follow the installation wizard.\nAccept the default settings unless you have specific preferences.\n\nLaunch Visual Studio Code:\n\nAfter installation, launch VSCode from the Start menu or applications folder.\n\n\n\n\n2.0.6 Setting Up R Support in Visual Studio Code:\n\nInstall R Extension:\n\nOpen VSCode and go to the Extensions view by clicking on the square icon on the sidebar or using the shortcut Ctrl+Shift+X.\nSearch for “R” in the Extensions view search box.\nInstall the “R Language” extension provided by Yuki Ueda.\n\nConfigure R Path (Optional):\n\nOpen the VSCode settings by pressing Ctrl+, or navigating to File &gt; Preferences &gt; Settings.\nClick on the “Open Settings (JSON)” icon in the upper-right corner of the Settings tab.\nAdd the following JSON configuration to set the path to your R executable:\n\n\n\n\"r.rpath.windows\": \"C:\\\\Program Files\\\\R\\\\R-4.x.x\\\\bin\\\\x64\\\\R.exe\",  // Replace with your R path\n\n\nSelect R Interpreter:\n\nCreate or open an R script in VSCode.\nLook for the “Select an R interpreter” notification at the bottom-right corner.\nClick on “Select R Interpreter” and choose the R version you installed.\n\nInstall Required R Packages:\n\nOpen the integrated terminal in VSCode using Ctrl+` .\nInstall the necessary R packages (e.g., languageserver and formatR) by running the following commands:\n\n\n\ninstall.packages(\"languageserver\")\ninstall.packages(\"formatR\")\n\n\nReload Window:\n\nAfter configuring R support, it’s recommended to reload the VSCode window to apply the changes.\n\nVerify R Support:\n\nOpen R Script:\n\nCreate or open an R script (.R file) in VSCode.\n\nCheck R Features:\n\nVerify that R features such as syntax highlighting, code completion, and linting are functioning correctly.\n\nRun R Script:\n\nRun parts of your R script or the entire script to ensure that the R interpreter is correctly executing code.\n\n\n\n\n\n2.0.7 Key Features\nVSCode is lightweight, supports the R Language Server, and can be enhanced with various extensions to meet specific development needs.\n\n\n\n\n2.0.8 Overview\nEmacs is a highly customizable and extensible text editor renowned for its versatility. It may have a steeper learning curve, but its power lies in its ability to adapt to individual preferences.\n\n\n2.0.9 Installation\n\nDownload and Install Emacs:\n\nVisit the GNU Emacs Download page and select the appropriate version for your operating system (Windows, macOS, or Linux).\nFollow the installation instructions provided on the download page.\n\nLaunch Emacs:\n\nAfter installation, launch Emacs. On Windows, you can find it in the Start menu. On macOS and Linux, open a terminal and type emacs.\nConfiguring Emacs for R Support:\n\nInstall ESS (Emacs Speaks Statistics):\n\nESS is a package for Emacs that provides support for various statistical languages, including R.\nOpen Emacs and add the following to your Emacs configuration file (usually ~/.emacs or ~/.emacs.d/init.el):\n\n\n\n;; Add MELPA repository for package installation\n(require 'package)\n(add-to-list 'package-archives '(\"melpa\" . \"https://melpa.org/packages/\") t)\n(package-initialize)\n\n;; Install ESS package\n(unless (package-installed-p 'ess)\n  (package-refresh-contents)\n  (package-install 'ess))\n\n\nConfigure ESS:\n\nCustomize your Emacs configuration to set up ESS for R. Add the following lines to your configuration file:\n\n\n\n;; Configure ESS for R\n(require 'ess-site)\n\n\nSelect R Interpreter:\n\nOpen an R script in Emacs. ESS should automatically detect your R installation.\nIf needed, customize the R interpreter by adding the following line to your configuration file:\n\n\n\n(setq inferior-R-program-name \"/path/to/R\")\n\n\nUseful Keybindings (Optional):\n\nAdd keybindings for common ESS commands. For example:\n\n\n\n(global-set-key (kbd \"C-c C-k\") 'ess-eval-buffer)\n(global-set-key (kbd \"C-c C-r\") 'ess-eval-region)\n\n\nESS Documentation (Optional):\n\nAccess ESS documentation by typing C-h i to open the Info viewer, then select “ESS” from the menu.\n\nReload Configuration:\n\nAfter making changes to your Emacs configuration, restart Emacs or use M-x load-file to reload the configuration.\n\nVerify R Support:\n\nOpen R Script:\n\nCreate or open an R script (.R file) in Emacs.\n\nCheck ESS Features:\n\nVerify that ESS features such as syntax highlighting, code evaluation, and interaction with R are functioning correctly.\n\nRun R Script:\n\nEvaluate parts of your R script or the entire script to ensure that the R interpreter is correctly executing code.\n\n\n\n\n\n2.0.10 Key Features\nEmacs supports extensive extensibility through packages, boasts ESS (Emacs Speaks Statistics) for R integration, and offers Org Mode for literate programming.\n\n\n\n\n2.0.11 Overview\nNeovim is a modern and extensible text editor that builds on the foundation of Vim. It combines the efficiency of Vim with additional features for a more contemporary editing experience.\n\n\n2.0.12 Installation\n\nDownload and Install Neovim:\n\nVisit the Neovim GitHub Releases page and download the installer appropriate for your operating system (Windows, macOS, or Linux).\nFollow the installation instructions provided on the GitHub page.\n\nLaunch Neovim:\n\nAfter installation, launch Neovim. On Windows, you can find it in the Start menu or use the executable. On macOS and Linux, open a terminal and type nvim.\n\nConfiguring Neovim for R Support:\n\nInstall a Plugin Manager (Optional):\n\nWhile optional, using a plugin manager makes it easier to manage Neovim plugins. Popular choices include vim-plug and dein.vim.\nFollow the installation instructions provided by the chosen plugin manager.\n\n\nInstall Nvim-R Plugin:\n\nNvim-R is a plugin that enhances Neovim for R development.\nAdd the following lines to your Neovim configuration file (usually ~/.config/nvim/init.vim or ~/.vimrc):\n\n\n\n\" For vim-plug\nPlug 'jalvesaq/Nvim-R'\n\n\" For dein.vim\ncall dein#add('jalvesaq/Nvim-R')\n\n\nConfigure Nvim-R:\n\nCustomize your Neovim configuration to set up Nvim-R for R. Add the following lines to your configuration file:\n\n\n\n\" Set the path to your R executable (replace with your actual path)\nlet g:vimrplugin_Rexecutable = '/path/to/R'\n\n\" Enable filetype plugin and indentation\nfiletype plugin indent on\n\n\" Set R as the default file type for .R files\nau BufNewFile,BufRead *.R set filetype=r\n\n\nInstall Plugins:\n\nOpen Neovim and run the command to install the configured plugins:\n\nFor vim-plug: :PlugInstall\nFor dein.vim: :call dein#install()\n\n\nReload Configuration:\n\nAfter adding the configuration, restart Neovim or use :source % to reload the configuration.\n\nVerify R Support:\n\nOpen R Script:\n\nCreate or open an R script (.R file) in Neovim.\n\nCheck Nvim-R Features:\n\nVerify that Nvim-R features, such as syntax highlighting, code evaluation, and interaction with R, are functioning correctly.\n\nRun R Script:\n\nEvaluate parts of your R script or the entire script to ensure that the R interpreter is correctly executing code.\n\n\n\n\n\n2.0.13 Key Features\nNeovim maintains Vim compatibility, supports plugins for extended functionality, and emphasizes efficient text editing.\n\n\n\n\n2.0.14 Overview\nSublime Text is a lightweight yet feature-rich text editor appreciated for its speed and simplicity. While not R-specific, it offers a customizable environment suitable for various programming languages.\n\n\n2.0.15 Installation\n\nDownload and Install Sublime Text:\n\nVisit the Sublime Text Download page and download the installer for your operating system (Windows, macOS, or Linux).\nFollow the installation instructions provided on the website.\n\nLaunch Sublime Text:\n\nAfter installation, launch Sublime Text. You can find it in the Start menu on Windows, in the Applications folder on macOS, or by using the terminal on Linux.\n\nConfiguring Sublime Text for R Support:\n\nInstall Package Control:\n\nPackage Control is a package manager for Sublime Text. Follow the installation instructions on the Package Control website.\n\nInstall Terminus Package:\n\nOpen Sublime Text and press Ctrl+Shift+P (Windows/Linux) or Cmd+Shift+P (macOS) to open the command palette.\nType “Install Package” and select “Package Control: Install Package.”\nSearch for “Terminus” and install the package.\n\nInstall R:\n\nMake sure you have R installed on your system. You can download it from the official R website.\n\nConfigure Terminus for R:\n\nOpen Sublime Text and create or open an R script (.R file).\nPress Ctrl+ (Windows/Linux) or Cmd+ (macOS) to open the Terminus console.\nIn the Terminus console, type the following command to start an R session:\n\n\n\n\nR\n\n- Terminus will open a new terminal at the bottom of Sublime Text,\n  providing an interactive R session.\n- Create Build System (Optional):\n  - You can create a custom build system for R scripts to simplify\n    execution.\n    - Open a new file in Sublime Text and paste the following JSON\n      configuration:\n\n{\n    \"cmd\": [\"R\", \"--slave\", \"--vanilla\", \"-f\", \"$file\"],\n    \"file_regex\": \"^(?:(...*?):([0-9]+):([0-9]+)|(...*?))$\",\n    \"selector\": \"source.R\"\n}\n\n    - Save the file with the extension .sublime-build in the\n      \"User\" directory of your Sublime Text \"Packages\" folder. You\n      can find this folder by selecting \"Preferences\" &gt; \"Browse\n      Packages...\" in Sublime Text.\n  - Run R Script:\n    - Open an R script in Sublime Text.\n    - Use the Terminus console to interact with the R session and\n      execute commands.\n\n\n2.0.16 Key Features\nSublime Text boasts multiple cursors, supports extensions through Package Control, and provides ample customization options."
  },
  {
    "objectID": "03_data_frames.html",
    "href": "03_data_frames.html",
    "title": "Data frames",
    "section": "",
    "text": "Step 1\nBefore beginning this tutorial, we should make sure we have all the tools in place. We will therefore start by installing the tidyverse ecosystem of packages. Among the many packages included under this umbrella are the packages readr, readxl and tibble - each of which will be used in this tutorial.\nIn addition, the foreign package supports importing data from other statistical software (such as Sas, Stata, Systat, System and Minitab).\nLet start by installing the tidyverse ecosystem of packages along with foreign.\n\npak::pkg_install(\"tidyverse\")\npak::pkg_install(\"foreign\")\n\nNow we will load these packages so that they are available for the rest of the session.\n\nlibrary(tidyverse)\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ ggplot2   3.4.4     ✔ tibble    3.2.1\n✔ lubridate 1.9.3     ✔ tidyr     1.3.0\n✔ purrr     1.0.2     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\nlibrary(foreign)\n\n\n\n\n\n\n\nNote\n\n\n\nNotice in the above output, when we load the tidyverse package, some validation steps are performed to indicate which actual packages were loaded. Importantly, notice also that a couple of conflicts are identified. The first of these dplyr::filter() masks stats::filter() indicates that once the dplyr package was loaded the previous definition of a function called filter (from the stats package) was overwritten (masked) by a definition contained wihin the dplyr package.\nThis is not an error. Rather, it is a warning to advise that if you were expecting to call the filter function and were expecting to get the behaviour defined within the stats package, then you should preface the call with the stats namespace. For example, call stats::filter() rather than just filter().\nNo such issues arose when loading the foreign package.\n\n\nStep 2\nThe second necessary preparation is to prepare the file system for a tidy working environment. Rather than place all R scripts, data and outputs into a single (increasingly cluttered folder), it is always better to organise your project into a set number of folders. For this tutorial, I would recommend setting up the following structure.\n../\n|-- data\n|-- scripts\nNow within your chosen editor, I suggest you create an R script within the scripts folder and set this path as the working directory.\nStep 3\nThe final preparation step is to download some data files to use during this tutorial. These files should be placed in the data folder. Each of the files are abbreviated versions of the same Mac Nally (1996) data set, yet each is in a different format (some are text files, others are in formats of other software). Each format is listed below, along with a link to manually access the data and an R code snippet that will download the file and place it in the ../data folder.\n\nmacnally.csv: a comma separated format\n\ndownload.file('https://github.com/ReefCloud/workshops/tree/main/data/macnally.csv', '../data/macnally.csv')\n\nmacnally.txt: a tab separated format\n\ndownload.file('https://github.com/ReefCloud/workshops/tree/main/data/macnally.txt', '../data/macnally.txt')\n\nmacnally.xlsx: an excel workbook format\n\ndownload.file('https://github.com/ReefCloud/workshops/tree/main/data/macnally.xlsx', '../data/macnally.xlsx')"
  },
  {
    "objectID": "03_data_frames.html#data.frame",
    "href": "03_data_frames.html#data.frame",
    "title": "Data frames",
    "section": "2.1 data.frame",
    "text": "2.1 data.frame\nData frames are generated by amalgamating vectors of the same length together. To illustrate the translation of a data set (collection of variables) into an R data frame (collection of vectors), a portion of a real data set by Mac Nally (1996) in which the bird communities were investigated from 37 sites across five habitats in southeastern Australia will be used. Although the original data set includes the measured maximum density of 102 bird species from the 37 sites, for simplicity’s sake only two bird species (GST: gray shrike thrush, EYR: eastern yellow robin) and the first eight of the sites will be included. The truncated data set, comprises a single factorial (or categorical) variable, two continuous variables, and a set of site (row) names, and is as follows:\n\n\n\n\nSite\nHABITAT\nGST\nEYR\n\n\n\n\nReedy Lake\nMixed\n3.4\n0.0\n\n\nPearcedale\nGipps.Manna\n3.4\n9.2\n\n\nWarneet\nGipps.Manna\n8.4\n3.8\n\n\nCranbourne\nGipps.Manna\n3.0\n5.0\n\n\nLysterfield\nMixed\n5.6\n5.6\n\n\nRed Hill\nMixed\n8.1\n4.1\n\n\nDevilbend\nMixed\n8.3\n7.1\n\n\nOlinda\nMixed\n4.6\n5.3\n\n\n\nFirstly, we will generate the three variables (excluding the site labels as they are not variables) separately:\n\nhabitat &lt;- factor(c('Mixed', 'Gipps.Manna', 'Gipps.Manna', 'Gipps.Manna', 'Mixed',\n  'Mixed', 'Mixed', 'Mixed'))\ngst &lt;- c(3.4, 3.4, 8.4, 3.0, 5.6, 8.1, 8.3, 4.6)\neyr &lt;- c(0.0, 9.2, 3.8, 5.0, 5.6, 4.1, 7.1, 5.3)\n\nNext, use the list the names of the vectors as arguments in the data.frame() function to amalgamate the three separate variables into a single data frame (data set) which we will call macnally (after the author).\n\nmacnally &lt;- data.frame(habitat, gst, eyr)\nmacnally\n\n      habitat gst eyr\n1       Mixed 3.4 0.0\n2 Gipps.Manna 3.4 9.2\n3 Gipps.Manna 8.4 3.8\n4 Gipps.Manna 3.0 5.0\n5       Mixed 5.6 5.6\n6       Mixed 8.1 4.1\n7       Mixed 8.3 7.1\n8       Mixed 4.6 5.3\n\n\nNotice that each vector (variable) becomes a column in the data frame and that each row represents a single sampling unit (in this case, each row represents a different site). By default, the rows are named using numbers corresponding to the number of rows in the data frame. However, these can be altered to reflect the names of the sampling units by assigning a list of alternative names to the row.names() (data frame row names) property of the data frame.\n\nrow.names(macnally) &lt;- c('Reedy Lake', 'Pearcedale', 'Warneet', 'Cranbourne',\n  'Lysterfield', 'Red Hill', 'Devilbend', 'Olinda')\nmacnally\n\n                habitat gst eyr\nReedy Lake        Mixed 3.4 0.0\nPearcedale  Gipps.Manna 3.4 9.2\nWarneet     Gipps.Manna 8.4 3.8\nCranbourne  Gipps.Manna 3.0 5.0\nLysterfield       Mixed 5.6 5.6\nRed Hill          Mixed 8.1 4.1\nDevilbend         Mixed 8.3 7.1\nOlinda            Mixed 4.6 5.3"
  },
  {
    "objectID": "03_data_frames.html#expand.grid",
    "href": "03_data_frames.html#expand.grid",
    "title": "Data frames",
    "section": "2.2 expand.grid",
    "text": "2.2 expand.grid\nWhen the data set contains multiple fully crossed categorical variables (factors), the expand.grid() function provides a convenient way to create the factor vectors.\n\nexpand.grid(rep = 1:4, \n  B = paste(\"b\", 1:2, sep = \"\"), \n  A = paste(\"a\", 1:3, sep = \"\")\n)\n\n   rep  B  A\n1    1 b1 a1\n2    2 b1 a1\n3    3 b1 a1\n4    4 b1 a1\n5    1 b2 a1\n6    2 b2 a1\n7    3 b2 a1\n8    4 b2 a1\n9    1 b1 a2\n10   2 b1 a2\n11   3 b1 a2\n12   4 b1 a2\n13   1 b2 a2\n14   2 b2 a2\n15   3 b2 a2\n16   4 b2 a2\n17   1 b1 a3\n18   2 b1 a3\n19   3 b1 a3\n20   4 b1 a3\n21   1 b2 a3\n22   2 b2 a3\n23   3 b2 a3\n24   4 b2 a3"
  },
  {
    "objectID": "03_data_frames.html#as_tibble",
    "href": "03_data_frames.html#as_tibble",
    "title": "Data frames",
    "section": "2.3 as_tibble",
    "text": "2.3 as_tibble\nTibbles are a modern re-imagining of data frames in R that focus on clarity, consistency, and user-friendliness. While both data frames and tibbles both hold data in rows and columns, tibbles introduce several key differences:\n\nPreserved Data Types: Unlike data frames which coerce strings to factors, tibbles maintain the original data types, facilitating accurate analysis and avoiding surprises.\nExplicit Naming: Column names are always strings, preventing unintentional creation of numeric or logical variables.\nImproved Printing: Tibbles display a concise overview, presenting only the first 10 rows and all fitting columns to screen, making exploration more efficient.\nStreamlined Subsetting: Accessing specific columns is simpler and safer, minimizing potential errors related to partial matching.\n\nThe as_tibble function converts a data frame into a tibble.\n\nmacnally.tbl &lt;- as_tibble(macnally)\nmacnally.tbl\n\n# A tibble: 8 × 3\n  habitat       gst   eyr\n  &lt;fct&gt;       &lt;dbl&gt; &lt;dbl&gt;\n1 Mixed         3.4   0  \n2 Gipps.Manna   3.4   9.2\n3 Gipps.Manna   8.4   3.8\n4 Gipps.Manna   3     5  \n5 Mixed         5.6   5.6\n6 Mixed         8.1   4.1\n7 Mixed         8.3   7.1\n8 Mixed         4.6   5.3\n\n\nSince the example data set is so small, there is no appreciable difference in how it is presented as either a data frame or a tibble. It is mainly when the data sets get larger that the distinctions become more apparent."
  },
  {
    "objectID": "03_data_frames.html#tribble",
    "href": "03_data_frames.html#tribble",
    "title": "Data frames",
    "section": "2.4 tribble",
    "text": "2.4 tribble\nThe tribble() function allows us to construct tibbles directly.\n\nmacnally.tbl &lt;- tribble(\n  ~habitat, ~gst, ~eyr,\n  \"Mixed\", 3.4, 0.0,\n  \"Gipps.Manna\", 3.4, 9.2,\n  \"Gipps.Manna\", 8.4, 3.8,\n  \"Gipps.Manna\", 3.0, 5.0,\n  \"Mixed\", 5.6, 5.6,\n  \"Mixed\", 8.1, 4.1,\n  \"Mixed\", 8.3, 7.1,\n  \"Mixed\", 4.6, 5.3,\n  )\nmacnally.tbl\n\n# A tibble: 8 × 3\n  habitat       gst   eyr\n  &lt;chr&gt;       &lt;dbl&gt; &lt;dbl&gt;\n1 Mixed         3.4   0  \n2 Gipps.Manna   3.4   9.2\n3 Gipps.Manna   8.4   3.8\n4 Gipps.Manna   3     5  \n5 Mixed         5.6   5.6\n6 Mixed         8.1   4.1\n7 Mixed         8.3   7.1\n8 Mixed         4.6   5.3\n\n\nNote that the construction of tibbles like this more closely resembles the eventual structure of the data. Compare this to the way data frames are constructed (by combining individual vectors)."
  },
  {
    "objectID": "03_data_frames.html#importing-from-text-file",
    "href": "03_data_frames.html#importing-from-text-file",
    "title": "Data frames",
    "section": "3.1 Importing from text file",
    "text": "3.1 Importing from text file\nThe easiest form of importation is from a pure text file. Since most software that accepts file input can read plain text files, text files can be created in all spreadsheet, database and statistical software packages and are also the default outputs of most data collection devices.\nIn a text file, data are separated (or delimited) by a specific character, which in turn defines what sort of text file it is. The text file should broadly represent the format of the data frame.\n\nvariables should be in columns and sampling units in rows. the first\nrow should contain the variable names and if there are row names, these should be in the first column\n\nThe following examples illustrate the format of the abbreviated Mac Nally (1996) data set created as both comma delimited (left) and tab delimited (right) files as well as the corresponding read.table() commands used to import the files.\n\n\n\n\n\n\nNote\n\n\n\nThe following examples assume that the above data will be in the current working directory. If the current working directory (which can be checked with the getwd() function) does not contain these files, then either:\n\ninclude the full path name (or path relative to the current working directory) as the filename argument\nchange the current working directory of your session prior to continuing (use the setwd() function)\ncopy and paste the files into the current working directory.\n\n\n\n\n\nComma delimited text file .csv\n\nLOCATION,HABITAT,GST,EYR\nReedy Lake,Mixed,3.4,0.0\nPearcedale,Gipps.Manna,3.4,9.2\nWarneet,Gipps.Manna,8.4,3.8\nCranbourne,Gipps.Manna,3.0,5.0\n....\n\n\nmacnally_new &lt;- read_csv(\"../data/macnally.csv\", \n  trim_ws = TRUE)\n\nRows: 37 Columns: 4\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (2): LOCATION, HABITAT\ndbl (2): GST, EYR\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\nmacnally_new\n\n# A tibble: 37 × 4\n   LOCATION      HABITAT              GST   EYR\n   &lt;chr&gt;         &lt;chr&gt;              &lt;dbl&gt; &lt;dbl&gt;\n 1 Reedy Lake    Mixed                3.4   0  \n 2 Pearcedale    Gipps.Manna          3.4   9.2\n 3 Warneet       Gipps.Manna          8.4   3.8\n 4 Cranbourne    Gipps.Manna          3     5  \n 5 Lysterfield   Mixed                5.6   5.6\n 6 Red Hill      Mixed                8.1   4.1\n 7 Devilbend     Mixed                8.3   7.1\n 8 Olinda        Mixed                4.6   5.3\n 9 Fern Tree Gum Montane Forest       3.2   5.2\n10 Sherwin       Foothills Woodland   4.6   1.2\n# ℹ 27 more rows\n\n\n\n\n\nTab delimited text file .txt\n\nLOCATION    HABITAT     GST EYR\nReedy Lake  Mixed       3.4 0.0\nPearcedale  Gipps.Manna 3.4 9.2\nWarneet     Gipps.Manna 8.4 3.8\nCranbourne  Gipps.Manna 3.0 5.0\n....\n\n\nmacnally_new &lt;- read_tsv(\"../data/macnally.txt\", \n  trim_ws = TRUE)\n\nRows: 37 Columns: 4\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \"\\t\"\nchr (2): LOCATION, HABITAT\ndbl (2): GST, EYR\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\nmacnally_new \n\n# A tibble: 37 × 4\n   LOCATION      HABITAT              GST   EYR\n   &lt;chr&gt;         &lt;chr&gt;              &lt;dbl&gt; &lt;dbl&gt;\n 1 Reedy Lake    Mixed                3.4   0  \n 2 Pearcedale    Gipps.Manna          3.4   9.2\n 3 Warneet       Gipps.Manna          8.4   3.8\n 4 Cranbourne    Gipps.Manna          3     5  \n 5 Lysterfield   Mixed                5.6   5.6\n 6 Red Hill      Mixed                8.1   4.1\n 7 Devilbend     Mixed                8.3   7.1\n 8 Olinda        Mixed                4.6   5.3\n 9 Fern Tree Gum Montane Forest       3.2   5.2\n10 Sherwin       Foothills Woodland   4.6   1.2\n# ℹ 27 more rows\n\n\n\n\nIn the above, the trim_ws = TRUE argument indicates that leading and trailing spaces should be removed from all the data. This is important as often spreadsheets (I’m looking at you Excel), add spaces before or after words (in particular). These are invisible, yet can cause huge headaches when running analyses or graphing..\nThe read_csv and read_tzv functions provide feedback about what they have imported. Specifically, they list the number of rows and columns, what the delimeting character is and the data type assigned to each field (variable/column).\nThe data are imported as a tibble.\nThere are numerous ways to specify the filename.\n\nusing full paths\n\nmacnally_new &lt;- read_csv(\"/home/Project/data/macnally.csv\", trim_ws = TRUE)\n\n\n\n\n\n\n\nNote\n\n\n\nIn the above example, the full path used was appropriate for the machine that the code was run on. However, it is unlikely to reflect a valid path on your machine. You may want to adjust it accordingly.\n\n\nusing relative paths\n\nmacnally_new &lt;- read_csv(\"../data/macnally.csv\", trim_ws = TRUE)\n\n\n\n\n\n\n\nNote\n\n\n\nRecall that ../data/ means navigate out of the current directory and into the data directory.\n\n\nusing ULRs\n\nmacnally_new &lt;- read_csv(url(\"https://github.com/ReefCloud/workshops/tree/main/data/macnally.csv\"), trim_ws = TRUE)\n\nIn the above example, the data are accessed directly from a remote location."
  },
  {
    "objectID": "03_data_frames.html#importing-from-the-clipboard",
    "href": "03_data_frames.html#importing-from-the-clipboard",
    "title": "Data frames",
    "section": "3.2 Importing from the clipboard",
    "text": "3.2 Importing from the clipboard\nThe read_tsv() function can also be used to import data (into a tibble) that has been placed on the clipboard by other software, thereby providing a very quick and convenient way of obtaining data from spreadsheets. Simply replace the filename argument with the clipboard() function. For example, to import data placed on the clipboard from Microsoft Excel, select the relevant cells, click copy and then in R, use the following syntax;\n\nmacnally_new &lt;- read_tsv(clipboard(), trim_ws = TRUE)\n\n\n\n\n\n\n\nWarning\n\n\n\nAlthough importing data from the clipboard can be convenient for quickly exploring something, it should mostly be discouraged from a reproducibility perspective:\n\nwhen such code is included in a script, the script will just import whatever is present on the clipboard at the time - which may or may not be what you expect it to be\nthere is no way to record the providence of the data because it is not pointing to a specific file or source."
  },
  {
    "objectID": "03_data_frames.html#importing-from-excel",
    "href": "03_data_frames.html#importing-from-excel",
    "title": "Data frames",
    "section": "3.3 Importing from Excel",
    "text": "3.3 Importing from Excel\nMicrosoft Excel is more than just a spreadsheet, it can contain macros, formulae, multiple worksheets and formatting. There are numerous ways to import xlsx files into R, yet depending on the complexity of the original files, the translations can be incomplete and inconsistent.\nOne of the easiest and safest ways to import data from Excel is either to save the worksheet as a text file (comma or tab delimited) and import the data as a text file (see above), or to copy the data to the clipboard in Excel and import the clipboard data into R.\nNevertheless, it is also possible to directly import a sheet from an excel workbook. Tidyverse includes a package called readxl, however as it is not one of the ‘core’ packages, it is not automatically loaded as part of the ecosystem when the tidyverse package is loaded. Hence to use the readxl package, it must be explicitly loaded.\n\nlibrary(readxl)\nmacnally_new &lt;- read_xlsx(\"../data/macnally.xlsx\", sheet = \"macnally\", trim_ws = TRUE)"
  },
  {
    "objectID": "03_data_frames.html#summary",
    "href": "03_data_frames.html#summary",
    "title": "Data frames",
    "section": "4.1 summary()",
    "text": "4.1 summary()\nThe summary() function is an overloaded function whose behaviour depends on the object passed to the function. When summary() is called with a data.frame, a summary is provided in which:\n\nnumeric vectors (variables) are summarized by the standard 5 number statistics and if there are any missing values, the number of missing values is also provided\ncategorical (factors) vectors are tallied up - that is, the number of instances of each level are counted.\nboolean states are also tallied\ncharacter vectors are only described by their length\ndate (and POSIX) vectors are summarized by 5 number summaries\n\n\nsummary(macnally)\n\n        habitat       gst            eyr           bool        \n Gipps.Manna:3   Min.   :3.00   Min.   :0.000   Mode :logical  \n Mixed      :5   1st Qu.:3.40   1st Qu.:4.025   FALSE:4        \n                 Median :5.10   Median :5.150   TRUE :4        \n                 Mean   :5.60   Mean   :5.013                  \n                 3rd Qu.:8.15   3rd Qu.:5.975                  \n                 Max.   :8.40   Max.   :9.200                  \n     char                date           \n Length:8           Min.   :2000-02-29  \n Class :character   1st Qu.:2000-03-18  \n Mode  :character   Median :2000-04-05  \n                    Mean   :2000-04-05  \n                    3rd Qu.:2000-04-23  \n                    Max.   :2000-05-12"
  },
  {
    "objectID": "03_data_frames.html#str",
    "href": "03_data_frames.html#str",
    "title": "Data frames",
    "section": "4.2 str()",
    "text": "4.2 str()\nSimilar to summary(), the str() function is an overloaded. The str() function generally produces a compact view of the structure of an object. When str() is called with a data.frame, this compact view comprises a nested list of abbreviated structures.\n\nstr(macnally)\n\n'data.frame':   8 obs. of  6 variables:\n $ habitat: Factor w/ 2 levels \"Gipps.Manna\",..: 2 1 1 1 2 2 2 2\n $ gst    : num  3.4 3.4 8.4 3 5.6 8.1 8.3 4.6\n $ eyr    : num  0 9.2 3.8 5 5.6 4.1 7.1 5.3\n $ bool   : logi  TRUE FALSE TRUE FALSE TRUE FALSE ...\n $ char   : chr  \"Large\" \"Small\" \"Large\" \"Small\" ...\n $ date   : Date, format: \"2000-02-29\" \"2000-03-10\" ..."
  },
  {
    "objectID": "03_data_frames.html#glimpse",
    "href": "03_data_frames.html#glimpse",
    "title": "Data frames",
    "section": "4.3 glimpse()",
    "text": "4.3 glimpse()\nThe glimpse() function in the tibble package is similar to str() except that it attempts to maximize the amount of data displayed according to the dimensions of the output.\n\nglimpse(macnally)\n\nRows: 8\nColumns: 6\n$ habitat &lt;fct&gt; Mixed, Gipps.Manna, Gipps.Manna, Gipps.Manna, Mixed, Mixed, Mi…\n$ gst     &lt;dbl&gt; 3.4, 3.4, 8.4, 3.0, 5.6, 8.1, 8.3, 4.6\n$ eyr     &lt;dbl&gt; 0.0, 9.2, 3.8, 5.0, 5.6, 4.1, 7.1, 5.3\n$ bool    &lt;lgl&gt; TRUE, FALSE, TRUE, FALSE, TRUE, FALSE, TRUE, FALSE\n$ char    &lt;chr&gt; \"Large\", \"Small\", \"Large\", \"Small\", \"Large\", \"Small\", \"Large\",…\n$ date    &lt;date&gt; 2000-02-29, 2000-03-10, 2000-03-20, 2000-03-31, 2000-04-10, 20…"
  },
  {
    "objectID": "03_data_frames.html#others",
    "href": "03_data_frames.html#others",
    "title": "Data frames",
    "section": "4.4 Others",
    "text": "4.4 Others\nThere are also numerous graphical methods including view() and fix(), however, I have focused on the script friendly routines. As the graphical routines require user input, they are inappropriate to include in scripts.\nWithin Rstudio, a data frame can be viewed like a spreadsheet. To view the data this way, click on the name of the data frame within the Environment pane. Furthermore, when in R Notebook mode, a simple functioning spreadsheet will be embedded within the notebook."
  },
  {
    "objectID": "03_data_frames.html#saverdsreadrds",
    "href": "03_data_frames.html#saverdsreadrds",
    "title": "Data frames",
    "section": "6.1 saveRDS/readRDS",
    "text": "6.1 saveRDS/readRDS\nFor example:\n\n## save just the macnally data frame to the data folder\nsaveRDS(macnally, file = \"../data/macnally.rds\")\n\nThis will save a single object in a compressed format.\nThe saved object(s) can be loaded during subsequent sessions by providing the name of the saved workspace image file as an argument to the load() function. For example:\n\nmacnally &lt;- readRDS(\"../data/macnally_stats.rds\")"
  },
  {
    "objectID": "03_data_frames.html#saveload",
    "href": "03_data_frames.html#saveload",
    "title": "Data frames",
    "section": "6.2 save/load",
    "text": "6.2 save/load\nWhen you want to save multiple objects, the save() function is convenient. This stores multiple objects in a binary (non-compressed) format.\n\n## save just the macnally data frame to the data folder\nsave(macnally, file = \"../data/macnally.RData\")\n## calculate the mean gst\nmean_gst &lt;- mean(macnally$gst)\n## display the mean gst\nmean_gst\n## save the macnally data frame as well as the mean gst object\nsave(macnally, mean_gst, file = \"../data/macnally_stats.RData\")\n\nThe saved object(s) can be loaded during subsequent sessions by providing the name of the saved workspace image file as an argument to the load() function. For example:\n\nload(\"../data/macnally_stats.RData\")\n\nNote, the load() reads the object(s) into the current environment with each object being assigned the names they were originally assigned when they were saved."
  },
  {
    "objectID": "03_data_frames.html#dump",
    "href": "03_data_frames.html#dump",
    "title": "Data frames",
    "section": "6.3 dump",
    "text": "6.3 dump\nSimilarly, a straight un-encoded text version of an object (including dataframes and tibbles) can be saved or added to a text file (such as an R script) using the dump() function.\n\ndump(\"macnally\", file = \"../data/macnally\")\n\nIf the file character string is left empty, the text representation of the object will be written to the console. This output can then be viewed or copied and pasted into a script file, thereby providing a convenient way to bundle together data sets along with graphical and analysis commands that act on the data sets. It can even be used to paste data into an email.\n\ndump(\"macnally\", file = \"\")\n\nThereafter, the dataset is automatically included when the script is sourced and cannot accidentally become separated from the script."
  },
  {
    "objectID": "04_data_wrangling.html",
    "href": "04_data_wrangling.html",
    "title": "Data wrangling (tidyverse and friends)",
    "section": "",
    "text": "I apologize in advance, this tutorial requires quite a bit of explaining and context before it can get into the code…. Good data manipulation is an art form that requires the use of many specific tools (functions) and expert data manipulation comes from the integration of these tools together. Therefore it is necessary to have an overview of the tool set before investigating any single tool."
  },
  {
    "objectID": "04_data_wrangling.html#the-grammar-of-data-manipulation",
    "href": "04_data_wrangling.html#the-grammar-of-data-manipulation",
    "title": "Data wrangling (tidyverse and friends)",
    "section": "2.1 The grammar of data manipulation",
    "text": "2.1 The grammar of data manipulation\nHadley and his collaborators argue that there is a grammar of data manipulation and that manipulations comprises a set of verbs. Furthermore, the philosophy adheres to the UNIX ideal that rather than attempt to build large complex tools that perform a large set of operations, it is better (with regards to usability and robustness) to build a tool set in which each tool performs a single, specific task and that the individual tools can be bolted together to achieve the complex operations.\nThe core of the tidyverse data manipulation ecosystem tools (verbs) can be organised into five categories within two types on the basis of what aspects of the data they operate on:\n\noperate on a single data set\n\noperate on the rows\n\ndplyr::arrange - changing the order of the rows (sorting)\ndplyr::filter - subset of rows based on column values\ndplyr::slice - subset of rows based on position\n\noperate on the columns\n\ndplyr::select - subset of columns\ndplyr::rename - change the names of columns\ndplyr::pull - extract a single column as a vector\ndplyr::distinct - unique combinations of column values\ndplyr::mutate - adding columns and modifying column values\ntidyr::unite - combine multiple columns together\ntidyr::separate - separating a single column into multiple columns\n\noperate on groups of columns\n\ndplyr::summarise - aggregating (collapsing) to a single row\ndplyr::count - count the number of unique combinations single row\ndplyr::group_by - define groups of rows\n\nreshapes (pivots) the data\n\ntidyr::pivot_longer - lengthen data from wide format\ntidyr::pivot_wider - widen data from long format\n\n\noperate of two data sets\n\n_join - merge (join) two data sets together based on common field(s)\n\n\nIn base R, variables (columns) are referred to by either their name (as a prefix to the environment - the data.frame etc), name (as a string) or their index (position). For example to access a variable called “Var1” within a dataset called “data”, we could use either data$Var1, data[,\"Var1\"] or data[,1] (if the focal variable was in the first column).\nThe tidyverse ecosystem adopts an alternative concept called tidy evaluation to make referring to columns more flexible.\n\ndata-masking - refer to variables as if they were directly attached to the current environment (e.g. Var1 instead of data$Var1. This form of variable referral is used within:\n\narrange()\nfilter()\ncount()\nmutate()\nsummarise()\ngroup_by()\n\ntidy selection - refer to variables by their position, name or type (e.g. starts_with(\"var\")). This form of variable referral is used within:\n\nselect()\nrename()\npull()\nacross() - which brings tidy selection semantics to data-masking (and thus functions like mutate())\n\nThe following table highlights the various tidy-selection options. The examples all illustrate a hypothetical data set (data) with hypothetical columns (Var1, Var2, etc) and cannot be evaluated directly. They all mostly illustrate the concept using the select() function.\n\n\n\n\n\n\ntidy-selection\n\n\nDescription\n\n\nExamples\n\n\n\n\n\n\nBare names\n\n\nSelect columns based on their names.Columns can be excluded by prepending the name with a negative sign (-).\n\n\n\nselect(data, Var1)\n\n\nselect(data, Var1, Var2)\n\n\nselect(data, c(Var1, Var2))\n\n\nselect(data, -Var1)\n\n\n\n\n\nRanges of columns\n\n\nSelect columns based on their a range of names or column numbers. The selections will be inclusive. Prepending with a negative sign (-) acts as an exclusion.\n\n\n\nselect(data, Var1:Var3)\n\n\nselect(data, 2:4)\n\n\n\n\n\nBoolean helper functions -contains() -starts_with() -ends_with() -matches() -num_range() -everything() -where() -all_of() -any_of()\n\n\nSelect columns based on evaluating functions on the column names - contains() - names containing the string - starts_with() - names starting with the string - ends_with() - names starting with the string - matches() - names matched with a regex - num_range() - names that start with string followed by numbers - everything() - all variables - useful in combination with other selections - where() - variable inclusion predicated by a function - all_of() - all variables included in a character vector - any_of() - any variables included in a character vector Each of the above can be reversed by prepending with either a exclamation sign (!) or negative sign (-). Also note that by default, these are not case sensitive.\n\n\n\nselect(data, contains(\"Var\"))\n\n\nselect(data, !contains(\"Var\"))\n\n\nselect(data, starts_with(\"Var\"))\n\n\nselect(data, ends_with(\"Var\"))\n\n\nselect(data, matches(\"^.var[1-5]$\"))\n\n\nselect(data, num_range(\"Var\", 1:2))\n\n\nselect(data, Var3, everything())\n\n\nselect(data, where(is.numeric))\n\n\nvars &lt;- c(\"Var1\", \"Var2\")\nselect(data, all_of(vars))\n\n\nvars &lt;- c(\"Var1\", \"Other\")\nselect(data, any_of(vars))"
  },
  {
    "objectID": "04_data_wrangling.html#piping",
    "href": "04_data_wrangling.html#piping",
    "title": "Data wrangling (tidyverse and friends)",
    "section": "2.2 Piping",
    "text": "2.2 Piping\nTypically, data manipulation/preparations comprise multiple steps and stages in which a series of alterations, additions etc are performed sequentially such that the data are progressively molded into a form appropriate for analysis etc. That is, to achieve the desired result, we must bolt multiple tools (verbs) together.\nTraditionally, this would have involved a separate expression for each step often resulting in the generation of numerous intermediate data sets. Furthermore, in an attempt to reduce the number of intermediate steps, functions are often nested within other functions such that alterations are made inline within another function.\nFor example, the following pseudo code examples illustrates the traditional and nested approaches to achieving numerous data manipulation steps:\n\n\nTraditional\n\ndata1 &lt;- select(data, ...)\ndata2 &lt;- group_by(data1, ...)\ndata3 &lt;- summarise(data2, ...)\n\n\nNested functions\n\ndata &lt;- summarise(group_by(select(data, ...)))\n\n\n\nCollectively, these practices can yield code that is very difficult to read and interpret.\nA long honoured unix coding principle is that each application should focus on performing one action and performing that function well. In order to perform a sequence of actions therefore involves piping (via the unix pipe character |) the output of one application to the input of another application and so on in a chain. The grammar of data wrangling also adopts the principle of each tool specializing on one action and tools should be piped together to achieve a sequence of actions.\nThe piping (glue) operator in R (as of version 4.1) is |&gt;. An object on the left hand side of the |&gt; operator is passed as the first argument of the function on the right hand side.\n\n\n\n\n\n\nNative vs the magrittr (%&gt;%) pipe\n\n\n\n\n\nPrior to the native adoption of the pipe character in R, piping was supported via the magrittr package. Within this package, the pipe operator is %&gt;%. Although both the native and magrittr pipe operators are somewhat analogous, they are not homologous.\n\nSyntax:\n\nNative pipe: Simple |&gt; symbol placed between the expression and function call.\nMagrittr pipe: Double percentage signs %&gt;% offering visual distinction from surrounding code.\n\nPlaceholder:\n\nNative pipe: No built-in placeholder for piped-in values. Functions need to handle them explicitly.\nMagrittr pipe: Dot placeholder (.), allowing concise access to piped-in values within the function call.\n\nFunctionality:\n\nNative pipe: More basic functionality, primarily focused on function chaining.\nMagrittr pipe: Offers additional features like:\n\nExposition pipe (%~$%): Displays the values passed through the pipe, facilitating debugging.\nInterjection pipe (~&gt;%): Modifies the piped-in value before passing it to the next function.\nLazy evaluation: Delays intermediate calculations until necessary, potentially improving performance.\n\n\nScope:\n\nNative pipe: Recently introduced, integrated directly into R Base package.\nMagrittr pipe: A separate package, offering more extensibility and customization options.\n\nAdoption:\n\nNative pipe: Gaining popularity due to its simplicity and integration with base R.\nMagrittr pipe: Widely used, having established a large community and ecosystem of compatible packages.\n\nChoosing between them depends on:\n\nPersonal preference: Some prefer the visual clarity of %&gt;%, while others favor the simplicity of |&gt;.\nProject requirements: Consider the need for features like the dot placeholder or additional pipe types.\nTeam collaboration: Choose a consistent style for shared code or adhere to project standards.\n\n\nUltimately, both pipes are powerful tools for data manipulation in R. Understanding their differences helps you choose the most appropriate option for your specific needs and coding style.\n\n\n\nIn pseudo code, the piping approach to the above manipulation would be:\n\ndata &lt;- data |&gt;\n    select(...) |&gt;\n    group_by(...) |&gt;\n    summarise(...)\n\nIf the code is set out as above (with each verb on a separate line), it gives an opportunity to provide a short comment to the right side of each line to provide useful documentation.\n\n\nA more specific example\n\nAs a motivating (if not a bit extreme) example, lets say we wanted to calculate the logSumExp function:\n\\[\nlog(\\sum^{n}_{i=1} e^{x_i})\n\\]\n\n## Generate some data\nset.seed(123)\nx &lt;- rgamma(10,5,1)\n## Calculate the logSumExp\nlog(sum(exp(x)))\n\n[1] 9.316408\n\n## OR\nx1 &lt;- exp(x)\nx2 &lt;-sum(x1)\nlog(x2)\n\n[1] 9.316408\n\n\nThe piping approach could be:\n\nx |&gt; exp() |&gt; sum() |&gt; log()\n\n[1] 9.316408\n\n\nTo reiterate, the following three are equivalent:\n\nexp(x)\n\n [1]   29.653639 1601.918872    5.101634  118.918637 7140.686681  252.361318\n [7]    9.175114    4.863565 1756.825350  199.466617\n\nx |&gt; exp()\n\n [1]   29.653639 1601.918872    5.101634  118.918637 7140.686681  252.361318\n [7]    9.175114    4.863565 1756.825350  199.466617\n\n\nas are the following:\n\nlog(x, base=10)\n\n [1] 0.5301465 0.8679950 0.2120706 0.6792861 0.9480981 0.7427928 0.3456667\n [8] 0.1991438 0.8733941 0.7239190\n\nx |&gt; log(base=10)\n\n [1] 0.5301465 0.8679950 0.2120706 0.6792861 0.9480981 0.7427928 0.3456667\n [8] 0.1991438 0.8733941 0.7239190\n\n\n\nMost of the following examples will demonstrate isolated data manipulation actions (such as filtering, summarising or joining) as this focuses on the specific uses of these functions without the distractions and complications of other actions. For isolated uses, piping has little (if any) advantages. Nevertheless, in recognition that data manipulations rarely comprise a single action (rather they are a series of linked actions), for all remaining examples demonstrated in the tidyverse (dplyr/tidyr) context, piping will be used."
  },
  {
    "objectID": "04_data_wrangling.html#tibbles",
    "href": "04_data_wrangling.html#tibbles",
    "title": "Data wrangling (tidyverse and friends)",
    "section": "2.3 Tibbles",
    "text": "2.3 Tibbles\ndata.frame’s are collections of variables of the identical length (yet not necessarily the same type) that the fundamental data structures used by most modelling routines in R. Nevertheless, there are numerous properties of data.frames that make them less than ideal. tibbles have been more recently engineered to address these shortcomings:\n\nif a data.frame is very large, the print method can result output that is too large to be useful. By contrast, tibbles truncate the output to a maximum of 10 rows and as many columns as will fit in the output. The tibble print method also displays the class (type) of each column (variable).\n\n\nshow comparison\n\n\n\n\ndat.1 |&gt; as.data.frame() \n\n   Treatment Plot Dose Time  Resp1  Resp2\n1    Control   P1    H    1   8.12   3.06\n2    Control   P1    H    2  20.55  25.94\n3    Control   P1    H    3  27.49  29.85\n4    Control   P1    H    4  44.79  25.39\n5    Control   P1    M    1  20.99  20.31\n6    Control   P1    M    2  37.54  17.62\n7    Control   P1    M    3  61.46  98.44\n8    Control   P1    M    4  82.21 160.01\n9    Control   P1    L    1  31.73  21.22\n10   Control   P1    L    2  59.08  37.51\n11   Control   P1    L    3  94.54 119.22\n12   Control   P1    L    4 121.17 116.45\n13   Control   P2    H    1   8.14  23.93\n14   Control   P2    H    2  13.36  28.02\n15   Control   P2    H    3  33.37  37.17\n16   Control   P2    H    4  39.87  38.25\n17   Control   P2    M    1  19.95  19.73\n18   Control   P2    M    2  42.83  40.52\n19   Control   P2    M    3  62.46   4.81\n20   Control   P2    M    4  81.78 136.66\n21   Control   P2    L    1  32.76  30.70\n22   Control   P2    L    2  62.35 123.78\n23   Control   P2    L    3  90.22 113.87\n24   Control   P2    L    4 114.03  76.52\n25 Exclusion   P3    H    1  21.86  23.58\n26 Exclusion   P3    H    2  39.83  28.03\n27 Exclusion   P3    H    3  59.53  21.32\n28 Exclusion   P3    H    4  75.59  90.76\n29 Exclusion   P3    M    1  38.57  30.63\n30 Exclusion   P3    M    2  81.25  83.61\n31 Exclusion   P3    M    3 124.08 124.09\n32 Exclusion   P3    M    4 159.69 112.65\n33 Exclusion   P3    L    1  61.16  39.53\n34 Exclusion   P3    L    2 119.84 110.27\n35 Exclusion   P3    L    3 175.87 286.33\n36 Exclusion   P3    L    4 238.76  54.23\n37 Exclusion   P4    H    1  18.82  28.60\n38 Exclusion   P4    H    2  39.82  39.07\n39 Exclusion   P4    H    3  63.30  93.43\n40 Exclusion   P4    H    4  82.29  60.15\n41 Exclusion   P4    M    1  39.51  45.90\n42 Exclusion   P4    M    2  79.24  88.04\n43 Exclusion   P4    M    3 122.09  84.19\n44 Exclusion   P4    M    4 161.67 256.34\n45 Exclusion   P4    L    1  57.93  85.24\n46 Exclusion   P4    L    2 117.88 167.90\n47 Exclusion   P4    L    3 181.09 314.49\n48 Exclusion   P4    L    4 242.31 304.70\n\n\n\n\ndat.1 |&gt; as_tibble()\n\n# A tibble: 48 × 6\n   Treatment Plot  Dose   Time Resp1  Resp2\n   &lt;fct&gt;     &lt;fct&gt; &lt;fct&gt; &lt;int&gt; &lt;dbl&gt;  &lt;dbl&gt;\n 1 Control   P1    H         1  8.12   3.06\n 2 Control   P1    H         2 20.6   25.9 \n 3 Control   P1    H         3 27.5   29.8 \n 4 Control   P1    H         4 44.8   25.4 \n 5 Control   P1    M         1 21.0   20.3 \n 6 Control   P1    M         2 37.5   17.6 \n 7 Control   P1    M         3 61.5   98.4 \n 8 Control   P1    M         4 82.2  160.  \n 9 Control   P1    L         1 31.7   21.2 \n10 Control   P1    L         2 59.1   37.5 \n# ℹ 38 more rows\n\n\n\n\n\ndata.frames have very strict column naming rules and when these are not satisfied, the names will be altered in order to adhere to the rules. tibbles permit a wider range of names.\n\n\nshow comparison\n\n\n\n\ndata.frame('1.3' = 1:6, 'Wt (kg)' = 1:6)\n\n  X1.3 Wt..kg.\n1    1       1\n2    2       2\n3    3       3\n4    4       4\n5    5       5\n6    6       6\n\n\n\n\ntibble('1.3' = 1:6, 'Wt (kg)' = 1:6)\n\n# A tibble: 6 × 2\n  `1.3` `Wt (kg)`\n  &lt;int&gt;     &lt;int&gt;\n1     1         1\n2     2         2\n3     3         3\n4     4         4\n5     5         5\n6     6         6\n\n\n\n\n\ncharacter vectors are often coerced into factors (categorical variables). This is not the case with tibbles.\nwhen vectors are added that are of a different length to the others in the data.frame, the values of the shorter vector(s) are recycled until all vectors are the same length. This behaviour can be dangerous and is not permitted in tibbles (except for vectors of length of one).\n\n\nshow comparison\n\n\n\n\ndata.frame(Var1 = 1:6, Var2 = 1:2, Var3 = 1)\n\n  Var1 Var2 Var3\n1    1    1    1\n2    2    2    1\n3    3    1    1\n4    4    2    1\n5    5    1    1\n6    6    2    1\n\n\n\n\ntibble(Var1 = 1:6, Var2 = 1:2, Var3 = 1)\n\nError in `tibble()`:\n! Tibble columns must have compatible sizes.\n• Size 6: Existing data.\n• Size 2: Column `Var2`.\nℹ Only values of size one are recycled.\n\ntibble(Var1 = 1:6, Var2 = 1)\n\n# A tibble: 6 × 2\n   Var1  Var2\n  &lt;int&gt; &lt;dbl&gt;\n1     1     1\n2     2     1\n3     3     1\n4     4     1\n5     5     1\n6     6     1\n\n\n\n\n\nwhen sub-setting via column indices, data.frames return a vector (when only a single index is provided) or a data.frame (if multiple indices are provided). This inconsistency is problematic in the context of a processing pipeline. tibble’s will always return a tibble from column indices.\n\n\nshow comparison\n\n\n\n\nas.data.frame(dat.1)[,2]\n\n [1] P1 P1 P1 P1 P1 P1 P1 P1 P1 P1 P1 P1 P2 P2 P2 P2 P2 P2 P2 P2 P2 P2 P2 P2 P3\n[26] P3 P3 P3 P3 P3 P3 P3 P3 P3 P3 P3 P4 P4 P4 P4 P4 P4 P4 P4 P4 P4 P4 P4\nLevels: P1 P2 P3 P4\n\n\n\n\nas_tibble(dat.1)[,2]\n\n# A tibble: 48 × 1\n   Plot \n   &lt;fct&gt;\n 1 P1   \n 2 P1   \n 3 P1   \n 4 P1   \n 5 P1   \n 6 P1   \n 7 P1   \n 8 P1   \n 9 P1   \n10 P1   \n# ℹ 38 more rows\n\n\n\n\n\ndata.frames permit partial matching via $ indexing. This can be problematic in the context of a processing pipeline. tibbles expressly forbid this.\n\n\nshow comparison\n\n\n\n\nas.data.frame(dat.1)$Plo\n\n [1] P1 P1 P1 P1 P1 P1 P1 P1 P1 P1 P1 P1 P2 P2 P2 P2 P2 P2 P2 P2 P2 P2 P2 P2 P3\n[26] P3 P3 P3 P3 P3 P3 P3 P3 P3 P3 P3 P4 P4 P4 P4 P4 P4 P4 P4 P4 P4 P4 P4\nLevels: P1 P2 P3 P4\n\n\n\n\nas_tibble(dat.1)$Plo\n\nWarning: Unknown or uninitialised column: `Plo`.\n\n\nNULL\n\n\n\n\n\ndata.frames have very clumsy support for list columns (a list column is a column whose cells contain lists). List columns are better supported in tibbles. The ability to support list columns is an integral for the functional programming routines of the purrr package.\n\n\nshow comparison\n\nIn this fictitious example, I would like to store three different data.frames (or any three objects for that matter) in the three cells of a variable (e.g. Var2). This is not possible in a data.frame - it will coerce the Var2 column into multiple columns (one for each object) and thus will also recycle the length of each to ensure they are all the same length. Once the data have been coerced into a data.frame, the structure is lost (we can no longer access Var2).\nThese issues are addressed in the tibble.\n\n\n\nD &lt;- data.frame(Var1 = LETTERS[1:3],\n           Var2 = list(\n               data.frame(a = 1:6),\n               data.frame(a = 1:3),\n               data.frame(a = 1:2)\n           ))\nD\n\n  Var1 Var2.a Var2.a.1 Var2.a.2\n1    A      1        1        1\n2    B      2        2        2\n3    C      3        3        1\n4    A      4        1        2\n5    B      5        2        1\n6    C      6        3        2\n\nD$Var2\n\nNULL\n\n\n\n\nD &lt;- tibble(Var1 = LETTERS[1:3],\n       Var2 = list(\n           data.frame(a = 1:6),\n           data.frame(a = 1:3),\n           data.frame(a = 1:2)\n           ))\nD\n\n# A tibble: 3 × 2\n  Var1  Var2        \n  &lt;chr&gt; &lt;list&gt;      \n1 A     &lt;df [6 × 1]&gt;\n2 B     &lt;df [3 × 1]&gt;\n3 C     &lt;df [2 × 1]&gt;\n\nD$Var2\n\n[[1]]\n  a\n1 1\n2 2\n3 3\n4 4\n5 5\n6 6\n\n[[2]]\n  a\n1 1\n2 2\n3 3\n\n[[3]]\n  a\n1 1\n2 2"
  },
  {
    "objectID": "04_data_wrangling.html#summary-functions",
    "href": "04_data_wrangling.html#summary-functions",
    "title": "Data wrangling (tidyverse and friends)",
    "section": "3.1 Summary functions",
    "text": "3.1 Summary functions\n\n\n\n\n\nFunction\n\n\nDescription\n\n\nExamples\n\n\n\n\n\n\nmean(), median()\n\n\nArithmetic mean and median.\nNote, boolean vectors are stored as a set of 0 (FALSE) and 1 (TRUE) and thus mathematical functions operate on them as if they were numbers.\n\n\n\nmean(x)\n\n[1] 4.814615\n\nmedian(B)\n\n[1] 1\n\n\n\n\n\n\nsum(), prod()\n\n\nSum and product.\n\n\n\nsum(x)\n\n[1] 48.14615\n\nprod(B)\n\n[1] 0\n\n\n\n\n\n\nvar(), sd()\n\n\nVariance and standard deviation.\n\n\n\nvar(x)\n\n[1] 6.692355\n\nsd(B)\n\n[1] 0.5163978\n\n\n\n\n\n\nmad(), IQR()\n\n\nMedian Absolute Deviation and Inter-Quartile Range.\n\n\n\nmad(x)\n\n[1] 3.540549\n\nIQR(B)\n\n[1] 1\n\n\n\n\n\n\nmin(), max()\n\n\nMinimum and maximum.\n\n\n\nmin(x)\n\n[1] 1.581772\n\nmax(B)\n\n[1] 1\n\n\n\n\n\n\nquantile()\n\n\nQuantiles\n\n\n\nquantile(x)\n\n      0%      25%      50%      75%     100% \n1.581772 2.509767 5.037043 6.916934 8.873564 \n\nquantile(x, p = 0.25)\n\n     25% \n2.509767 \n\n\n\n\n\n\ndplyr::first(), dplyr::last(), dplyr::nth()\n\n\nFirst, laste and nth value.\n\n\n\nfirst(x)\n\n[1] 3.389585\n\nfirst(x, order_by = A)\n\n[1] 3.389585\n\nlast(B)\n\n[1] TRUE\n\nnth(A, n = 4)\n\n[1] \"b\"\n\n\n\n\n\n\ndplyr::n(), dplyr::n_distinct()\n\n\nNumber of values, number of distinct values.\nn() is a special case that can only be used within the context of a data.frame or tibble.\n\n\n\nn_distinct(A)\n\n[1] 2"
  },
  {
    "objectID": "04_data_wrangling.html#vectorised-functions",
    "href": "04_data_wrangling.html#vectorised-functions",
    "title": "Data wrangling (tidyverse and friends)",
    "section": "3.2 Vectorised functions",
    "text": "3.2 Vectorised functions\n\n\n\n\n\nFunction\n\n\nDescription\n\n\nExamples\n\n\n\n\n\n\n+,-,*,/,^,%/%, %%\n\n\ntypical arithmetic operators\n\n\n\nx + 2\n\n [1]  5.389585  9.378957  3.629561  6.778440\n [5] 10.873564  7.530862  4.216495  3.581772\n [9]  9.471264  7.295647\n\nx * B\n\n [1] 0.000000 7.378957 1.629561 4.778440\n [5] 8.873564 0.000000 2.216495 0.000000\n [9] 0.000000 5.295647\n\n\n\n\n\n\nlog(),log2(),log10(), exp()\n\n\nlogarithms and exponentials\n\n\n\nlog(x)\n\n [1] 1.2207074 1.9986324 0.4883105 1.5641140\n [5] 2.1830765 1.7103437 0.7959271 0.4585455\n [9] 2.0110642 1.6668851\n\nlog10(x)\n\n [1] 0.5301465 0.8679950 0.2120706 0.6792861\n [5] 0.9480981 0.7427928 0.3456667 0.1991438\n [9] 0.8733941 0.7239190\n\nexp(x)\n\n [1]   29.653639 1601.918872    5.101634\n [4]  118.918637 7140.686681  252.361318\n [7]    9.175114    4.863565 1756.825350\n[10]  199.466617\n\n\n\n\n\n\n&lt;,&lt;=,&gt;,&gt;=,!=,==\n\n\nlogical operators\n\n\n\nx &lt; 5\n\n [1]  TRUE FALSE  TRUE  TRUE FALSE FALSE\n [7]  TRUE  TRUE FALSE FALSE\n\nB == TRUE\n\n [1] FALSE  TRUE  TRUE  TRUE  TRUE FALSE\n [7]  TRUE FALSE FALSE  TRUE\n\n\n\n\n\n\nbetween()\n\n\nWhether a value is between two numbers\n\n\n\nbetween(x, 3, 5)\n\n [1]  TRUE FALSE FALSE  TRUE FALSE FALSE\n [7] FALSE FALSE FALSE FALSE\n\n\n\n\n\n\nnear()\n\n\nA safe way of assessing equality (==) in floating points\n\n\n\nx == 3.39\n\n [1] FALSE FALSE FALSE FALSE FALSE FALSE\n [7] FALSE FALSE FALSE FALSE\n\nnear(x, y = 3.39, tol =0.01)\n\n [1]  TRUE FALSE FALSE FALSE FALSE FALSE\n [7] FALSE FALSE FALSE FALSE\n\n\n\n\n\n\nlag(), lead()\n\n\nshift cases down/up by one\n\n\n\nlag(x)\n\n [1]       NA 3.389585 7.378957 1.629561\n [5] 4.778440 8.873564 5.530862 2.216495\n [9] 1.581772 7.471264\n\nlead(x)\n\n [1] 7.378957 1.629561 4.778440 8.873564\n [5] 5.530862 2.216495 1.581772 7.471264\n [9] 5.295647       NA\n\n\n\n\n\n\ncummax(), cummin(), dplyr::cummean()\n\n\nCumulative max, min and mean\n\n\n\ncummax(x)\n\n [1] 3.389585 7.378957 7.378957 7.378957\n [5] 8.873564 8.873564 8.873564 8.873564\n [9] 8.873564 8.873564\n\ncummin(B)\n\n [1] 0 0 0 0 0 0 0 0 0 0\n\ncummean(x)\n\n [1] 3.389585 5.384271 4.132701 4.294136\n [5] 5.210021 5.263495 4.828209 4.422404\n [9] 4.761167 4.814615\n\ncummean(x &gt; 2)\n\n [1] 1.0000000 1.0000000 0.6666667 0.7500000\n [5] 0.8000000 0.8333333 0.8571429 0.7500000\n [9] 0.7777778 0.8000000\n\ncummean(B)\n\n [1] 0.0000000 0.5000000 0.6666667 0.7500000\n [5] 0.8000000 0.6666667 0.7142857 0.6250000\n [9] 0.5555556 0.6000000\n\n\n\n\n\n\ncumsum(), cumprod()\n\n\nCumulative sum and product\n\n\n\ncumsum(x)\n\n [1]  3.389585 10.768542 12.398103 17.176543\n [5] 26.050107 31.580969 33.797464 35.379235\n [9] 42.850499 48.146146\n\ncumsum(x &gt; 3)\n\n [1] 1 2 2 3 4 5 5 5 6 7\n\ncumprod(B)\n\n [1] 0 0 0 0 0 0 0 0 0 0\n\n\n\n\n\n\ndplyr::cumall(), dplyr::cumany()\n\n\nCumulative all and any (mainly for use with filtering).\n\n\n\ncumall(x)\n\n [1] TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE\n [9] TRUE TRUE\n\ncumall(x &gt; 2)\n\n [1]  TRUE  TRUE FALSE FALSE FALSE FALSE\n [7] FALSE FALSE FALSE FALSE\n\ncumany(x &gt; 4)\n\n [1] FALSE  TRUE  TRUE  TRUE  TRUE  TRUE\n [7]  TRUE  TRUE  TRUE  TRUE\n\ncumany(B)\n\n [1] FALSE  TRUE  TRUE  TRUE  TRUE  TRUE\n [7]  TRUE  TRUE  TRUE  TRUE\n\ncumall(B)\n\n [1] FALSE FALSE FALSE FALSE FALSE FALSE\n [7] FALSE FALSE FALSE FALSE\n\n\n\n\n\n\nrank(), order()\n\n\nRank and order of items\n\n\n\nrank(x)\n\n [1]  4  8  2  5 10  7  3  1  9  6\n\norder(x)\n\n [1]  8  3  7  1  4 10  6  2  9  5\n\nrank(B)\n\n [1] 2.5 7.5 7.5 7.5 7.5 2.5 7.5 2.5 2.5 7.5\n\n\n\n\n\n\ndplyr::min_rank(), dplyr::dense_rank(), dplyr::percent_rank()\n\n\nRank in which ties = min, without gaps and expressed as a percentage.\n\n\n\nmin_rank(x)\n\n [1]  4  8  2  5 10  7  3  1  9  6\n\ndense_rank(x)\n\n [1]  4  8  2  5 10  7  3  1  9  6\n\npercent_rank(x)\n\n [1] 0.3333333 0.7777778 0.1111111 0.4444444\n [5] 1.0000000 0.6666667 0.2222222 0.0000000\n [9] 0.8888889 0.5555556\n\nrank(B)\n\n [1] 2.5 7.5 7.5 7.5 7.5 2.5 7.5 2.5 2.5 7.5\n\n\n\n\n\n\ndplyr::row_number()\n\n\nRank in which ties = first.\n\n\n\nrow_number(x)\n\n [1]  4  8  2  5 10  7  3  1  9  6\n\n\n\n\n\n\ndplyr::cume_dist()\n\n\nCumulative empirical distribution (proportion less than current value).\n\n\n\ncume_dist(x)\n\n [1] 0.4 0.8 0.2 0.5 1.0 0.7 0.3 0.1 0.9 0.6\n\n\n\n\n\n\ndplyr::ntile()\n\n\nPartition into (n) bins.\n\n\n\nntile(x, n = 3)\n\n [1] 1 3 1 2 3 2 1 1 3 2\n\n\n\n\n\n\ndplyr::if_else()\n\n\nElementwise (case by case) if and else.\n\n\n\nif_else(x &gt; 3, true = \"H\", false = \"L\")\n\n [1] \"H\" \"H\" \"L\" \"H\" \"H\" \"H\" \"L\" \"L\" \"H\" \"H\"\n\n\n\n\n\n\ndplyr::case_when()\n\n\nElementwise multiple if and else.\n\n\n\ncase_when(x &lt;= 3 ~ \"L\",\n          x &gt; 3 & x &lt;= 6 ~ \"M\",\n          x &gt; 6 ~ \"H\")\n\n [1] \"M\" \"H\" \"L\" \"M\" \"H\" \"M\" \"L\" \"L\" \"H\" \"M\""
  },
  {
    "objectID": "04_data_wrangling.html#subset-columns-select",
    "href": "04_data_wrangling.html#subset-columns-select",
    "title": "Data wrangling (tidyverse and friends)",
    "section": "5.1 Subset columns (select)",
    "text": "5.1 Subset columns (select)\nSelecting works by either including (or excluding) the column names that you indicate or via special selection ‘Helper’ functions that pass a vector of column indices to include in the subset data.\n\n\n\n\n\n\n\n\n\n\nFirst 10 rows of the `dat.1` data.frame\n\n\nTreatment\nPlot\nDose\nTime\nResp1\nResp2\n\n\n\n\nControl\nP1\nH\n1\n8.12\n3.06\n\n\nControl\nP1\nH\n2\n20.55\n25.94\n\n\nControl\nP1\nH\n3\n27.49\n29.85\n\n\nControl\nP1\nH\n4\n44.79\n25.39\n\n\nControl\nP1\nM\n1\n20.99\n20.31\n\n\nControl\nP1\nM\n2\n37.54\n17.62\n\n\nControl\nP1\nM\n3\n61.46\n98.44\n\n\nControl\nP1\nM\n4\n82.21\n160.01\n\n\nControl\nP1\nL\n1\n31.73\n21.22\n\n\nControl\nP1\nL\n2\n59.08\n37.51\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nThe select() function users tidy-select semantics.\n\nInclusion / exclusion of from bare namesInclusion / exclusion based on positionInclusion / exclusion from name predicatesSelect and num_rangeReorder columns…Select and all_of / any_ofSelect and where\n\n\nSelect specific variables\n\ndat.1 |&gt; select(Treatment, Dose, Time, Resp1) |&gt;\n    head() \n\n  Treatment Dose Time Resp1\n1   Control    H    1  8.12\n2   Control    H    2 20.55\n3   Control    H    3 27.49\n4   Control    H    4 44.79\n5   Control    M    1 20.99\n6   Control    M    2 37.54\n\n\nExclude specific variables\n\ndat.1 |&gt; select(-Plot, -Resp2) |&gt;\n    head()\n\n  Treatment Dose Time Resp1\n1   Control    H    1  8.12\n2   Control    H    2 20.55\n3   Control    H    3 27.49\n4   Control    H    4 44.79\n5   Control    M    1 20.99\n6   Control    M    2 37.54\n\n\n\n\nInclude columns Treatment through to Time\n\ndat.1 |&gt; select(Treatment:Time) |&gt;\n    head() \n\n  Treatment Plot Dose Time\n1   Control   P1    H    1\n2   Control   P1    H    2\n3   Control   P1    H    3\n4   Control   P1    H    4\n5   Control   P1    M    1\n6   Control   P1    M    2\n\n\nExclude columns Treatment through to Time\n\ndat.1 |&gt; select(-(Treatment:Time)) |&gt;\n    head() \n\n  Resp1 Resp2\n1  8.12  3.06\n2 20.55 25.94\n3 27.49 29.85\n4 44.79 25.39\n5 20.99 20.31\n6 37.54 17.62\n\n\nExclude columns Treatment through to Time\n\ndat.1 |&gt; select(!(Treatment:Time)) |&gt;\n    head() \n\n  Resp1 Resp2\n1  8.12  3.06\n2 20.55 25.94\n3 27.49 29.85\n4 44.79 25.39\n5 20.99 20.31\n6 37.54 17.62\n\n\n\n\nNames containing and ‘r’ (case insensitive)\n\ndat.1 |&gt; select(contains(\"R\")) |&gt;\n    head() \n\n  Treatment Resp1 Resp2\n1   Control  8.12  3.06\n2   Control 20.55 25.94\n3   Control 27.49 29.85\n4   Control 44.79 25.39\n5   Control 20.99 20.31\n6   Control 37.54 17.62\n\n\nNames starting with ‘r’ (case insensitive)\n\ndat.1 |&gt; select(starts_with(\"R\")) |&gt;\n    head() \n\n  Resp1 Resp2\n1  8.12  3.06\n2 20.55 25.94\n3 27.49 29.85\n4 44.79 25.39\n5 20.99 20.31\n6 37.54 17.62\n\n\nNames ending in ‘e’ (case insensitive)\n\ndat.1 |&gt; select(ends_with(\"e\")) |&gt;\n    head() \n\n  Dose Time\n1    H    1\n2    H    2\n3    H    3\n4    H    4\n5    M    1\n6    M    2\n\n\nNames that are exactly four characters long\n\ndat.1 |&gt; select(matches(\"^.{4}$\")) |&gt;\n    head()\n\n  Plot Dose Time\n1   P1    H    1\n2   P1    H    2\n3   P1    H    3\n4   P1    H    4\n5   P1    M    1\n6   P1    M    2\n\n\n\n\n\ndat.1 |&gt; select(num_range(\"Resp\", 1:2)) |&gt;\n    head()\n\n  Resp1 Resp2\n1  8.12  3.06\n2 20.55 25.94\n3 27.49 29.85\n4 44.79 25.39\n5 20.99 20.31\n6 37.54 17.62\n\n\n\n\n\ndat.1 |&gt; select(num_range(\"Resp\", 1:2),\n                 everything()) |&gt;\n    head() \n\n  Resp1 Resp2 Treatment Plot Dose Time\n1  8.12  3.06   Control   P1    H    1\n2 20.55 25.94   Control   P1    H    2\n3 27.49 29.85   Control   P1    H    3\n4 44.79 25.39   Control   P1    H    4\n5 20.99 20.31   Control   P1    M    1\n6 37.54 17.62   Control   P1    M    2\n\n\n\n\nSelect from a vector of strings\n\nVars &lt;- c(\"Resp1\", \"Resp2\")\ndat.1 |&gt; select(all_of(Vars)) |&gt;\n    head()\n\n  Resp1 Resp2\n1  8.12  3.06\n2 20.55 25.94\n3 27.49 29.85\n4 44.79 25.39\n5 20.99 20.31\n6 37.54 17.62\n\n\nSelect from string vector of strings…\n\nVars &lt;- c(\"Resp1\", \"Resp2\", \"Resp3\")\ndat.1 |&gt; select(any_of(Vars)) |&gt;\n    head() \n\n  Resp1 Resp2\n1  8.12  3.06\n2 20.55 25.94\n3 27.49 29.85\n4 44.79 25.39\n5 20.99 20.31\n6 37.54 17.62\n\n\n\nVars &lt;- c(\"Resp1\", \"Resp2\", \"Resp3\")\ndat.1 |&gt; select(-any_of(Vars)) |&gt;\n    head() \n\n  Treatment Plot Dose Time\n1   Control   P1    H    1\n2   Control   P1    H    2\n3   Control   P1    H    3\n4   Control   P1    H    4\n5   Control   P1    M    1\n6   Control   P1    M    2\n\n\n\n\n\ndat.1 |&gt; select(where(is.numeric)) |&gt;\n    head() \n\n  Time Resp1 Resp2\n1    1  8.12  3.06\n2    2 20.55 25.94\n3    3 27.49 29.85\n4    4 44.79 25.39\n5    1 20.99 20.31\n6    2 37.54 17.62\n\n\n\n\n\nSince tibbles permit column names that have special characters in them, in order to refer to a column that has a name with special characters, it is necessary to enclose the name in backticks. For example, to select the variable, Pocillopora damicornis (which contains a space in the name - these are not permitted in data.frames, yet are permitted in tibbles) and print the first six rows:\n\ntikus |&gt;\n    select(`Pocillopora damicornis`) |&gt;\n    head()\n\n   Pocillopora damicornis\nV1                     79\nV2                     51\nV3                     42\nV4                     15\nV5                      9\nV6                     72"
  },
  {
    "objectID": "04_data_wrangling.html#renaming-columns-rename",
    "href": "04_data_wrangling.html#renaming-columns-rename",
    "title": "Data wrangling (tidyverse and friends)",
    "section": "5.2 Renaming columns (rename)",
    "text": "5.2 Renaming columns (rename)\nNote, it is possible to have column names renamed during a select action.\nBoth the rename() and select() functions user tidy-select semantics.\n\ndat.1 |&gt;\n    select(\"Weight\" = Resp1) |&gt;\n    head()\n\n  Weight\n1   8.12\n2  20.55\n3  27.49\n4  44.79\n5  20.99\n6  37.54\n\n\nIf we want to retain the other variables, we would also have to include them in the select either explicitly, or via a helper function.\n\ndat.1 |&gt;\n    select(everything(), \"Weight\" = Resp1) |&gt;\n    head()\n\n  Treatment Plot Dose Time Weight Resp2\n1   Control   P1    H    1   8.12  3.06\n2   Control   P1    H    2  20.55 25.94\n3   Control   P1    H    3  27.49 29.85\n4   Control   P1    H    4  44.79 25.39\n5   Control   P1    M    1  20.99 20.31\n6   Control   P1    M    2  37.54 17.62\n\n\nHowever, note that this might not retain the order of the columns. Hence, for simple renaming of columns, the rename function is more convenient.\n\ndat.1 |&gt;\n    rename(\"Weight\" = Resp1) |&gt;\n    head()\n\n  Treatment Plot Dose Time Weight Resp2\n1   Control   P1    H    1   8.12  3.06\n2   Control   P1    H    2  20.55 25.94\n3   Control   P1    H    3  27.49 29.85\n4   Control   P1    H    4  44.79 25.39\n5   Control   P1    M    1  20.99 20.31\n6   Control   P1    M    2  37.54 17.62\n\n\nIt is also possible to rename columns based on a lookup (list or data.frame). This is handy for cases when data columns have conveniently abbreviated names yet you are preparing data for tabular output - and thus need more descriptive column names.\n\nlookup &lt;- list(\"Response 1\" = \"Resp1\",\n               \"Response 2\" = \"Resp2\")\ndat.1 |&gt;\n    rename(!!!lookup) |&gt;\n    head()\n\n  Treatment Plot Dose Time Response 1 Response 2\n1   Control   P1    H    1       8.12       3.06\n2   Control   P1    H    2      20.55      25.94\n3   Control   P1    H    3      27.49      29.85\n4   Control   P1    H    4      44.79      25.39\n5   Control   P1    M    1      20.99      20.31\n6   Control   P1    M    2      37.54      17.62\n\n\nIn the above example, the big bang operator  !!! forces-splice a list operator. That is, the elements of the list are spliced into the statement as if they had been included directly.\nTo do the same from a data.frame lookup..\n\nlookup &lt;- tribble(\n    ~Abbr_name, ~Long_name,\n    \"Resp1\",     \"Response 1\",\n    \"Resp2\",     \"Response 2\")\n## Convert to list of pairs\nlookup &lt;- lookup |&gt;\n    select(Long_name, Abbr_name) |&gt; \n    deframe() |&gt;\n    list()\ndat.1 |&gt;\n    rename(!!!lookup) |&gt;\n    head()\n\n  Treatment Plot Dose Time Response 1 Response 2\n1   Control   P1    H    1       8.12       3.06\n2   Control   P1    H    2      20.55      25.94\n3   Control   P1    H    3      27.49      29.85\n4   Control   P1    H    4      44.79      25.39\n5   Control   P1    M    1      20.99      20.31\n6   Control   P1    M    2      37.54      17.62"
  },
  {
    "objectID": "04_data_wrangling.html#select-a-single-column-pull",
    "href": "04_data_wrangling.html#select-a-single-column-pull",
    "title": "Data wrangling (tidyverse and friends)",
    "section": "5.3 Select a single column (pull)",
    "text": "5.3 Select a single column (pull)\nAs indicated earlier, single column indices on tibbles return a single column tibble. To extract a single column as a vector, there is a pull function.\nThe pull() function users tidy-select semantics.\n\ndat.1 |&gt; pull(Resp1) \n\n [1]   8.12  20.55  27.49  44.79  20.99  37.54  61.46  82.21  31.73  59.08\n[11]  94.54 121.17   8.14  13.36  33.37  39.87  19.95  42.83  62.46  81.78\n[21]  32.76  62.35  90.22 114.03  21.86  39.83  59.53  75.59  38.57  81.25\n[31] 124.08 159.69  61.16 119.84 175.87 238.76  18.82  39.82  63.30  82.29\n[41]  39.51  79.24 122.09 161.67  57.93 117.88 181.09 242.31"
  },
  {
    "objectID": "04_data_wrangling.html#subset-of-rows-filter",
    "href": "04_data_wrangling.html#subset-of-rows-filter",
    "title": "Data wrangling (tidyverse and friends)",
    "section": "5.4 Subset of rows (filter)",
    "text": "5.4 Subset of rows (filter)\nFiltering selects rows for which a condition is evaluated to be TRUE. Hence, any logical expression or vectorized function that returns Boolean values (TRUE or FALSE) can be used for filtering.\nThe filter() function users data-masking semantics.\n\n\n\n\n\n\n\n\n\n\nFirst 10 rows of the `dat.1` data.frame\n\n\nTreatment\nPlot\nDose\nTime\nResp1\nResp2\n\n\n\n\nControl\nP1\nH\n1\n8.12\n3.06\n\n\nControl\nP1\nH\n2\n20.55\n25.94\n\n\nControl\nP1\nH\n3\n27.49\n29.85\n\n\nControl\nP1\nH\n4\n44.79\n25.39\n\n\nControl\nP1\nM\n1\n20.99\n20.31\n\n\nControl\nP1\nM\n2\n37.54\n17.62\n\n\nControl\nP1\nM\n3\n61.46\n98.44\n\n\nControl\nP1\nM\n4\n82.21\n160.01\n\n\nControl\nP1\nL\n1\n31.73\n21.22\n\n\nControl\nP1\nL\n2\n59.08\n37.51\n\n\n\n\n\n\n\n\n\n\n\n\nHelper function\nCombine multiple selections …\n\n\n\n\nif_any()\nWith an an OR\n\n\nif_all()\nWith an AND)\n\n\n\nNote, by default, the above searchers are NOT case sensitive\n\n\n\n\nLogical/Boolean function\nDescription\n\n\n\n\n==\nis equal to\n\n\n!=\nis not equal to\n\n\n&lt;\nis less than\n\n\n&gt;\nis greater than\n\n\n&lt;=\nis less than or equal to\n\n\n&gt;=\nis greater than or equal to\n\n\nis.na()\nis equal to NA\n\n\n!is.na()\nis not equal to NA\n\n\n%in%\nis in the following vector\n\n\n!\nnot\n\n\n& &&\nlogical AND\n\n\n| ||\nlogical OR\n\n\nxor()\nelementwise OR\n\n\nisTRUE()\nis true\n\n\nisFALSE()\nis false\n\n\n\n\n\n\nFilter by category levelFilter by multiple category levelsFilter by numericFilter and betweenFilter by numeric (cumulative functions)Filter by multiple filters (AND)Filter by multiple filters (OR)Filter by multiple selection filters (AND)Filter by multiple selection filters (OR)\n\n\n\ndat.1 |&gt; filter(Dose == \"H\")\n\n   Treatment Plot Dose Time Resp1 Resp2\n1    Control   P1    H    1  8.12  3.06\n2    Control   P1    H    2 20.55 25.94\n3    Control   P1    H    3 27.49 29.85\n4    Control   P1    H    4 44.79 25.39\n5    Control   P2    H    1  8.14 23.93\n6    Control   P2    H    2 13.36 28.02\n7    Control   P2    H    3 33.37 37.17\n8    Control   P2    H    4 39.87 38.25\n9  Exclusion   P3    H    1 21.86 23.58\n10 Exclusion   P3    H    2 39.83 28.03\n11 Exclusion   P3    H    3 59.53 21.32\n12 Exclusion   P3    H    4 75.59 90.76\n13 Exclusion   P4    H    1 18.82 28.60\n14 Exclusion   P4    H    2 39.82 39.07\n15 Exclusion   P4    H    3 63.30 93.43\n16 Exclusion   P4    H    4 82.29 60.15\n\n\n\n\n\ndat.1 |&gt; filter(Dose %in% c(\"H\", \"M\"))\n\n   Treatment Plot Dose Time  Resp1  Resp2\n1    Control   P1    H    1   8.12   3.06\n2    Control   P1    H    2  20.55  25.94\n3    Control   P1    H    3  27.49  29.85\n4    Control   P1    H    4  44.79  25.39\n5    Control   P1    M    1  20.99  20.31\n6    Control   P1    M    2  37.54  17.62\n7    Control   P1    M    3  61.46  98.44\n8    Control   P1    M    4  82.21 160.01\n9    Control   P2    H    1   8.14  23.93\n10   Control   P2    H    2  13.36  28.02\n11   Control   P2    H    3  33.37  37.17\n12   Control   P2    H    4  39.87  38.25\n13   Control   P2    M    1  19.95  19.73\n14   Control   P2    M    2  42.83  40.52\n15   Control   P2    M    3  62.46   4.81\n16   Control   P2    M    4  81.78 136.66\n17 Exclusion   P3    H    1  21.86  23.58\n18 Exclusion   P3    H    2  39.83  28.03\n19 Exclusion   P3    H    3  59.53  21.32\n20 Exclusion   P3    H    4  75.59  90.76\n21 Exclusion   P3    M    1  38.57  30.63\n22 Exclusion   P3    M    2  81.25  83.61\n23 Exclusion   P3    M    3 124.08 124.09\n24 Exclusion   P3    M    4 159.69 112.65\n25 Exclusion   P4    H    1  18.82  28.60\n26 Exclusion   P4    H    2  39.82  39.07\n27 Exclusion   P4    H    3  63.30  93.43\n28 Exclusion   P4    H    4  82.29  60.15\n29 Exclusion   P4    M    1  39.51  45.90\n30 Exclusion   P4    M    2  79.24  88.04\n31 Exclusion   P4    M    3 122.09  84.19\n32 Exclusion   P4    M    4 161.67 256.34\n\n\n\n\n\ndat.1 |&gt; filter(Resp1 &lt; 25)\n\n  Treatment Plot Dose Time Resp1 Resp2\n1   Control   P1    H    1  8.12  3.06\n2   Control   P1    H    2 20.55 25.94\n3   Control   P1    M    1 20.99 20.31\n4   Control   P2    H    1  8.14 23.93\n5   Control   P2    H    2 13.36 28.02\n6   Control   P2    M    1 19.95 19.73\n7 Exclusion   P3    H    1 21.86 23.58\n8 Exclusion   P4    H    1 18.82 28.60\n\n\n\n\n\ndat.1 |&gt; filter(between(Resp1, 15, 25))\n\n  Treatment Plot Dose Time Resp1 Resp2\n1   Control   P1    H    2 20.55 25.94\n2   Control   P1    M    1 20.99 20.31\n3   Control   P2    M    1 19.95 19.73\n4 Exclusion   P3    H    1 21.86 23.58\n5 Exclusion   P4    H    1 18.82 28.60\n\n\n\n\nKeep all cases after a value of Resp1 has exceeded 200\n\ndat.1 |&gt; filter(cumany(Resp1 &gt; 200))\n\n   Treatment Plot Dose Time  Resp1  Resp2\n1  Exclusion   P3    L    4 238.76  54.23\n2  Exclusion   P4    H    1  18.82  28.60\n3  Exclusion   P4    H    2  39.82  39.07\n4  Exclusion   P4    H    3  63.30  93.43\n5  Exclusion   P4    H    4  82.29  60.15\n6  Exclusion   P4    M    1  39.51  45.90\n7  Exclusion   P4    M    2  79.24  88.04\n8  Exclusion   P4    M    3 122.09  84.19\n9  Exclusion   P4    M    4 161.67 256.34\n10 Exclusion   P4    L    1  57.93  85.24\n11 Exclusion   P4    L    2 117.88 167.90\n12 Exclusion   P4    L    3 181.09 314.49\n13 Exclusion   P4    L    4 242.31 304.70\n\n\nKeep all cases until the first case of Resp1 &lt; 25\n\ndat.1 |&gt; filter(cumall(Resp1 &lt; 25))\n\n  Treatment Plot Dose Time Resp1 Resp2\n1   Control   P1    H    1  8.12  3.06\n2   Control   P1    H    2 20.55 25.94\n\n\n\n\n\ndat.1 |&gt; filter(Dose == \"H\", Resp1 &lt; 25)\n\n  Treatment Plot Dose Time Resp1 Resp2\n1   Control   P1    H    1  8.12  3.06\n2   Control   P1    H    2 20.55 25.94\n3   Control   P2    H    1  8.14 23.93\n4   Control   P2    H    2 13.36 28.02\n5 Exclusion   P3    H    1 21.86 23.58\n6 Exclusion   P4    H    1 18.82 28.60\n\n##OR\ndat.1 |&gt; filter(Dose == \"H\" & Resp1 &lt; 25)\n\n  Treatment Plot Dose Time Resp1 Resp2\n1   Control   P1    H    1  8.12  3.06\n2   Control   P1    H    2 20.55 25.94\n3   Control   P2    H    1  8.14 23.93\n4   Control   P2    H    2 13.36 28.02\n5 Exclusion   P3    H    1 21.86 23.58\n6 Exclusion   P4    H    1 18.82 28.60\n\n\n\n\n\ndat.1 |&gt; filter(Dose == \"H\" | Resp1 &lt; 25)\n\n   Treatment Plot Dose Time Resp1 Resp2\n1    Control   P1    H    1  8.12  3.06\n2    Control   P1    H    2 20.55 25.94\n3    Control   P1    H    3 27.49 29.85\n4    Control   P1    H    4 44.79 25.39\n5    Control   P1    M    1 20.99 20.31\n6    Control   P2    H    1  8.14 23.93\n7    Control   P2    H    2 13.36 28.02\n8    Control   P2    H    3 33.37 37.17\n9    Control   P2    H    4 39.87 38.25\n10   Control   P2    M    1 19.95 19.73\n11 Exclusion   P3    H    1 21.86 23.58\n12 Exclusion   P3    H    2 39.83 28.03\n13 Exclusion   P3    H    3 59.53 21.32\n14 Exclusion   P3    H    4 75.59 90.76\n15 Exclusion   P4    H    1 18.82 28.60\n16 Exclusion   P4    H    2 39.82 39.07\n17 Exclusion   P4    H    3 63.30 93.43\n18 Exclusion   P4    H    4 82.29 60.15\n\n\n\n\n\ndat.1 |&gt; filter(if_all(starts_with(\"Resp\"), ~ . &lt; 25))\n\n  Treatment Plot Dose Time Resp1 Resp2\n1   Control   P1    H    1  8.12  3.06\n2   Control   P1    M    1 20.99 20.31\n3   Control   P2    H    1  8.14 23.93\n4   Control   P2    M    1 19.95 19.73\n5 Exclusion   P3    H    1 21.86 23.58\n\n\n\n\n\ndat.1 |&gt; filter(if_any(starts_with(\"Resp\"), ~ . &lt; 25))\n\n   Treatment Plot Dose Time Resp1 Resp2\n1    Control   P1    H    1  8.12  3.06\n2    Control   P1    H    2 20.55 25.94\n3    Control   P1    M    1 20.99 20.31\n4    Control   P1    M    2 37.54 17.62\n5    Control   P1    L    1 31.73 21.22\n6    Control   P2    H    1  8.14 23.93\n7    Control   P2    H    2 13.36 28.02\n8    Control   P2    M    1 19.95 19.73\n9    Control   P2    M    3 62.46  4.81\n10 Exclusion   P3    H    1 21.86 23.58\n11 Exclusion   P3    H    3 59.53 21.32\n12 Exclusion   P4    H    1 18.82 28.60"
  },
  {
    "objectID": "04_data_wrangling.html#subset-of-rows-by-position-slice",
    "href": "04_data_wrangling.html#subset-of-rows-by-position-slice",
    "title": "Data wrangling (tidyverse and friends)",
    "section": "5.5 Subset of rows by position (slice)",
    "text": "5.5 Subset of rows by position (slice)\n\nKeep rows 1 through to 4Keep rows 1 through to 4 and 7\n\n\n\ndat.1 |&gt; slice(1:4)\n\n  Treatment Plot Dose Time Resp1 Resp2\n1   Control   P1    H    1  8.12  3.06\n2   Control   P1    H    2 20.55 25.94\n3   Control   P1    H    3 27.49 29.85\n4   Control   P1    H    4 44.79 25.39\n\n\n\n\n\ndat.1 |&gt; slice(c(1:4, 7))\n\n  Treatment Plot Dose Time Resp1 Resp2\n1   Control   P1    H    1  8.12  3.06\n2   Control   P1    H    2 20.55 25.94\n3   Control   P1    H    3 27.49 29.85\n4   Control   P1    H    4 44.79 25.39\n5   Control   P1    M    3 61.46 98.44"
  },
  {
    "objectID": "04_data_wrangling.html#random-selection-of-rows-sample_n",
    "href": "04_data_wrangling.html#random-selection-of-rows-sample_n",
    "title": "Data wrangling (tidyverse and friends)",
    "section": "5.6 Random selection of rows (sample_n)",
    "text": "5.6 Random selection of rows (sample_n)\nIn each of the examples, I will set the random seed to ensure we can all repeat the example exactly.\n\nRandom sample of rowsRandom fractional sample of rows\n\n\nRandom sample of 10 rows (without replacement)\n\nset.seed(123)\ndat.1 |&gt; sample_n(10, replace = FALSE)\n\n   Treatment Plot Dose Time  Resp1  Resp2\n1  Exclusion   P3    M    3 124.08 124.09\n2    Control   P2    H    3  33.37  37.17\n3    Control   P2    H    2  13.36  28.02\n4    Control   P1    H    3  27.49  29.85\n5  Exclusion   P4    M    2  79.24  88.04\n6  Exclusion   P4    M    3 122.09  84.19\n7  Exclusion   P4    H    1  18.82  28.60\n8  Exclusion   P4    L    2 117.88 167.90\n9  Exclusion   P3    H    1  21.86  23.58\n10 Exclusion   P3    H    2  39.83  28.03\n\n\n\n\nRandom sample of 25% of the rows (without replacement)\n\nset.seed(123)\ndat.1 |&gt; sample_frac(0.25, replace = FALSE)\n\n   Treatment Plot Dose Time  Resp1  Resp2\n1  Exclusion   P3    M    3 124.08 124.09\n2    Control   P2    H    3  33.37  37.17\n3    Control   P2    H    2  13.36  28.02\n4    Control   P1    H    3  27.49  29.85\n5  Exclusion   P4    M    2  79.24  88.04\n6  Exclusion   P4    M    3 122.09  84.19\n7  Exclusion   P4    H    1  18.82  28.60\n8  Exclusion   P4    L    2 117.88 167.90\n9  Exclusion   P3    H    1  21.86  23.58\n10 Exclusion   P3    H    2  39.83  28.03\n11 Exclusion   P3    H    3  59.53  21.32\n12   Control   P1    M    1  20.99  20.31"
  },
  {
    "objectID": "04_data_wrangling.html#effects-of-filtering-on-factor-levels",
    "href": "04_data_wrangling.html#effects-of-filtering-on-factor-levels",
    "title": "Data wrangling (tidyverse and friends)",
    "section": "5.7 Effects of filtering on factor levels",
    "text": "5.7 Effects of filtering on factor levels\nIn R, categorical variables (factors) are actually stored as vectors of integers (1, 2, 3, …) along with an attribute that registers the names (and order) of the levels. We can see this, if we ask to see the structure of any categorical variable:\n\nstr(dat.1$Dose)\n\n Factor w/ 3 levels \"H\",\"L\",\"M\": 1 1 1 1 3 3 3 3 2 2 ...\n\n\nIn the above, we see that the levels of the Dose variable are “H”, “L”, “M” (by default, levels of an unordered factor are alphabetical). The first four cases are all 1, which is mapped to “H”. The next four are 3 which maps to “M” and so on.\nAlternatively, we can explore the levels attribute of a factor via the levels() function:\n\nlevels(dat.1$Dose)\n\n[1] \"H\" \"L\" \"M\"\n\nlevels(dat.1$Plot)\n\n[1] \"P1\" \"P2\" \"P3\" \"P4\"\n\nlevels(dat.1$Treatment)\n\n[1] \"Control\"   \"Exclusion\"\n\n\nAlthough subsets of rows (filter, sample_n etc) may appear to completely remove particular levels of a categorical variable, these actions do not update factor attributes. Consequently, many routines that operate on such factors (such as plots and statistical models) will proceed as if all factor levels are present (e.g. plots will contain gaps where space has been provisioned for all levels even though there may be no data associated with all levels).\nTo illustrate this, we will filter the dat.1 data such that it only includes cases for which Plot equals “P1” and then explore the levels attribute of some of the categorical variables.\n\ndat.2 &lt;- dat.1 |&gt;\n    filter(Plot == \"P1\")\ndat.2\n\n   Treatment Plot Dose Time  Resp1  Resp2\n1    Control   P1    H    1   8.12   3.06\n2    Control   P1    H    2  20.55  25.94\n3    Control   P1    H    3  27.49  29.85\n4    Control   P1    H    4  44.79  25.39\n5    Control   P1    M    1  20.99  20.31\n6    Control   P1    M    2  37.54  17.62\n7    Control   P1    M    3  61.46  98.44\n8    Control   P1    M    4  82.21 160.01\n9    Control   P1    L    1  31.73  21.22\n10   Control   P1    L    2  59.08  37.51\n11   Control   P1    L    3  94.54 119.22\n12   Control   P1    L    4 121.17 116.45\n\nlevels(dat.2$Dose)\n\n[1] \"H\" \"L\" \"M\"\n\nlevels(dat.2$Plot)\n\n[1] \"P1\" \"P2\" \"P3\" \"P4\"\n\nlevels(dat.2$Treatment)\n\n[1] \"Control\"   \"Exclusion\"\n\n\nSo although the data only contains Plot values of “P1” (and Treatment values of “Control”), the levels are still listed as “P1”, “P2”, “P3”, and “P4”.\nTo ensure that the attributes reflect the subset data, it is necessary to use the droplevels() function:\n\ndat.2 &lt;- dat.1 |&gt;\n    filter(Plot == \"P1\") |&gt;\n    droplevels()\nlevels(dat.2$Dose)\n\n[1] \"H\" \"L\" \"M\"\n\nlevels(dat.2$Plot)\n\n[1] \"P1\"\n\nlevels(dat.2$Treatment)\n\n[1] \"Control\""
  },
  {
    "objectID": "04_data_wrangling.html#mathematical-functions",
    "href": "04_data_wrangling.html#mathematical-functions",
    "title": "Data wrangling (tidyverse and friends)",
    "section": "6.1 Mathematical functions",
    "text": "6.1 Mathematical functions\n\n\n\n\n\n\n\n\nFunction\nDescription\n\n\n\n\n+,-,*,/,^,%/%, %%\ntypical arithmetic operators\n\n\nlog(),log2(),log10(), exp()\nlogarithms/exponentials\n\n\n&lt;,&lt;=,&gt;,&gt;=,!=,==\nlogical operators\n\n\nbetween()\nwhether a case is between to numbers\n\n\nnear()\na safe way of assessing equality in floating points\n\n\n\n\narithmetic operatorslogarithmic operatorslogical operatorsnearbetween\n\n\n\ndat.1 |&gt; mutate(Sum = Resp1 + Resp2,\n                 Div = Resp1 / Resp2) |&gt;\n    head()\n\n  Treatment Plot Dose Time Resp1 Resp2   Sum       Div\n1   Control   P1    H    1  8.12  3.06 11.18 2.6535948\n2   Control   P1    H    2 20.55 25.94 46.49 0.7922128\n3   Control   P1    H    3 27.49 29.85 57.34 0.9209380\n4   Control   P1    H    4 44.79 25.39 70.18 1.7640803\n5   Control   P1    M    1 20.99 20.31 41.30 1.0334810\n6   Control   P1    M    2 37.54 17.62 55.16 2.1305335\n\n\n\n\n\ndat.1 |&gt; mutate(logResp1 = log(Resp1),\n                 expResp2 = exp(Resp2)) |&gt;\n    head()\n\n  Treatment Plot Dose Time Resp1 Resp2 logResp1     expResp2\n1   Control   P1    H    1  8.12  3.06 2.094330 2.132756e+01\n2   Control   P1    H    2 20.55 25.94 3.022861 1.843312e+11\n3   Control   P1    H    3 27.49 29.85 3.313822 9.197934e+12\n4   Control   P1    H    4 44.79 25.39 3.801985 1.063499e+11\n5   Control   P1    M    1 20.99 20.31 3.044046 6.614864e+08\n6   Control   P1    M    2 37.54 17.62 3.625407 4.490232e+07\n\n\n\n\n\ndat.1 |&gt; mutate(largeResp1 = Resp1 &gt; 25) |&gt;\n    head()\n\n  Treatment Plot Dose Time Resp1 Resp2 largeResp1\n1   Control   P1    H    1  8.12  3.06      FALSE\n2   Control   P1    H    2 20.55 25.94      FALSE\n3   Control   P1    H    3 27.49 29.85       TRUE\n4   Control   P1    H    4 44.79 25.39       TRUE\n5   Control   P1    M    1 20.99 20.31      FALSE\n6   Control   P1    M    2 37.54 17.62       TRUE\n\n\n\n\n\ndat.1 |&gt; mutate(\n              A = Resp1 == 8.1,\n              B = near(Resp1, 8.1, tol = 0.1)) |&gt;\n    head()\n\n  Treatment Plot Dose Time Resp1 Resp2     A     B\n1   Control   P1    H    1  8.12  3.06 FALSE  TRUE\n2   Control   P1    H    2 20.55 25.94 FALSE FALSE\n3   Control   P1    H    3 27.49 29.85 FALSE FALSE\n4   Control   P1    H    4 44.79 25.39 FALSE FALSE\n5   Control   P1    M    1 20.99 20.31 FALSE FALSE\n6   Control   P1    M    2 37.54 17.62 FALSE FALSE\n\n\n\n\n\ndat.1 |&gt; mutate(mediumResp1 = between(Resp1, 15, 25)) |&gt;\n    head()\n\n  Treatment Plot Dose Time Resp1 Resp2 mediumResp1\n1   Control   P1    H    1  8.12  3.06       FALSE\n2   Control   P1    H    2 20.55 25.94        TRUE\n3   Control   P1    H    3 27.49 29.85       FALSE\n4   Control   P1    H    4 44.79 25.39       FALSE\n5   Control   P1    M    1 20.99 20.31        TRUE\n6   Control   P1    M    2 37.54 17.62       FALSE"
  },
  {
    "objectID": "04_data_wrangling.html#offset-functions",
    "href": "04_data_wrangling.html#offset-functions",
    "title": "Data wrangling (tidyverse and friends)",
    "section": "6.2 Offset functions",
    "text": "6.2 Offset functions\n\n\n\n\n\n\n\n\nFunction\nDescription\n\n\n\n\nlag()\nshift cases down one\n\n\nlead()\nshift cases up one\n\n\n\n\nlagsleads\n\n\n\ndat.1 |&gt; mutate(lagResp1 = lag(Resp1)) |&gt;\n    head()\n\n  Treatment Plot Dose Time Resp1 Resp2 lagResp1\n1   Control   P1    H    1  8.12  3.06       NA\n2   Control   P1    H    2 20.55 25.94     8.12\n3   Control   P1    H    3 27.49 29.85    20.55\n4   Control   P1    H    4 44.79 25.39    27.49\n5   Control   P1    M    1 20.99 20.31    44.79\n6   Control   P1    M    2 37.54 17.62    20.99\n\n\n\n\n\ndat.1 |&gt; mutate(leadResp1 = lead(Resp1)) |&gt;\n    tail()\n\n   Treatment Plot Dose Time  Resp1  Resp2 leadResp1\n43 Exclusion   P4    M    3 122.09  84.19    161.67\n44 Exclusion   P4    M    4 161.67 256.34     57.93\n45 Exclusion   P4    L    1  57.93  85.24    117.88\n46 Exclusion   P4    L    2 117.88 167.90    181.09\n47 Exclusion   P4    L    3 181.09 314.49    242.31\n48 Exclusion   P4    L    4 242.31 304.70        NA"
  },
  {
    "objectID": "04_data_wrangling.html#cumulative-aggregate-functions",
    "href": "04_data_wrangling.html#cumulative-aggregate-functions",
    "title": "Data wrangling (tidyverse and friends)",
    "section": "6.3 Cumulative aggregate functions",
    "text": "6.3 Cumulative aggregate functions\n\n\n\n\n\n\n\n\nFunction\nDescription\n\n\n\n\ncummax()\ncumulative maximum\n\n\ncummin()\ncumulative minimum\n\n\ncummean()\ncumulative mean\n\n\ncumprod()\ncumulative product\n\n\ncumsum()\ncumulative sum\n\n\nrank()\nrank of current case (ties averaged)\n\n\nmin_rank()\nrank of current case (minimum rank for ties)\n\n\ndense_rank()\nrank of current case (minimum rank for ties, no gaps)\n\n\npercent_rank()\nmin_rank of current case (scaled to [0,1])\n\n\ncume_dist()\ncumulative empirical distribution (prop. less than current rank)\n\n\nrow_number()\nrank of current case (first row for ties)\n\n\nntile()\nbin into (n) buckets\n\n\n\n\ncummmax/ cummin/ cummeancumsum/ cumprodrank/ min_rank/ dense_rank/ percent_rankcumulative empirical distributionrank row numberbin into buckets\n\n\n\ndat.1 |&gt; mutate(Cummin = cummin(Resp1),\n                 Cummax = cummax(Resp1),\n                 Cummean = cummean(Resp1)) |&gt;\n    head()\n\n  Treatment Plot Dose Time Resp1 Resp2 Cummin Cummax Cummean\n1   Control   P1    H    1  8.12  3.06   8.12   8.12  8.1200\n2   Control   P1    H    2 20.55 25.94   8.12  20.55 14.3350\n3   Control   P1    H    3 27.49 29.85   8.12  27.49 18.7200\n4   Control   P1    H    4 44.79 25.39   8.12  44.79 25.2375\n5   Control   P1    M    1 20.99 20.31   8.12  44.79 24.3880\n6   Control   P1    M    2 37.54 17.62   8.12  44.79 26.5800\n\n\n\n\n\ndat.1 |&gt; mutate(Cumsum = cumsum(Resp1),\n                 Cumprod = cumprod(Resp1)) |&gt;\n    head()\n\n  Treatment Plot Dose Time Resp1 Resp2 Cumsum      Cumprod\n1   Control   P1    H    1  8.12  3.06   8.12 8.120000e+00\n2   Control   P1    H    2 20.55 25.94  28.67 1.668660e+02\n3   Control   P1    H    3 27.49 29.85  56.16 4.587146e+03\n4   Control   P1    H    4 44.79 25.39 100.95 2.054583e+05\n5   Control   P1    M    1 20.99 20.31 121.94 4.312569e+06\n6   Control   P1    M    2 37.54 17.62 159.48 1.618939e+08\n\n\n\n\n\ndat.1 |&gt; mutate(Rank = rank(Resp1),\n                 minRank = min_rank(Resp1),\n                 denseRank = dense_rank(Resp1),\n                 percentRank = percent_rank(Resp1)) |&gt;\n    head()\n\n  Treatment Plot Dose Time Resp1 Resp2 Rank minRank denseRank percentRank\n1   Control   P1    H    1  8.12  3.06    1       1         1   0.0000000\n2   Control   P1    H    2 20.55 25.94    6       6         6   0.1063830\n3   Control   P1    H    3 27.49 29.85    9       9         9   0.1702128\n4   Control   P1    H    4 44.79 25.39   20      20        20   0.4042553\n5   Control   P1    M    1 20.99 20.31    7       7         7   0.1276596\n6   Control   P1    M    2 37.54 17.62   13      13        13   0.2553191\n\n\n\n\n\ndat.1 |&gt; mutate(cume_dist(Resp1)) |&gt;\n    head()\n\n  Treatment Plot Dose Time Resp1 Resp2 cume_dist(Resp1)\n1   Control   P1    H    1  8.12  3.06       0.02083333\n2   Control   P1    H    2 20.55 25.94       0.12500000\n3   Control   P1    H    3 27.49 29.85       0.18750000\n4   Control   P1    H    4 44.79 25.39       0.41666667\n5   Control   P1    M    1 20.99 20.31       0.14583333\n6   Control   P1    M    2 37.54 17.62       0.27083333\n\n\n\n\n\ndat.1 |&gt; mutate(row_number(Resp1)) |&gt;\n    head()\n\n  Treatment Plot Dose Time Resp1 Resp2 row_number(Resp1)\n1   Control   P1    H    1  8.12  3.06                 1\n2   Control   P1    H    2 20.55 25.94                 6\n3   Control   P1    H    3 27.49 29.85                 9\n4   Control   P1    H    4 44.79 25.39                20\n5   Control   P1    M    1 20.99 20.31                 7\n6   Control   P1    M    2 37.54 17.62                13\n\n\n\n\n\ndat.1 |&gt; mutate(ntile(Resp1, 5)) |&gt;\n    head()\n\n  Treatment Plot Dose Time Resp1 Resp2 ntile(Resp1, 5)\n1   Control   P1    H    1  8.12  3.06               1\n2   Control   P1    H    2 20.55 25.94               1\n3   Control   P1    H    3 27.49 29.85               1\n4   Control   P1    H    4 44.79 25.39               2\n5   Control   P1    M    1 20.99 20.31               1\n6   Control   P1    M    2 37.54 17.62               2"
  },
  {
    "objectID": "04_data_wrangling.html#miscellaneous",
    "href": "04_data_wrangling.html#miscellaneous",
    "title": "Data wrangling (tidyverse and friends)",
    "section": "6.4 Miscellaneous",
    "text": "6.4 Miscellaneous\n\n\n\n\n\n\n\n\nFunction\nDescription\n\n\n\n\nif_else()\nelementwise (case by case) if and else\n\n\ncase_when()\nelementwise multiple if_else\n\n\nna_if()\nelementwise replace nominated value with NA\n\n\npmax()\nelementwise maximum across multiple columns\n\n\npmin()\nelementwise minimum across multiple columns\n\n\n\n\nif_elsecase_when\n\n\n\ndat.1 |&gt; mutate(Size = if_else(Resp1 &gt; 25, \"Big\", \"Small\")) |&gt;\n    head()\n\n  Treatment Plot Dose Time Resp1 Resp2  Size\n1   Control   P1    H    1  8.12  3.06 Small\n2   Control   P1    H    2 20.55 25.94 Small\n3   Control   P1    H    3 27.49 29.85   Big\n4   Control   P1    H    4 44.79 25.39   Big\n5   Control   P1    M    1 20.99 20.31 Small\n6   Control   P1    M    2 37.54 17.62   Big\n\n\n\n\n\ndat.1 |&gt; mutate(Size = case_when(Resp1 &lt; 15 ~ \"Small\",\n                               Resp1 &lt; 25 ~ \"Medium\",\n                               Resp1 &gt;= 25 ~ \"Big\")) |&gt;\n    head()\n\n  Treatment Plot Dose Time Resp1 Resp2   Size\n1   Control   P1    H    1  8.12  3.06  Small\n2   Control   P1    H    2 20.55 25.94 Medium\n3   Control   P1    H    3 27.49 29.85    Big\n4   Control   P1    H    4 44.79 25.39    Big\n5   Control   P1    M    1 20.99 20.31 Medium\n6   Control   P1    M    2 37.54 17.62    Big"
  },
  {
    "objectID": "04_data_wrangling.html#summary-functions-1",
    "href": "04_data_wrangling.html#summary-functions-1",
    "title": "Data wrangling (tidyverse and friends)",
    "section": "6.5 Summary functions",
    "text": "6.5 Summary functions\nSummary functions (those that return a single value) are also permissible - the value will be recycled for the total length of the input vector. A table of useful summary functions can be found in the Summarise section.\n\ndat.1 |&gt; mutate(meanResp1 = mean(Resp1)) |&gt;\n    head()\n\n  Treatment Plot Dose Time Resp1 Resp2 meanResp1\n1   Control   P1    H    1  8.12  3.06  75.26604\n2   Control   P1    H    2 20.55 25.94  75.26604\n3   Control   P1    H    3 27.49 29.85  75.26604\n4   Control   P1    H    4 44.79 25.39  75.26604\n5   Control   P1    M    1 20.99 20.31  75.26604\n6   Control   P1    M    2 37.54 17.62  75.26604\n\n\nAnother important summary function is the n() function. This function returns the total number of rows. In the following example, we will use it to create a column that just provides a running row counter (e.g. a row index variable).\n\ndat.1 |&gt; mutate(N = 1:n()) |&gt;\n    head()\n\n  Treatment Plot Dose Time Resp1 Resp2 N\n1   Control   P1    H    1  8.12  3.06 1\n2   Control   P1    H    2 20.55 25.94 2\n3   Control   P1    H    3 27.49 29.85 3\n4   Control   P1    H    4 44.79 25.39 4\n5   Control   P1    M    1 20.99 20.31 5\n6   Control   P1    M    2 37.54 17.62 6"
  },
  {
    "objectID": "04_data_wrangling.html#multiple-mutations-across",
    "href": "04_data_wrangling.html#multiple-mutations-across",
    "title": "Data wrangling (tidyverse and friends)",
    "section": "6.6 Multiple mutations (across)",
    "text": "6.6 Multiple mutations (across)\nIn the section on select, a set of select helper functions were described to facilitate convenient ways to select columns based on properties of the column names etc. The across() function allows us to bring those same selection helper functions to mutate.\nThe across() function has the following form:\n\nacross(.cols, .fns, .names)\n\nwhere:\n\n.cols - a tidy selection (e.g. selection helper function)\n.fns - a function (or list of functions) to apply to each selected column\n.names - a glue specification determining the format of the new variable names. By default the glue will be either {.col} (when there is only a single function) or {.col}.{fn} (when a list of functions)\n\n\nSimple selectionsSimple selections with namingwhere selections with namingnum_range selections with namingMultiple selections and functionsAdditional arguments to the function(s)\n\n\n\ndat.1 |&gt; mutate(across(c(Resp1, Resp2), log)) |&gt;\n    head()\n\n  Treatment Plot Dose Time    Resp1    Resp2\n1   Control   P1    H    1 2.094330 1.118415\n2   Control   P1    H    2 3.022861 3.255786\n3   Control   P1    H    3 3.313822 3.396185\n4   Control   P1    H    4 3.801985 3.234355\n5   Control   P1    M    1 3.044046 3.011113\n6   Control   P1    M    2 3.625407 2.869035\n\n\n\n\n\ndat.1 |&gt; mutate(across(c(Resp1, Resp2),\n                        .fns = log,\n                        .names = \"l{.col}\")) |&gt;\n    head()\n\n  Treatment Plot Dose Time Resp1 Resp2   lResp1   lResp2\n1   Control   P1    H    1  8.12  3.06 2.094330 1.118415\n2   Control   P1    H    2 20.55 25.94 3.022861 3.255786\n3   Control   P1    H    3 27.49 29.85 3.313822 3.396185\n4   Control   P1    H    4 44.79 25.39 3.801985 3.234355\n5   Control   P1    M    1 20.99 20.31 3.044046 3.011113\n6   Control   P1    M    2 37.54 17.62 3.625407 2.869035\n\n\n\n\n\ndat.1 |&gt; mutate(across(where(is.numeric),\n                        .fns = log,\n                        .names = \"l{.col}\")) |&gt;\n    head()\n\n  Treatment Plot Dose Time Resp1 Resp2     lTime   lResp1   lResp2\n1   Control   P1    H    1  8.12  3.06 0.0000000 2.094330 1.118415\n2   Control   P1    H    2 20.55 25.94 0.6931472 3.022861 3.255786\n3   Control   P1    H    3 27.49 29.85 1.0986123 3.313822 3.396185\n4   Control   P1    H    4 44.79 25.39 1.3862944 3.801985 3.234355\n5   Control   P1    M    1 20.99 20.31 0.0000000 3.044046 3.011113\n6   Control   P1    M    2 37.54 17.62 0.6931472 3.625407 2.869035\n\n\n\n\n\ndat.1 |&gt; mutate(across(num_range(\"Resp\", 1:2),\n                        .fns = log,\n                        .names = \"l{.col}\")) |&gt;\n    head()\n\n  Treatment Plot Dose Time Resp1 Resp2   lResp1   lResp2\n1   Control   P1    H    1  8.12  3.06 2.094330 1.118415\n2   Control   P1    H    2 20.55 25.94 3.022861 3.255786\n3   Control   P1    H    3 27.49 29.85 3.313822 3.396185\n4   Control   P1    H    4 44.79 25.39 3.801985 3.234355\n5   Control   P1    M    1 20.99 20.31 3.044046 3.011113\n6   Control   P1    M    2 37.54 17.62 3.625407 2.869035\n\n\n\n\n\ndat.1 |&gt; mutate(across(c(Resp1, Resp2),\n                        .fns = list(l = log, s = sqrt),\n                        .names = \"{.fn}.{.col}\")) |&gt;\n    head()\n\n  Treatment Plot Dose Time Resp1 Resp2  l.Resp1  s.Resp1  l.Resp2  s.Resp2\n1   Control   P1    H    1  8.12  3.06 2.094330 2.849561 1.118415 1.749286\n2   Control   P1    H    2 20.55 25.94 3.022861 4.533211 3.255786 5.093133\n3   Control   P1    H    3 27.49 29.85 3.313822 5.243091 3.396185 5.463515\n4   Control   P1    H    4 44.79 25.39 3.801985 6.692533 3.234355 5.038849\n5   Control   P1    M    1 20.99 20.31 3.044046 4.581484 3.011113 4.506662\n6   Control   P1    M    2 37.54 17.62 3.625407 6.126989 2.869035 4.197618\n\n\n\n\nCentring all numeric variables (note the use of the purrr style lambda formula for functions that require additional arguments. When applying the function, the focal variable is assigned the name of .x.\n\ndat.1 |&gt; mutate(across(c(Resp1, Resp2),\n                        .fns = list(c =  ~ scale(.x, scale = FALSE)),\n                        .names = \"{.fn}{.col}\")) |&gt;\n    head()\n\n  Treatment Plot Dose Time Resp1 Resp2    cResp1    cResp2\n1   Control   P1    H    1  8.12  3.06 -67.14604 -78.64958\n2   Control   P1    H    2 20.55 25.94 -54.71604 -55.76958\n3   Control   P1    H    3 27.49 29.85 -47.77604 -51.85958\n4   Control   P1    H    4 44.79 25.39 -30.47604 -56.31958\n5   Control   P1    M    1 20.99 20.31 -54.27604 -61.39958\n6   Control   P1    M    2 37.54 17.62 -37.72604 -64.08958"
  },
  {
    "objectID": "04_data_wrangling.html#changing-vectors",
    "href": "04_data_wrangling.html#changing-vectors",
    "title": "Data wrangling (tidyverse and friends)",
    "section": "6.7 Changing vectors",
    "text": "6.7 Changing vectors\n\nCast to different classChange factor labelsChange factor levelsChange factor levels and labelsChange factor levels to reflect data orderChange factor levels according to a numeric variable\n\n\nConvert Time (a numeric) into a factor\n\ndat.1 |&gt; mutate(Time = factor(Time)) |&gt;\n    tibble()\n\n# A tibble: 48 × 6\n   Treatment Plot  Dose  Time  Resp1  Resp2\n   &lt;fct&gt;     &lt;fct&gt; &lt;fct&gt; &lt;fct&gt; &lt;dbl&gt;  &lt;dbl&gt;\n 1 Control   P1    H     1      8.12   3.06\n 2 Control   P1    H     2     20.6   25.9 \n 3 Control   P1    H     3     27.5   29.8 \n 4 Control   P1    H     4     44.8   25.4 \n 5 Control   P1    M     1     21.0   20.3 \n 6 Control   P1    M     2     37.5   17.6 \n 7 Control   P1    M     3     61.5   98.4 \n 8 Control   P1    M     4     82.2  160.  \n 9 Control   P1    L     1     31.7   21.2 \n10 Control   P1    L     2     59.1   37.5 \n# ℹ 38 more rows\n\n\n\n\nChange the labels of the “H” and “M” levels of Dose\n\ndat.1 |&gt; mutate(Dose = fct_recode(Dose, High = 'H',  Medium = 'M')) |&gt;\n    tibble()\n\n# A tibble: 48 × 6\n   Treatment Plot  Dose    Time Resp1  Resp2\n   &lt;fct&gt;     &lt;fct&gt; &lt;fct&gt;  &lt;int&gt; &lt;dbl&gt;  &lt;dbl&gt;\n 1 Control   P1    High       1  8.12   3.06\n 2 Control   P1    High       2 20.6   25.9 \n 3 Control   P1    High       3 27.5   29.8 \n 4 Control   P1    High       4 44.8   25.4 \n 5 Control   P1    Medium     1 21.0   20.3 \n 6 Control   P1    Medium     2 37.5   17.6 \n 7 Control   P1    Medium     3 61.5   98.4 \n 8 Control   P1    Medium     4 82.2  160.  \n 9 Control   P1    L          1 31.7   21.2 \n10 Control   P1    L          2 59.1   37.5 \n# ℹ 38 more rows\n\ndat.1 |&gt; mutate(Dose = fct_recode(Dose, High = 'H',  Medium = 'M')) |&gt;\n    str()\n\n'data.frame':   48 obs. of  6 variables:\n $ Treatment: Factor w/ 2 levels \"Control\",\"Exclusion\": 1 1 1 1 1 1 1 1 1 1 ...\n $ Plot     : Factor w/ 4 levels \"P1\",\"P2\",\"P3\",..: 1 1 1 1 1 1 1 1 1 1 ...\n $ Dose     : Factor w/ 3 levels \"High\",\"L\",\"Medium\": 1 1 1 1 3 3 3 3 2 2 ...\n $ Time     : int  1 2 3 4 1 2 3 4 1 2 ...\n $ Resp1    : num  8.12 20.55 27.49 44.79 20.99 ...\n $ Resp2    : num  3.06 25.94 29.85 25.39 20.31 ...\n - attr(*, \"out.attrs\")=List of 2\n  ..$ dim     : Named int [1:3] 4 3 4\n  .. ..- attr(*, \"names\")= chr [1:3] \"Time\" \"Dose\" \"Plot\"\n  ..$ dimnames:List of 3\n  .. ..$ Time: chr [1:4] \"Time=1\" \"Time=2\" \"Time=3\" \"Time=4\"\n  .. ..$ Dose: chr [1:3] \"Dose=H\" \"Dose=M\" \"Dose=L\"\n  .. ..$ Plot: chr [1:4] \"Plot=P1\" \"Plot=P2\" \"Plot=P3\" \"Plot=P4\"\n\n\n\n\nChange the level order of the Dose factor to something more natural.\n\ndat.1 |&gt; pull(Dose)\n\n [1] H H H H M M M M L L L L H H H H M M M M L L L L H H H H M M M M L L L L H H\n[39] H H M M M M L L L L\nLevels: H L M\n\ndat.1 |&gt;\n    mutate(Dose = fct_relevel(Dose, c(\"L\", \"M\", \"H\"))) |&gt; \n    as_tibble() |&gt;\n    pull(Dose)\n\n [1] H H H H M M M M L L L L H H H H M M M M L L L L H H H H M M M M L L L L H H\n[39] H H M M M M L L L L\nLevels: L M H\n\n\n\n\nChange the labels and level order of the Dose factor to something more natural.\n\ndat.1 |&gt; pull(Dose)\ndat.1 |&gt; mutate(\n              Dose = fct_relevel(Dose, c(\"L\", \"M\", \"H\")),\n              Dose = fct_recode(Dose, High = 'H',  Medium = 'M')\n              ) |&gt;\n    as_tibble |&gt; \n    pull(Dose)\n\nError: The pipe operator requires a function call as RHS (&lt;text&gt;:6:5)\n\n\n\n\n\ndat.1 |&gt; pull(Dose)\ndat.1 |&gt; mutate(Dose = fct_reorder(Dose, 1:n())) |&gt;\n    as_tibble |&gt; \n    pull(Dose)\n\nError: The pipe operator requires a function call as RHS (&lt;text&gt;:3:5)\n\n\n\n\nChange the order of Dose levels according to the median Resp1 values\n\ndat.1 |&gt; pull(Dose)\ndat.1 |&gt; mutate(Dose = fct_reorder(Dose, Resp1, median)) |&gt;\n    as_tibble |&gt; \n    pull(Dose)\n\nError: The pipe operator requires a function call as RHS (&lt;text&gt;:3:5)"
  },
  {
    "objectID": "04_data_wrangling.html#count",
    "href": "04_data_wrangling.html#count",
    "title": "Data wrangling (tidyverse and friends)",
    "section": "7.1 Count",
    "text": "7.1 Count\nThe count() function provides a convenient way to count up the number of unique combinations of factors.\n\nCount single factorCount multiple factors\n\n\n\ndat.1 |&gt; count(Dose)\n\n  Dose  n\n1    H 16\n2    L 16\n3    M 16\n\n\n\n\n\ndat.1 |&gt; count(Dose, between(Resp1, 30, 50))\n\n  Dose between(Resp1, 30, 50)  n\n1    H                  FALSE 11\n2    H                   TRUE  5\n3    L                  FALSE 14\n4    L                   TRUE  2\n5    M                  FALSE 12\n6    M                   TRUE  4"
  },
  {
    "objectID": "04_data_wrangling.html#wide-to-long-pivot_longer",
    "href": "04_data_wrangling.html#wide-to-long-pivot_longer",
    "title": "Data wrangling (tidyverse and friends)",
    "section": "9.1 Wide to long (pivot_longer)",
    "text": "9.1 Wide to long (pivot_longer)\nWhilst wide data formats are often more compact and typically easier to manage for data entry (particularly in the field), the data are not in the appropriate format for most analyses (traditional repeated measures and multivariate analyses are two exceptions). Most analyses require that each replicate is in its own row and thus it is necessary to be rearrange or reshape (melt) the data from this wide format to the long (molten) format.\n\n\n\n\n\nWhilst there are numerous routines in R for reshaping data, we will only explore those that are formally part of the tidyverse ecosystem.\nThe pivot_longer() function (tidyr package) is very useful for converting wide (repeated measures-like) into long format. The important parameters to specify are:\n\npivot_longer(data, cols, names_to, values_to, values_drop_na)\n\nwhere:\n\ndata - the input dataframe or tibble\ncols - a tidy select specification of the columns to be lengthened into a single column\nnames_to - a name (string) to give a new column into which to store the names of the old wide column names\nvalues_to - a name (string) to give the new column containing the values that were previously in the old columns.\nvalues_drop_na - whether or not to drop rows that only contain NA values in the new value column.\n\nTo illustrate, we will use the dat.w dataframe.\n\n\n\nThe `data.w` data.frame\n\n\n\nPlot\nBetween\nTime.0\nTime.1\nTime.2\n\n\n\n\nR1\nP1\nA1\n8\n14\n14\n\n\nR2\nP2\nA1\n10\n12\n11\n\n\nR3\nP3\nA2\n7\n11\n8\n\n\nR4\nP4\nA2\n11\n9\n2\n\n\n\n\n\n\n\n\nPivot longerPivot longer (with starts_with)\n\n\n\ndata.w |&gt; pivot_longer(Time.0:Time.2,\n                        names_to = \"Time\",\n                        values_to = \"Count\")\n\n# A tibble: 12 × 4\n   Plot  Between Time   Count\n   &lt;fct&gt; &lt;fct&gt;   &lt;chr&gt;  &lt;int&gt;\n 1 P1    A1      Time.0     8\n 2 P1    A1      Time.1    14\n 3 P1    A1      Time.2    14\n 4 P2    A1      Time.0    10\n 5 P2    A1      Time.1    12\n 6 P2    A1      Time.2    11\n 7 P3    A2      Time.0     7\n 8 P3    A2      Time.1    11\n 9 P3    A2      Time.2     8\n10 P4    A2      Time.0    11\n11 P4    A2      Time.1     9\n12 P4    A2      Time.2     2\n\n\n\n\n\ndata.w |&gt; pivot_longer(starts_with(\"Time\"),\n                        names_to = \"Time\",\n                        names_prefix = \"Time.\",\n                        values_to = \"Count\"\n                        )\n\n# A tibble: 12 × 4\n   Plot  Between Time  Count\n   &lt;fct&gt; &lt;fct&gt;   &lt;chr&gt; &lt;int&gt;\n 1 P1    A1      0         8\n 2 P1    A1      1        14\n 3 P1    A1      2        14\n 4 P2    A1      0        10\n 5 P2    A1      1        12\n 6 P2    A1      2        11\n 7 P3    A2      0         7\n 8 P3    A2      1        11\n 9 P3    A2      2         8\n10 P4    A2      0        11\n11 P4    A2      1         9\n12 P4    A2      2         2"
  },
  {
    "objectID": "04_data_wrangling.html#long-to-wide-pivot_wider",
    "href": "04_data_wrangling.html#long-to-wide-pivot_wider",
    "title": "Data wrangling (tidyverse and friends)",
    "section": "9.2 Long to wide (pivot_wider)",
    "text": "9.2 Long to wide (pivot_wider)\nThe opposite of making a data set longer is to make a data set wider. Whilst analytical and graphical routines might require data to be in long format, wide tabular summaries are typically more compact and familiar.\n\n\n\n\n\nWidening is performed via the pivot_wider() function, the most important parameters of which are:\n\npivot_wider(data, id_cols, names_from, values_from\n\nwhere:\n\ndata - the input dataframe or tibble\nid_cols - a tidy select specification of the columns that uniquely identify the case - these columns will not be widened.\nnames_from - a tidy select specification of the column(s) that contain the names to be used as new column names.\nvalues_from - a tidy select specification of the column(s) that contain the values to be used as values in the new columns (e.g, the data to be widened).\n\nTo illustrate, we will use the dat.w dataframe.\n\n\n\nThe `data` data.frame\n\n\nResp1\nResp2\nBetween\nPlot\nSubplot\nWithin\n\n\n\n\n8\n17\nA1\nP1\nS1\nB1\n\n\n10\n18\nA1\nP1\nS1\nB2\n\n\n7\n17\nA1\nP1\nS2\nB1\n\n\n11\n21\nA1\nP1\nS2\nB2\n\n\n14\n19\nA2\nP2\nS3\nB1\n\n\n12\n13\nA2\nP2\nS3\nB2\n\n\n11\n24\nA2\nP2\nS4\nB1\n\n\n9\n18\nA2\nP2\nS4\nB2\n\n\n14\n25\nA3\nP3\nS5\nB1\n\n\n11\n18\nA3\nP3\nS5\nB2\n\n\n8\n27\nA3\nP3\nS6\nB1\n\n\n2\n22\nA3\nP3\nS6\nB2\n\n\n8\n17\nA1\nP4\nS7\nB1\n\n\n10\n22\nA1\nP4\nS7\nB2\n\n\n7\n16\nA1\nP4\nS8\nB1\n\n\n12\n13\nA1\nP4\nS8\nB2\n\n\n11\n23\nA2\nP5\nS9\nB1\n\n\n12\n19\nA2\nP5\nS9\nB2\n\n\n12\n23\nA2\nP5\nS10\nB1\n\n\n10\n21\nA2\nP5\nS10\nB2\n\n\n3\n17\nA3\nP6\nS11\nB1\n\n\n11\n16\nA3\nP6\nS11\nB2\n\n\n13\n26\nA3\nP6\nS12\nB1\n\n\n7\n28\nA3\nP6\nS12\nB2\n\n\n\n\n\n\n\nNote, these data are not as long as they could be. Purely “long” data should have each observation in its own row. The data dataframe has two observations (one for “Resp1” and one for “Resp2”) per row.\n\nPivot wider for Resp1 onlyPivot wider for Resp1 and Resp2\n\n\nWiden the “Resp1” variable by the levels of the Between factor.\n\ndata |&gt; select(-Resp2) |&gt;\n    pivot_wider(names_from = Within,\n                values_from = c(Resp1))\n\n# A tibble: 12 × 5\n   Between Plot  Subplot    B1    B2\n   &lt;fct&gt;   &lt;fct&gt; &lt;fct&gt;   &lt;int&gt; &lt;int&gt;\n 1 A1      P1    S1          8    10\n 2 A1      P1    S2          7    11\n 3 A2      P2    S3         14    12\n 4 A2      P2    S4         11     9\n 5 A3      P3    S5         14    11\n 6 A3      P3    S6          8     2\n 7 A1      P4    S7          8    10\n 8 A1      P4    S8          7    12\n 9 A2      P5    S9         11    12\n10 A2      P5    S10        12    10\n11 A3      P6    S11         3    11\n12 A3      P6    S12        13     7\n\n\n\n\nWiden the “Resp1” and “Resp2” variables by the levels of the Between factor.\n\ndata |&gt; pivot_wider(names_from = Within,\n                values_from = starts_with(\"Resp\"))\n\n# A tibble: 12 × 7\n   Between Plot  Subplot Resp1_B1 Resp1_B2 Resp2_B1 Resp2_B2\n   &lt;fct&gt;   &lt;fct&gt; &lt;fct&gt;      &lt;int&gt;    &lt;int&gt;    &lt;int&gt;    &lt;int&gt;\n 1 A1      P1    S1             8       10       17       18\n 2 A1      P1    S2             7       11       17       21\n 3 A2      P2    S3            14       12       19       13\n 4 A2      P2    S4            11        9       24       18\n 5 A3      P3    S5            14       11       25       18\n 6 A3      P3    S6             8        2       27       22\n 7 A1      P4    S7             8       10       17       22\n 8 A1      P4    S8             7       12       16       13\n 9 A2      P5    S9            11       12       23       19\n10 A2      P5    S10           12       10       23       21\n11 A3      P6    S11            3       11       17       16\n12 A3      P6    S12           13        7       26       28\n\n\nAlternatively we could make the data longer before widening\n\ndata |&gt;\n    pivot_longer(cols = starts_with(\"Resp\")) |&gt;\n    pivot_wider(names_from = c(name, Within),\n                values_from = value)\n\n# A tibble: 12 × 7\n   Between Plot  Subplot Resp1_B1 Resp2_B1 Resp1_B2 Resp2_B2\n   &lt;fct&gt;   &lt;fct&gt; &lt;fct&gt;      &lt;int&gt;    &lt;int&gt;    &lt;int&gt;    &lt;int&gt;\n 1 A1      P1    S1             8       17       10       18\n 2 A1      P1    S2             7       17       11       21\n 3 A2      P2    S3            14       19       12       13\n 4 A2      P2    S4            11       24        9       18\n 5 A3      P3    S5            14       25       11       18\n 6 A3      P3    S6             8       27        2       22\n 7 A1      P4    S7             8       17       10       22\n 8 A1      P4    S8             7       16       12       13\n 9 A2      P5    S9            11       23       12       19\n10 A2      P5    S10           12       23       10       21\n11 A3      P6    S11            3       17       11       16\n12 A3      P6    S12           13       26        7       28"
  },
  {
    "objectID": "04_data_wrangling.html#vlookup-in-r",
    "href": "04_data_wrangling.html#vlookup-in-r",
    "title": "Data wrangling (tidyverse and friends)",
    "section": "12.1 VLOOKUP in R",
    "text": "12.1 VLOOKUP in R\nLookup tables provide a way of inserting a column of data into a large data set such that the entries in the new column are determined by a relational match within another data set (the lookup table). For example, the main data set might contain data collected from a number of sites (Plots). Elsewhere we may have a data set that just contains the set of sites and their corresponding latitudes and longitudes (geographical lookup table). We could incorporate these latitudes and longitudes into the main data set by merging against the geographical lookup table. In Excel, this is referred to as vlookup, in a relational database (and in tidyverse) it is referred to as a join.\nIf we again consider our data.bio data, but this time also consider the data.geo data. This later dataset contains the latitude and longitude of each of the plots.\n\n\n\n\n\n\n\nResp1\nResp2\nBetween\nPlot\nSubplot\n\n\n\n\n8\n18\nA1\nP1\nS1\n\n\n10\n21\nA1\nP1\nS2\n\n\n11\n23\nA1\nP2\nS4\n\n\n14\n22\nA2\nP3\nS5\n\n\n12\n24\nA2\nP3\nS6\n\n\n11\n23\nA2\nP4\nS7\n\n\n9\n20\nA2\nP4\nS8\n\n\n14\n11\nA3\nP5\nS9\n\n\n11\n22\nA3\nP5\nS10\n\n\n8\n24\nA3\nP6\nS11\n\n\n2\n16\nA3\nP6\nS12\n\n\n\n\n\n\n\n\n\n\n\n\n\nPlot\nLAT\nLONG\n\n\n\n\nP1\n17.9605\n145.4326\n\n\nP2\n17.5210\n146.1983\n\n\nP3\n17.0011\n146.3839\n\n\nP4\n18.2350\n146.7934\n\n\nP5\n18.9840\n146.0345\n\n\nP6\n20.1154\n146.4672\n\n\n\n\n\n\n\n\n\n\nKeep all bio information (left_join)\n\n\n\ndata.bio |&gt; left_join(data.geo)\n\n   Resp1 Resp2 Between Plot Subplot     LAT     LONG\n1      8    18      A1   P1      S1 17.9605 145.4326\n2     10    21      A1   P1      S2 17.9605 145.4326\n3     11    23      A1   P2      S4 17.5210 146.1983\n4     14    22      A2   P3      S5 17.0011 146.3839\n5     12    24      A2   P3      S6 17.0011 146.3839\n6     11    23      A2   P4      S7 18.2350 146.7934\n7      9    20      A2   P4      S8 18.2350 146.7934\n8     14    11      A3   P5      S9 18.9840 146.0345\n9     11    22      A3   P5     S10 18.9840 146.0345\n10     8    24      A3   P6     S11 20.1154 146.4672\n11     2    16      A3   P6     S12 20.1154 146.4672"
  },
  {
    "objectID": "05_grammar_of_graphics.html",
    "href": "05_grammar_of_graphics.html",
    "title": "The grammar of graphics (ggplot2)",
    "section": "",
    "text": "This Tutorial has been thrown together a little hastily and is therefore not very well organised - sorry! Graphical features are demonstrated either via tables of properties or as clickable graphics that reveal the required R code. Click on a graphic to reveal/toggle the source code or to navigate to an expanded section.\nThis tutorial is intended to be viewed sequentially. It begins with the basic ggplot framework and then progressively builds up more and more features as default elements are gradually replaced to yeild more customized graphics.\nHaving said that, I am going to start with a sort of showcase of graphics which should act as quick navigation to entire sections devoted to the broad series of graphs related to each of the featured graphics. I have intentionally titled each graph according to the main feature it encapsulates rather than any specific functions that are used to produce the features as often a single graphic requires a combination of features and thus functions. Furthermore, the grammar of graphics specifications are sufficiently unfamiliar to many that the relationships between the types of graphical features a researcher wishes to produce and the specific syntax required to achieve the desired result can be difficult to recognise.\nEach graphic is intended to encapsulate a broad series of related graph types."
  },
  {
    "objectID": "05_grammar_of_graphics.html#primitive-geoms",
    "href": "05_grammar_of_graphics.html#primitive-geoms",
    "title": "The grammar of graphics (ggplot2)",
    "section": "2.1 Primitive geoms",
    "text": "2.1 Primitive geoms\nPrimitive geoms are simple plotting shapes that typically represent direct mapping of data variables to the shapes - that is, they do not require specific stat functions. Hence, all primitive geoms use stat_identity. Nevertheless, it is possible to have the shapes mapped via alternative stats functions is appropriate (see points).\n\nBlank Points Text Paths Polygons Areas Ribbons \n\n\nAlthough this might seem pointless, it can be useful for forcing axes scales to conform to a particular format - since axes scales are determined by the first layer (which can be blank) defined in the sequence of expressions.\nTo help illustrate this, I will introduce a fabricated data set comprising the length (mm) of 10 day old frog tadpoles incubated at three different temperatures (Low, Medium, High).\n\n\n\ntadpole &lt;- tribble(\n    ~length, ~temp,\n    2.1,     \"Low\",\n    2.0,     \"Low\",\n    1.8,     \"Low\",\n    2.2,     \"Medium\",\n    2.3,     \"Medium\",\n    2.3,     \"Medium\",\n    2.5,     \"High\",\n    2.7,     \"High\",\n    2.8,     \"High\",\n    ) %&gt;%\n    mutate(temp = factor(temp))\n\n\n\nNow imagine you wish to produce a scatterplot (with length mapped to the y-axis and day mapped to the x-axis) to explore these data. Since although temp is categorical, it is ordered, we would also like to plot a line representing the overall trend in tadpole length in relation to temperature. Doing so would introduce one of two problems:\n\nlines can only be plotted when both x and y are mapped to continuous variables\nin order to plot a line, we would need to convert temperature into a numeric variable in some way, however doing so would mean that the axes labels loose their meaning.\n\n\n\nUsing a geom_blank allows us to define a line and maintain useful axes labels. The second and third examples below will illustrate the problem and solution respectively.\n\n\n\n\n\nFeature\n\n\ngeom\n\n\nstat\n\n\nposition\n\n\nAesthetic parameters / Notes\n\n\nExample plot\n\n\n\n\n\n\nBlank layer\n\n\n_blank\n\n\n_identity\n\n\nidentity\n\n\nx,y\n\n\n\n\n\n\n\n\n\n\n\n\nggplot(data=tadpole, aes(y = length, x = temp)) +\n    geom_blank()\n\n\n\n\n\nBlank layer\n\n\n_blank\n\n\n_summary\n\n\nidentity\n\n\nx,y\n\n\n\n\n\n\n\n\n\n\n\n\nggplot(data=tadpole, aes(y = length, x = as.numeric(temp))) +\n    geom_line(stat = 'summary', fun = mean) \n\n\n\n\n\nBlank layer\n\n\n_blank\n\n\n_summary\n\n\nidentity\n\n\nx,y\n\n\n\n\n\n\n\n\n\n\n\n\nggplot(data=tadpole, aes(y = length, x = temp))+\n    geom_blank() +\n    geom_line(aes(x = as.numeric(temp)),\n                  stat = 'summary', fun = mean) \n\n\n\n\n\n\n\n\ngeom_point draws points (scatterplot). Typically the stat used is stat_identity as we wish to use the values in two continuous vectors as the coordinates of each point.\nThe following list describes the mapping aesthetic properties associated with geom_point. The entries in bold are compulsory.\n\n\nShow attributes\n\n\n\n\n\n\n\n\n\nParameter\ngeom_point\n\n\n\n\naesthetics\n\n\n\nx - variable to map to the x-axis\n✔\n\n\ny - variable to map to the y-axis\n✔\n\n\ngroup - plot separate series without aesthetic differences\n✔\n\n\nalpha - transparency\n✔\n\n\ncolour - colour of the points/lines\n✔\n\n\nfill - inner colour of points/shapes\n✔\n\n\nlinetype - type of lines used to construct points/lines\n✔\n\n\nsize - thickness of the line\n✔\n\n\nshape - the plotting symbol/character\n✔\n\n\nweight - weightings of values\n✔\n\n\n\n\n\n\n\n\n\nFeature\n\n\ngeom\n\n\nstat\n\n\nposition\n\n\nAesthetic parameters / Notes\n\n\nExample plot\n\n\n\n\n\n\npoints layer\n\n\n_point\n\n\n_identity\n\n\nidentity\n\n\nx,ygeom_point forms the basis of various plots such as scatterplots, maps and others\n\n\n\n\n\n\n\n\n\n\n\n\nggplot(data=df, aes(y = y, x = x)) +\n    geom_point()\n\n\n\n\n\nmeans points layer\n\n\n_point\n\n\n_identity\n\n\nidentity\n\n\nx,y,funplots points based on the values provided\n\n\n\n\n\n\n\n\n\n\n\n\nggplot(data=CO2, aes(x = conc, y = uptake)) +\n    geom_point()\n\n\n\n\n\nmeans points layer\n\n\n_point\n\n\n_summary\n\n\nidentity\n\n\nx,y,funplots the result of the specified summary function\n\n\n\n\n\n\n\n\n\n\n\n\nggplot(data=CO2, aes(x = conc, y = uptake)) +\n    geom_point(stat = \"summary\", fun = mean)\n\n\n\n\n\n\nThe plotting symbols are specified by either a number (index of a plotting symbol - see below) or a single character (printed literally).\n\n\n\n\n\n\n\nThe following list describes the mapping aesthetic properties associated with geom_text. The entries in bold are compulsory.\n\n\nShow attributes\n\n\n\n\n\n\n\n\n\nParameter\ngeom_text\n\n\n\n\n- x - variable to map to the x-axis\n✔\n\n\n- y - variable to map to the y-axis\n✔\n\n\n- label - text to use as labels\n✔\n\n\n- group - plot separate series without aesthetic differences\n✔\n\n\n- alpha - transparency\n✔\n\n\n- colour - colour of the points/lines\n✔\n\n\n- fill - inner colour of points/shapes\n✔\n\n\n- linetype - type of lines used to construct points/lines\n✔\n\n\n- shape - symbol shape for points\n✔\n\n\n- size - size of symbol\n✔\n\n\n- family - font family\n✔\n\n\n- fontface - bold, italic, normal etc\n✔\n\n\n- hjust - horizontal justification\n✔\n\n\n- vjust - vertical justification\n✔\n\n\n\n\n\n\nadditional parameters\n\n\n\n- parse - whether to parse labels into expressions (to include special characters)\nFALSE\n\n\n- nudge_x - horizontal adjustments to label positions\n0\n\n\n- nudge_y - vertical adjustments to label positions\n0\n\n\n- check_overlap - whether to plot text that overlaps other text in layer\nFALSE\n\n\n\n\n\n\n\n\n\nFeature\n\n\ngeom\n\n\nstat\n\n\nposition\n\n\nAesthetic parameters / Notes\n\n\nExample plot\n\n\n\n\n\n\nText layer\n\n\n_text\n\n\n_identity\n\n\nidentity\n\n\nx,y,labelText on a plot - useful for depicting the location of observations\n\n\n\n\n\n\n\n\n\n\n\n\nggplot(data=df, aes(y = y, x = x)) +\n    geom_text(aes(label = z))\n\n\n\n\n\nText layer\n\n\n_text\n\n\n_identity\n\n\nidentity\n\n\nx,y,labelText on a plot - useful for depicting the location of observations\n\n\n\n\n\n\n\n\n\n\n\n\nggplot(data=CO2, aes(y = uptake, x = conc)) +\n    geom_text(aes(label = Treatment))\n\n\n\n\n\nText layer\n\n\n_text\n\n\n_identity\n\n\nidentity\n\n\nx,y,labelText on a plot - useful for depicting the location of observations\n\n\n\n\n\n\n\n\n\n\n\n\nggplot(data=CO2, aes(y = uptake, x = conc)) +\n    geom_text(aes(label = toupper(substr(Treatment, 1, 1))))\n\n\n\n\n\n\nHorizontal (hjust) and vertical (vjust) text justification controls are often a source of confusion and this is further exacerbated when combined with angle control. The following excellent demonstration from here provides a visual aid to understanding the use of these controls.\n\ntd &lt;- expand.grid(\n    hjust=c(0, 0.5, 1),\n    vjust=c(0, 0.5, 1),\n    angle=c(0, 45, 90),\n    text=\"text\"\n)\n\nggplot(td, aes(x=hjust, y=vjust)) + \n    geom_point() +\n    geom_text(aes(label=text, angle=angle, hjust=hjust, vjust=vjust)) + \n    facet_grid(~angle) +\n    scale_x_continuous(breaks=c(0, 0.5, 1), expand=c(0, 0.2)) +\n    scale_y_continuous(breaks=c(0, 0.5, 1), expand=c(0, 0.2))\n\n\n\n\n\n\ngeom_path draws paths (line plots). Paths order the coordinates according to the order in the data frame (c.f. geom_line and geom_step)\n\n\nShow attributes\n\n\n\n\n\n\n\n\n\nParameter\ngeom_path\n\n\n\n\n- x - variable to map to the x-axis\n✔\n\n\n- y - variable to map to the y-axis\n✔\n\n\n- group - plot separate series without aesthetic differences\n✔\n\n\n- alpha - transparency\n✔\n\n\n- colour - colour of the points/lines\n✔\n\n\n- fill - inner colour of points/shapes\n✔\n\n\n- linetype - type of lines used to construct points/lines\n✔\n\n\n- shape - symbol shape for points\n✔\n\n\n- size - size of symbol\n✔\n\n\n\n\n\n\nadditional parameters\n\n\n\n- lineend - line end style (round, butt, squate)\n‘butt’\n\n\n- linejoin - line join style (round, mitre, bevel)\n‘round’\n\n\n- linemitre - line mitre limit\n10\n\n\n- arrow - arrow specification (grid::arrow())\nNULL\n\n\n\n\n\n\n\n\n\nFeature\n\n\ngeom\n\n\nstat\n\n\nposition\n\n\nAesthetic parameters / Notes\n\n\nExample plot\n\n\n\n\n\n\npaths layer\n\n\n_path\n\n\n_identity\n\n\nidentity\n\n\nx,ygeom_path draws lines connecting coordinates in the order present in the data frame\n\n\n\n\n\n\n\n\n\n\n\n\nggplot(data=df, aes(y = y, x = x)) +\n    geom_path()\n\n\n\n\n\n\nThe simple line types available are highlighted in the following figure:\n\n\n\n\n\n\n\ngeom_polygon draws polygons with the coordinates ordered according to the order in the data frame.\n\n\nShow attributes\n\n\n\n\n\n\n\n\n\nParameter\ngeom_polygon\n\n\n\n\n- x - variable to map to the x-axis\n✔\n\n\n- y - variable to map to the y-axis\n✔\n\n\n- group - plot separate series without aesthetic differences\n✔\n\n\n- alpha - transparency\n✔\n\n\n- colour - colour of the points/lines\n✔\n\n\n- fill - inner colour of points/shapes\n✔\n\n\n- linetype - type of lines used to construct points/lines\n✔\n\n\n- shape - symbol shape for points\n✔\n\n\n- size - size of symbol\n✔\n\n\n\n\n\n\nadditional parameters\n\n\n\n- rule - determines how holes in polygons are treated\n‘evenodd’\n\n\n\n\n\n\n\n\n\nFeature\n\n\ngeom\n\n\nstat\n\n\nposition\n\n\nAesthetic parameters / Notes\n\n\nExample plot\n\n\n\n\n\n\npolygon layer\n\n\n_polygon\n\n\n_identity\n\n\nidentity\n\n\nx,ygeom_polygon draws polygons using coordinates in the order present in the data frame\n\n\n\n\n\n\n\n\n\n\n\n\nggplot(data=df, aes(y = y, x = x)) +\n    geom_polygon()\n\n\n\n\n\n\n\n\ngeom_area draws areas under curves with the coordinates ordered according to the order in the data frame.\n\n\nShow attributes\n\n\n\n\n\n\n\n\n\nParameter\ngeom_area\n\n\n\n\n- x - variable to map to the x-axis\n✔\n\n\n- y - variable to map to the y-axis\n✔\n\n\n- group - plot separate series without aesthetic differences\n✔\n\n\n- alpha - transparency\n✔\n\n\n- colour - colour of the points/lines\n✔\n\n\n- fill - inner colour of points/shapes\n✔\n\n\n- linetype - type of lines used to construct points/lines\n✔\n\n\n- shape - symbol shape for points\n✔\n\n\n- size - size of symbol\n✔\n\n\n\n\n\n\nadditional parameters\n\n\n\n- outline.type - determines the type of outline to draw around area\n‘both’\n\n\n\n\n\n\n\n\n\nFeature\n\n\ngeom\n\n\nstat\n\n\nposition\n\n\nAesthetic parameters / Notes\n\n\nExample plot\n\n\n\n\n\n\narea layer\n\n\n_area\n\n\n_identity\n\n\nidentity\n\n\nx,ygeom_area draws areas under a curve using coordinates in the order present in the data frame\n\n\n\n\n\n\n\n\n\n\n\n\nggplot(data=df, aes(y = y, x = x)) +\n    geom_area()\n\n\n\n\n\n\n\n\ngeom_ribbon draws ribbons (polygons) based on upper (max) and lower (min) levels of y associated with each level of x and are typically used to represent uncertainty in trends.\n\n\nShow attributes\n\n\n\n\n\n\n\n\n\nParameter\ngeom_ribbon\n\n\n\n\n- x - variable to map to the x-axis\n✔\n\n\n- y - variable to map to the y-axis\n✔\n\n\n- group - plot separate series without aesthetic differences\n✔\n\n\n- alpha - transparency\n✔\n\n\n- colour - colour of the points/lines\n✔\n\n\n- fill - inner colour of points/shapes\n✔\n\n\n- linetype - type of lines used to construct points/lines\n✔\n\n\n- shape - symbol shape for points\n✔\n\n\n- size - size of symbol\n✔\n\n\n\n\n\n\nadditional parameters\n\n\n\n- outline.type - determines the type of outline to draw around area\n‘both’\n\n\n\n\n\n\n\n\n\nFeature\n\n\ngeom\n\n\nstat\n\n\nposition\n\n\nAesthetic parameters / Notes\n\n\nExample plot\n\n\n\n\n\n\nribbon layer\n\n\n_ribbon\n\n\n_identity\n\n\nidentity\n\n\nx,ygeom_ribbon draws ribbons on a plot - useful for depicting uncertainty (confidence/credibility) intervals\n\n\n\n\n\n\n\n\n\n\n\n\nggplot(data=df, aes(ymin = y -1, ymax = y + 1, x = x)) +\n    geom_ribbon()\n\n\n\n\n\nribbon layer\n\n\n_ribbon\n\n\n_identity\n\n\nidentity\n\n\nx,ygeom_ribbon draws ribbons on a plot - useful for depicting uncertainty (confidence/credibility) intervals\n\n\n\n\n\n\n\n\n\n\n\n\nBOD.lm &lt;- lm(demand ~ Time, data = BOD)\nnewdata &lt;- with(BOD, data.frame(Time = seq(min(Time), max(Time),\n                                           length = 100)))\nnewdata &lt;- newdata %&gt;% cbind(predict(BOD.lm, newdata = newdata,\n                                     interval = 'confidence'))\nggplot(data=newdata) +\n    geom_ribbon(aes(x = Time, ymin = lwr, ymax = upr))\n\n\n\n\n\nribbon layer\n\n\n_ribbon\n\n\n_identity\n\n\nidentity\n\n\nx,ygeom_ribbon draws ribbons on a plot - useful for depicting uncertainty (confidence/credibility) intervals\n\n\n\n\n\n\n\n\n\n\n\n\nBOD.lm &lt;- lm(demand ~ Time, data = BOD)\nnewdata &lt;- with(BOD, data.frame(Time = seq(min(Time), max(Time),\n                                           length = 100)))\nnewdata &lt;- newdata %&gt;% cbind(predict(BOD.lm, newdata = newdata,\n                                     interval = 'confidence'))\nggplot(data=newdata, aes(x = Time)) +\n    geom_ribbon(aes(x = Time, ymin = lwr, ymax = upr),\n                fill='orange') +\n    geom_line(aes(y = fit)) +\n    geom_point(data = BOD, aes(y=demand))"
  },
  {
    "objectID": "05_grammar_of_graphics.html#visualising-distributions-1",
    "href": "05_grammar_of_graphics.html#visualising-distributions-1",
    "title": "The grammar of graphics (ggplot2)",
    "section": "2.2 Visualising distributions",
    "text": "2.2 Visualising distributions\n\nBoxplots Histograms Densityplots Violinplots QQplots Barplots Dotplots Scatterplotmatrix \n\n\ngeom_boxplot constructs boxplots. The values of the various elements of the boxplot (quantiles, whiskers etc) are calculated by its main pairing function (stat_boxplot). The following list describes the mapping aesthetic properties associated with geom_boxplot. The entries in bold are compulsory. Note that boxplots are usually specified via the geom_boxplot function which will engage the stat_boxplot to calculate the quantiles, whiskers and outliers. Therefore, confusingly, when calling geom_boxplot, the compulsory parameters are actually those required by stat_boxplot (unless you indicated to use stat_identity).\n\n\nShow attributes\n\n\n\n\n\n\n\n\n\n\nParameter\ngeom_boxplot\nstat_boxplot\n\n\n\n\naesthetics\n\n\n\n\nx - variable to map to the x-axis\n✔\n✔\n\n\ny - variable to map to the other axis\n✔\n✔\n\n\nlower - value of the lower box line (25th percentile)\n✔\n\n\n\nmiddle - value of the middle box line (50th percentile)\n✔\n\n\n\nupper - value of the upper box line (75th percentile)\n✔\n\n\n\nymin - value of lower whisker\n✔\n\n\n\nymax - value of upper whisker\n✔\n\n\n\ngroup - plot separate series without aesthetic differences\n✔\n✔\n\n\nalpha - transparency\n✔\n✔\n\n\ncolour - colour of the points/lines\n✔\n✔\n\n\nfill - inner colour of points/shapes\n✔\n✔\n\n\nlinetype - type of lines used to construct points/lines\n✔\n✔\n\n\nsize - thickness of the line\n✔\n✔\n\n\nweight - weightings of values\n✔\n✔\n\n\n\n\n\n\n\nadditional parameters\n\n\n\n\noutlier.colour - color of symbols for outliers\nNULL\nNULL\n\n\noutlier.fill - fill of symbols for outliers\nNULL\nNULL\n\n\noutlier.shape - shape of symbols for outliers\nNULL\nNULL\n\n\noutlier.size - size of symbols for outliers\nNULL\nNULL\n\n\noutlier.stroke - colour of lines in symbols for outliers\nNULL\nNULL\n\n\noutlier.alpha - transparency of symbols for outliers\nNULL\nNULL\n\n\nnotch - whether to notch the boxplots\nFALSE\nFALSE\n\n\nnotchwidth - width of notch\n0.5\n0.5\n\n\n\n\n\n\n\nComputed variables\n\n\n\n\nlower - value of the lower box line (25th percentile)\n✔\n\n\n\nmiddle - value of the middle box line (50th percentile)\n✔\n\n\n\nupper - value of the upper box line (75th percentile)\n✔\n\n\n\nymin - value of lower whisker\n✔\n\n\n\nymax - value of upper whisker\n✔\n\n\n\n\n\n\n\n\n\n\nFeature\n\n\ngeom\n\n\nstat\n\n\nposition\n\n\nAesthetic parameters / Notes\n\n\nExample plot\n\n\n\n\n\n\nboxplot\n\n\n_boxplot\n\n\n_boxplot\n\n\ndodge\n\n\nxplot of quantiles, whiskers and outliers.\n\n\n\n\n\n\n\n\n\n\n\n\nggplot(data=diamonds, aes(x = carat)) +\n    geom_boxplot()\n\n\n\n\n\nboxplot\n\n\n_boxplot\n\n\n_boxplot\n\n\ndodge\n\n\nyplot of quantiles, whiskers and outliers.\n\n\n\n\n\n\n\n\n\n\n\n\nggplot(data=diamonds, aes(y = carat)) +\n    geom_boxplot()\n\n\n\n\n\nconditional boxplot\n\n\n_boxplot\n\n\n_boxplot\n\n\ndodge\n\n\ny,xplot of quantiles, whiskers and outliers.\n\n\n\n\n\n\n\n\n\n\n\n\nggplot(data=diamonds, aes(y = carat, x = cut)) +\n    geom_boxplot()\n\n\n\n\n\n\n\n\ngeom_histogram draws histograms of continuous data after binning the data,\nThe following list describes the mapping aesthetic properties associated with geom_histogram. The entries in bold are compulsory.\n\n\nShow attributes\n\n\n\n\n\n\n\n\n\n\nParameter\ngeom_histogram\nstat_bin\n\n\n\n\naesthetics\n\n\n\n\nx - variable to map to the x-axis\n✔\n✔\n\n\ngroup - plot separate series without aesthetic differences\n✔\n✔\n\n\nalpha - transparency\n✔\n✔\n\n\ncolour - colour of the points/lines\n✔\n✔\n\n\nfill - inner colour of points/shapes\n✔\n✔\n\n\nlinetype - type of lines used to construct points/lines\n✔\n✔\n\n\nsize - thickness of the line\n✔\n✔\n\n\nweight - weightings of values\n✔\n✔\n\n\n\n\n\n\n\nadditional parameters\n\n\n\n\nbinwidth - width of the bins\nNULL\nNULL\n\n\nbins - number of bins\nNULL\nNULL\n\n\nbreaks - vector of bin boundaries\n\nNULL\n\n\ncenter - bin position specifier\n\nNULL\n\n\nboundary - bin position specifier\n\nNULL\n\n\nclosed - which bin edge is included\n\nc(‘right’,‘left’)\n\n\npad - whether to include empty bins at either end of x\n\nFALSE\n\n\norientation - which axis (x or y) to operate on\nNA\nNA\n\n\n\n\n\n\n\nComputed variables\n\n\n\n\ncount - number of points in bin\n✔\n\n\n\ndensity - density of points in bin\n✔\n\n\n\nncount - counts scaled to max of 1\n✔\n\n\n\nndensity - density scaled to max of 1\n✔\n\n\n\n\n\n\n\n\n\n\n\nFeature\n\n\ngeom\n\n\nstat\n\n\nposition\n\n\nAesthetic parameters / Notes\n\n\nExample plot\n\n\n\n\n\n\nhistogram layer\n\n\n_histogram\n\n\n_bin\n\n\nstack\n\n\nx or ygeom_histogram bins continuous data and uses the number of cases in each bin as the height of a set of rectangles.Computed variables:\n\n\n\n\n\n\n\n\n\n\n\n\nggplot(data = diamonds, aes(x = carat)) +\n    geom_histogram()\n\n\n\n\n\nhistogram layer\n\n\n_histogram\n\n\n_bin\n\n\nstack\n\n\nx or ythe granularity of the histogram can be altered by changing the binwidth.\n\n\n\n\n\n\n\n\n\n\n\n\nggplot(data = diamonds, aes(x = carat)) +\n    geom_histogram(binwidth = 0.05)\n\n\n\n\n\nhistogram layer\n\n\n_histogram\n\n\n_bin\n\n\nstack\n\n\nx or ythe granularity of the histogram can be altered by changing the number of bins.\n\n\n\n\n\n\n\n\n\n\n\n\nggplot(data = diamonds, aes(x = carat)) +\n    geom_histogram(bins = 10)\n\n\n\n\n\nhistogram layer\n\n\n_histogram\n\n\n_bin\n\n\nstack\n\n\nx or ygeom_histogram bins continuous data and uses the number of cases in each bin as the height of a set of rectangles.\n\n\n\n\n\n\n\n\n\n\n\n\nggplot(data = diamonds, aes(x = carat)) +\n    geom_histogram(aes(fill = cut))\n\n\n\n\n\nhistogram layer\n\n\n_histogram\n\n\n_bin\n\n\ndodge\n\n\nx or ygeom_histogram bins continuous data and uses the number of cases in each bin as the height of a set of rectangles.\n\n\n\n\n\n\n\n\n\n\n\n\nggplot(data = diamonds, aes(x = carat)) +\n    geom_histogram(aes(fill = cut), position = 'dodge')\n\n\n\n\n\n\n\n\ngeom_density constructs smooth density distributions from continuous vectors. The actual smoothed densities are calculated by its main pairing function (stat_density). The following list describes the mapping aesthetic properties associated with geom_density and stat_density. The entries in bold are compulsory. Note that density plots are usually specified via the geom_density function which will engage the stat_density. Therefore, confusingly, when calling geom_density, the compulsory paramaters are actually those required by stat_density (unless you indicated to use stat_identity).\n\n\nShow attributes\n\n\n\n\n\n\n\n\n\n\nParameter\ngeom_density\nstat_density\n\n\n\n\naesthetics\n\n\n\n\nx - variable to map to the x-axis\n✔\n✔\n\n\ngroup - plot separate series without aesthetic differences\n✔\n✔\n\n\nalpha - transparency\n✔\n✔\n\n\ncolour - colour of the points/lines\n✔\n✔\n\n\nfill - inner colour of points/shapes\n✔\n✔\n\n\nlinetype - type of lines used to construct points/lines\n✔\n✔\n\n\nsize - thickness of the line\n✔\n✔\n\n\nweight - weightings of values\n✔\n✔\n\n\n\n\n\n\n\nadditional parameters\n\n\n\n\nbw - bandwidth smoothing (either sd of kernel or name of function)\n“nrd0”\n“nrd0”\n\n\nadjust - multiplicate bandwidth adjustment\n1\n1\n\n\nkernel - density() kernel to use\n“gaussian”\n“gaussian”\n\n\nn - number of equ-spaced points to estimate density\n512\n512\n\n\ntrim - whether to trim the range of data\nFALSE\nFALSE\n\n\norientation - which axis (x or y) to operate on\nNA\nNA\n\n\n\n\n\n\n\nComputed variables\n\n\n\n\ndensity - density of points in bin\n✔\n\n\n\ncount - density * number of points\n✔\n\n\n\nscaled density - density scaled to max of 1\n✔\n\n\n\nndensity - density scaled to max of 1\n✔\n\n\n\n\n\n\n\n\n\n\nFeature\n\n\ngeom\n\n\nstat\n\n\nposition\n\n\nAesthetic parameters / Notes\n\n\nExample plot\n\n\n\n\n\n\ndensity layer\n\n\n_density\n\n\n_density\n\n\nidentity\n\n\nx or y\n\n\n\n\n\n\n\n\n\n\n\n\nggplot(data = diamonds, aes(x = carat)) +\n    geom_density()\n\n\n\n\n\ndensity layer\n\n\n_density\n\n\n_density\n\n\nidentity\n\n\nx or y\n\n\n\n\n\n\n\n\n\n\n\n\nggplot(data = diamonds, aes(x = carat)) +\n    geom_density(bw=0.1)\n\n\n\n\n\ndensity layer\n\n\n_density\n\n\n_density\n\n\nidentity\n\n\nx or y, fill or other groupingMultiple densities with overlapping ranges\n\n\n\n\n\n\n\n\n\n\n\n\nggplot(data = diamonds, aes(x = carat)) +\n    geom_density(aes(fill = cut), alpha=0.5)\n\n\n\n\n\ndensity layer\n\n\n_density\n\n\n_density\n\n\nstack\n\n\nx or y, fill or other groupingMultiple densities stacked on top of one another\n\n\n\n\n\n\n\n\n\n\n\n\nggplot(data = diamonds, aes(x = carat)) +\n    geom_density(aes(fill = cut), position = 'stack')\n\n\n\n\n\n\n\n\ngeom_violin constructs violin plots. Violin plots are a blend on boxplot and density plots in that they are a density plot mirrored across a central axis and displayed similarly to a boxplot. Since they are derived from density plots, geom_violin and its stat (stat_ydensity) have most of the same parameters as geom_density/stat_density. Violin plots are a useful way to present continuous distributions that have greater granularity than boxplots.\n\n\nShow attributes\n\n\n\n\n\n\n\n\n\n\nParameter\ngeom_violin\nstat_ydensity\n\n\n\n\naesthetics\n\n\n\n\nx - variable to map to the x-axis\n✔\n✔\n\n\ngroup - plot separate series without aesthetic differences\n✔\n✔\n\n\nalpha - transparency\n✔\n✔\n\n\ncolour - colour of the points/lines\n✔\n✔\n\n\nfill - inner colour of points/shapes\n✔\n✔\n\n\nlinetype - type of lines used to construct points/lines\n✔\n✔\n\n\nsize - thickness of the line\n✔\n✔\n\n\nweight - weightings of values\n✔\n✔\n\n\n\n\n\n\n\nadditional parameters\n\n\n\n\nbw - bandwidth smoothing (either sd of kernel or name of function)\n“nrd0”\n“nrd0”\n\n\nadjust - multiplicate bandwidth adjustment\n1\n1\n\n\nkernel - density() kernel to use\n“gaussian”\n“gaussian”\n\n\nn - number of equ-spaced points to estimate density\n512\n512\n\n\ntrim - whether to trim the range of data\nFALSE\nFALSE\n\n\norientation - which axis (x or y) to operate on\nNA\nNA\n\n\n\n\n\n\n\nComputed variables\n\n\n\n\ndensity - density of points in bin\n✔\n\n\n\ncount - density * number of points\n✔\n\n\n\nscaled density - density scaled to max of 1\n✔\n\n\n\nndensity - density scaled to max of 1\n✔\n\n\n\n\n\n\n\n\n\n\nFeature\n\n\ngeom\n\n\nstat\n\n\nposition\n\n\nAesthetic parameters / Notes\n\n\nExample plot\n\n\n\n\n\n\nviolin\n\n\n_violin\n\n\n_ydensity\n\n\ndodge\n\n\nxplot of quantiles, whiskers and outliers.\n\n\n\n\n\n\n\n\n\n\n\n\nggplot(diamonds) +\n    geom_violin(aes(y = carat, x = carat), orientation = 'x')\n\n\n\n\n\nviolin\n\n\n_violin\n\n\n_ydensity\n\n\ndodge\n\n\nyplot of quantiles, whiskers and outliers.\n\n\n\n\n\n\n\n\n\n\n\n\nggplot(diamonds) +\n    geom_violin(aes(y = carat, x = carat), orientation = 'y')\n\n\n\n\n\nconditional violin\n\n\n_violin\n\n\n_ydensity\n\n\ndodge\n\n\ny,xplot of quantiles, whiskers and outliers.\n\n\n\n\n\n\n\n\n\n\n\n\nggplot(diamonds) +\n    geom_violin(aes(y = carat, x = cut))\n\n\n\n\n\n\n\n\ngeom_qq constructs quantile-quantile (QQ) plots. QQ plots illustrate the quantiles of the sample distribution against the quantiles expected for the theoretical distribution. A straight line implies that the sample distribution matches the theoretical distribution well. Deviations (typically at the tails) imply a lack of match. To help assess deviations from linearity, the geom_qq_line/stat_qq_line function depicts the ideal match as a straight line for comparison.\n\n\n\n\nShow attributes\n\n\n\n\n\n\n\n\n\n\nParameter\ngeom_qq\nstat_qq\n\n\n\n\naesthetics\n\n\n\n\nsample - variable to map to the x-axis\n✔\n✔\n\n\ngroup - plot separate series without aesthetic differences\n✔\n✔\n\n\nalpha - transparency\n✔\n✔\n\n\ncolour - colour of the points/lines\n✔\n✔\n\n\nfill - inner colour of points/shapes\n✔\n✔\n\n\nlinetype - type of lines used to construct points/lines\n✔\n✔\n\n\nsize - thickness of the line\n✔\n✔\n\n\nweight - weightings of values\n✔\n✔\n\n\n\n\n\n\n\nadditional parameters\n\n\n\n\ndistribution - function that calculates quantiles for a distribution\nstats::qnorm\nstats::qnorm\n\n\ndparams - additional parameters for the distribution\nlist()\nlist()\n\n\norientation - which axis (x or y) to operate on\nNA\nNA\n\n\n\n\n\n\n\nComputed variables\n\n\n\n\nsample - sample quantiles\n✔\n\n\n\ntheoretical - theoretical quantiles\n✔\n\n\n\n\n\n\n\n\n\n\nFeature\n\n\ngeom\n\n\nstat\n\n\nposition\n\n\nAesthetic parameters / Notes\n\n\nExample plot\n\n\n\n\n\n\nQQ plot\n\n\n_qq\n\n\n_qq\n\n\nidentity\n\n\nsample\n\n\n\n\n\n\n\n\n\n\n\n\nggplot(diamonds, aes(sample = carat)) +\n    geom_qq() +\n    geom_qq_line()\n\n\n\n\n\nQQ plot\n\n\n_qq\n\n\n_qq\n\n\nidentity\n\n\nsamplethis example will explore a Gamma theoretical distribution (rather than the default Gaussian). When specifying an alternative distribution, it may be necessary to supply certain distribution parameters. In this case, the appropriate shape parameter for the Gamma distribution is required. This is first estimated via the fitdistr() function from the MASS _package`.\n\n\n\n\n\n\n\n\n\n\n\n\nshape &lt;- MASS::fitdistr(diamonds$carat,\n                        densfun = \"gamma\")$estimate[\"shape\"]\nggplot(diamonds, aes(sample = carat)) +\n    geom_qq(distribution = stats::qgamma,\n            dparams = list(shape = shape)) +\n    geom_qq_line(distribution = stats::qgamma,\n                 dparams = list(shape = shape))\n\n\n\n\n\nQQ plot\n\n\n_qq\n\n\n_qq\n\n\nidentity\n\n\nsample\n\n\n\n\n\n\n\n\n\n\n\n\nggplot(diamonds, aes(sample = carat, colour = cut)) +\n    geom_qq() +\n    geom_qq_line()\n\n\n\n\n\n\n\n\ngeom_bar constructs barcharts. By default, the bins of each bar along with the associated bar heights are calculated by the stats_count function. The following list describes the mapping aesthetic properties associated with geom_bar and stats_count. The entries in bold are compulsory.\n\n\n\n\nShow attributes\n\n\n\n\n\n\n\n\n\n\nParameter\ngeom_bar\nstat_count\n\n\n\n\naesthetics\n\n\n\n\nx or y - variable to map to the x/y-axis\n✔\n✔\n\n\ngroup - plot separate series without aesthetic differences\n✔\n✔\n\n\nalpha - transparency\n✔\n✔\n\n\ncolour - colour of the points/lines\n✔\n✔\n\n\nfill - inner colour of points/shapes\n✔\n✔\n\n\nlinetype - type of lines used to construct points/lines\n✔\n✔\n\n\nsize - thickness of the line\n✔\n✔\n\n\nweight - weightings of values\n✔\n✔\n\n\n\n\n\n\n\nadditional parameters\n\n\n\n\nwidth - width of the bars\nNULL\nNULL\n\n\norientation - which axis (x or y) to operate on\nNA\nNA\n\n\n\n\n\n\n\nComputed variables\n\n\n\n\ncount - number of points to bin\n✔\n\n\n\nprop - groupwise proportion\n✔\n\n\n\n\n\n\n\n\n\n\nFeature\n\n\ngeom\n\n\nstat\n\n\nposition\n\n\nAesthetic parameters / Notes\n\n\nExample plot\n\n\n\n\n\n\nBar plot\n\n\n_bar\n\n\n_count\n\n\nstack\n\n\nsample\n\n\n\n\n\n\n\n\n\n\n\n\nggplot(diamonds, aes(x = cut)) +\n    geom_bar()\n\n\n\n\n\nStacked bar plot\n\n\n_bar\n\n\n_count\n\n\nstack\n\n\nsampleby default a viridis colour blind safe palette is applied.\n\n\n\n\n\n\n\n\n\n\n\n\nggplot(diamonds, aes(x = cut, fill = clarity)) +\n    geom_bar()\n\n\n\n\n\nConditional bar plot\n\n\n_bar\n\n\n_count\n\n\ndodge2\n\n\nsampleby default a viridis colour blind safe palette is applied.\n\n\n\n\n\n\n\n\n\n\n\n\nggplot(diamonds, aes(x = cut, fill = clarity)) +\n    geom_bar(position = \"dodge2\")\n\n\n\n\n\n\n\n\n\n\ngeom_dotplot draws dotplots of continuous data after binning the data. This geom is unusual in that it does not have an associated stat. Instead, it calls its own density function. Dotplots are really only useful for small datasets. The reason for this is that the counts in each bin are represented by circles (the size of which is determined by the bin width) and thus if the counts are high, the stack of circles will extend beyond the y-axis (unless the stack ratio is altered). Moreover, the y-axis scale is meaningless.\nThe following list describes the mapping aesthetic properties associated with geom_dotplot. The entries in bold are compulsory.\n\n\nShow attributes\n\n\n\n\n\n\n\n\n\nParameter\ngeom_histogram\n\n\n\n\naesthetics\n\n\n\nx - variable to map to the x-axis\n✔\n\n\ngroup - plot separate series without aesthetic differences\n✔\n\n\nalpha - transparency\n✔\n\n\ncolour - colour of the points/lines\n✔\n\n\nfill - inner colour of points/shapes\n✔\n\n\nlinetype - type of lines used to construct points/lines\n✔\n\n\nsize - thickness of the line\n✔\n\n\nweight - weightings of values\n✔\n\n\n\n\n\n\nadditional parameters\n\n\n\nbinwidth - (maximum) bin width\nNULL\n\n\nbinaxis - the axis to bin along\n“x”\n\n\nmethod - method for binning\n“dotdensity”\n\n\nbinpositions - method for determining the position of dots\n“bygroup”\n\n\nstackdir - which direction to stack dots\n“up”\n\n\nstackratio - how close to stack dots\n1\n\n\ndotsize - diameter of dot relative to binwidth\n1\n\n\nstackgroups - whether to stack dots across groups\nFALSE\n\n\norigin - origin of first bin\nNULL\n\n\nright - should bin intervals be closed on the right (a, b] or not [a, b)\nTRUE\n\n\nwidth - when binaxis is “y”, the spacing of dot stacks for dodging\n0.9\n\n\ndrop - whether to remove bins with zero counts\nFALSE\n\n\n\n\n\n\nComputed variables\n\n\n\ncount - number of points in bin\n✔\n\n\ndensity - density of points in bin\n✔\n\n\nncount - counts scaled to max of 1\n✔\n\n\nndensity - density scaled to max of 1\n✔\n\n\n\n\n\n\n\n\n\nFeature\n\n\ngeom\n\n\nstat\n\n\nposition\n\n\nAesthetic parameters / Notes\n\n\nExample plot\n\n\n\n\n\n\ndotplot layer\n\n\n_dotplot\n\n\n\n\nidentity\n\n\nx or y\n\n\n\n\n\n\n\n\n\n\n\n\nggplot(data = CO2, aes(x = uptake)) +\n    geom_dotplot()\n\n\n\n\n\ndotplot layer\n\n\n_dotplot\n\n\n\n\nidentity\n\n\nx or y\n\n\n\n\n\n\n\n\n\n\n\n\nggplot(data = CO2, aes(x = uptake)) +\n    geom_dotplot(binwidth = 3)\n\n\n\n\n\ndotplot layer\n\n\n_dotplot\n\n\n\n\nidentity\n\n\nx or y\n\n\n\n\n\n\n\n\n\n\n\n\nggplot(data = CO2, aes(x = uptake, fill = Type)) +\n    geom_dotplot(stackgroups = TRUE,\n                 binpositions = 'all',\n                 binwidth=3, dotsize=1) \n\n\n\n\n\n\n\n\nThe ggpairs() function is not actually part of the ggplot2 package. Rather it is part of its own package (GGally). Nevertheless, this graphic, in which all pairs of variables are plotted in a matrix of panels can be a very useful way to explore the individual and relational characteristics of multiple variables simultaneously.\n\n\n\n\nShow attributes\n\n\n\n\n\n\n\n\n\nParameter\ngeom_histogram\n\n\n\n\naesthetics\n\n\n\ngroup - plot separate series without aesthetic differences\n✔\n\n\nalpha - transparency\n✔\n\n\ncolour - colour of the points/lines\n✔\n\n\nfill - inner colour of points/shapes\n✔\n\n\nlinetype - type of lines used to construct points/lines\n✔\n\n\nsize - thickness of the line\n✔\n\n\nweight - weightings of values\n✔\n\n\n\n\n\n\nadditional parameters\n\n\n\ncolumns - which columns to include\n1:ncol(data)\n\n\ntitle,xlab,ylab - titles\nNULL\n\n\nupper,lower - functions for plots to appear in off diagonal panels\n…\n\n\ndiag - function for plots to appear in diagonal panels\n…\n\n\naxisLabels - whether and how to display axis labels\nc(“show”, “internal”, “none”)\n\n\ncolumnLabels - label names to display\ncolnames(data[columns])\n\n\nlabeller - facet labeller function\n“label_value”\n\n\nswitch - which (if any) facet labels to switch position\nNULL\n\n\nshowStrips - whether to display all strips (panel banners)\nNULL\n\n\nlegend - whether or position of legend\nNULL\n\n\ncardinality_threshold - max number of factor levels permitted\n15\n\n\nprogress - whether to show a progress bar while computing (if &gt;15 panels)\nNULL\n\n\nproportions - amount of area given to each plot\nNULL\n\n\n\n\n\n\n\n\n\nFeature\n\n\ngeom\n\n\nstat\n\n\nposition\n\n\nAesthetic parameters / Notes\n\n\nExample plot\n\n\n\n\n\n\ndotplot layer\n\n\n_dotplot\n\n\n\n\nidentity\n\n\nx or y\n\n\n\n\n\n\n\n\n\n\n\n\nggpairs(iris, colour = \"Species\", upper = list(continuous = \"density\",\n    combo = \"box\"), diag = list(continuous = \"density\"),\n    lower = list(continuous = \"smooth\"), axisLabels = \"show\")"
  },
  {
    "objectID": "05_grammar_of_graphics.html#visualising-trends-1",
    "href": "05_grammar_of_graphics.html#visualising-trends-1",
    "title": "The grammar of graphics (ggplot2)",
    "section": "2.3 Visualising trends",
    "text": "2.3 Visualising trends\n\nScatterplots Lineplots Smootherplots Tiles Raster Contours Filledcontour \n\n\nsee points\n\n\ngeom_line draws lines joining coordinates. Typically the stat used is stat_identity as we wish to use the values in two continuous vectors as the coordinates of each line segment. geom_line differs from geom_path in that the former first orders the data according to the x-axis.\n\n\nShow attributes\n\n\n\n\n\n\n\n\n\nParameter\ngeom_line\n\n\n\n\naesthetics\n\n\n\nx - variable to map to the x-axis\n✔\n\n\ny - variable to map to the other axis\n✔\n\n\ngroup - plot separate series without aesthetic differences\n✔\n\n\nalpha - transparency\n✔\n\n\ncolour - colour of the points/lines\n✔\n\n\nfill - inner colour of points/shapes\n✔\n\n\nlinetype - type of lines used to construct points/lines\n✔\n\n\nsize - thickness of the line\n✔\n\n\nweight - weightings of values\n✔\n\n\n\n\n\n\nadditional parameters\n\n\n\n\n\n\n\nComputed variables\n\n\n\n\n\n\n\n\n\n\nFeature\n\n\ngeom\n\n\nstat\n\n\nposition\n\n\nAesthetic parameters / Notes\n\n\nExample plot\n\n\n\n\n\n\nline plot\n\n\n_line\n\n\n_identity\n\n\nidentity\n\n\nx,yscatterplot on only the first level of Plant.\n\n\n\n\n\n\n\n\n\n\n\n\nggplot(filter(CO2, Plant == first(Plant))) +\n    geom_line(aes(x = conc, y = uptake)) \n\n\n\n\n\nline plot\n\n\n_line\n\n\n_identity\n\n\nidentity\n\n\nx,yscatterplot of each Plant level.\n\n\n\n\n\n\n\n\n\n\n\n\nggplot(data = CO2, aes(x = conc, y = uptake)) +\n    geom_line(aes(group = Plant))\n\n\n\n\n\nline plot\n\n\n_line\n\n\n_identity\n\n\nidentity\n\n\nx,yscatterplot of each Plant level coloured separately.\n\n\n\n\n\n\n\n\n\n\n\n\nggplot(data = CO2, aes(x = conc, y = uptake)) +\n    geom_line(aes(colour = Plant))\n\n\n\n\n\nline plot\n\n\n_line\n\n\n_identity\n\n\nidentity\n\n\nx,yscatterplot of mean across all Plants.\n\n\n\n\n\n\n\n\n\n\n\n\nggplot(data = CO2, aes(x = conc, y = uptake)) +\n    geom_line(stat = \"summary\", fun = mean)\n\n\n\n\n\nline plot\n\n\n_line\n\n\n_identity\n\n\nidentity\n\n\nx,yscatterplot of mean across all Plants.\n\n\n\n\n\n\n\n\n\n\n\n\nggplot(data = CO2, aes(x = conc, y = uptake)) +\n    geom_line(stat = \"summary\", fun = mean, aes(color = Type))\n\n\n\n\n\n\n\n\ngeom_smooth draws smooths lines (and 95% confidence intervals) through data clouds. Typically the stat used is stat_smooth which in turn engages one of the available smoothing methods (e.g. lm, glm, gam, loess or rlm).\n\n\nShow attributes\n\n\n\n\n\n\n\n\n\n\nParameter\ngeom_smooth\ngeom_smooth\n\n\n\n\naesthetics\n\n\n\n\nx - variable to map to the x-axis\n✔\n✔\n\n\ny - variable to map to the other axis\n✔\n✔\n\n\ngroup - plot separate series without aesthetic differences\n✔\n✔\n\n\nalpha - transparency\n✔\n✔\n\n\ncolour - colour of the points/lines\n✔\n✔\n\n\nfill - inner colour of points/shapes\n✔\n✔\n\n\nlinetype - type of lines used to construct points/lines\n✔\n✔\n\n\nsize - thickness of the line\n✔\n✔\n\n\nweight - weightings of values\n✔\n✔\n\n\n\n\n\n\n\nadditional parameters\n\n\n\n\nmethod - smoothing method (modelling function)\nNULL\nNULL\n\n\nformula - formula to use in smoothing function\nNULL\nNULL\n\n\nse - whether to display confidence intervals\nTRUE\nTRUE\n\n\nn - number of points at which to evaluate the smoother\n\n80\n\n\nspan - degree of smoothing for loess smoother\n\n0.75\n\n\nfullrange - whether the fit should span full range (or just data)\n\nFALSE\n\n\nmethod.args - additional arguments passed on to modelling function\n\nlist()\n\n\n\n\n\n\n\nComputed variables\n\n\n\n\ny or x - the predicted value\n✔\n\n\n\nymin or xmin - lower confidence interval\n✔\n\n\n\nymax or xmax - upper confidence interval\n✔\n\n\n\nse - standard error\n✔\n\n\n\n\n\n\n\n\n\n\nFeature\n\n\ngeom\n\n\nstat\n\n\nposition\n\n\nAesthetic parameters / Notes\n\n\nExample plot\n\n\n\n\n\n\nline plot\n\n\n_line\n\n\n_identity\n\n\nidentity\n\n\nx,yscatterplot on only the first level of Plant.\n\n\n\n\n\n\n\n\n\n\n\n\nggplot(filter(CO2, Plant == first(Plant))) +\n    geom_smooth(aes(x = conc, y = uptake)) \n\n\n\n\n\nline plot\n\n\n_line\n\n\n_identity\n\n\nidentity\n\n\nx,yscatterplot of each Plant level.\n\n\n\n\n\n\n\n\n\n\n\n\nggplot(data = CO2, aes(x = conc, y = uptake)) +\n    geom_smooth(aes(colour = Type))\n\n\n\n\n\nline plot\n\n\n_line\n\n\n_identity\n\n\nidentity\n\n\nx,yscatterplot of each Plant level coloured separately.\n\n\n\n\n\n\n\n\n\n\n\n\nggplot(data = BOD, aes(x = Time, y = demand)) +\n    geom_smooth(method = \"lm\", formula = \"y ~ x\")\n\n\n\n\n\nline plot\n\n\n_line\n\n\n_identity\n\n\nidentity\n\n\nx,yscatterplot of each Plant level coloured separately.\n\n\n\n\n\n\n\n\n\n\n\n\nggplot(data = BOD, aes(x = Time, y = demand)) +\n    geom_smooth(method = \"lm\", formula = \"y ~ x\")\n\n\n\n\n\n\n\n\ngeom_tile constructs heat maps given x,y coordinates and a z value to associate with the fill of each tile. Note, the data must be a complete grid.\n\n\nShow attributes\n\n\n\n\n\n\n\n\n\nParameter\ngeom_tile\n\n\n\n\naesthetics\n\n\n\nx - variable to map to the x-axis\n✔\n\n\ny - variable to map to the other axis\n✔\n\n\ngroup - plot separate series without aesthetic differences\n✔\n\n\nalpha - transparency\n✔\n\n\ncolour - colour of the points/lines\n✔\n\n\nfill - inner colour of points/shapes\n✔\n\n\nlinetype - type of lines used to construct points/lines\n✔\n\n\nsize - thickness of the line\n✔\n\n\nweight - weightings of values\n✔\n\n\n\n\n\n\nadditional parameters\n\n\n\nlinejoin - line join style\n“mitre”\n\n\n\n\n\n\nComputed variables\n\n\n\n\n\n\n\n\n\n\nFeature\n\n\ngeom\n\n\nstat\n\n\nposition\n\n\nAesthetic parameters / Notes\n\n\nExample plot\n\n\n\n\n\n\ntile plot\n\n\n_tile\n\n\n_identity\n\n\nidentity\n\n\nx,yheatmap of 2d density.\n\n\n\n\n\n\n\n\n\n\n\n\nggplot(faithfuld, aes(y = eruptions, x = waiting)) +\n    geom_tile(aes(fill = density)) \n\n\n\n\n\n\n\n\ngeom_raster is similar to geom_tile in that it constructs heat maps given x,y coordinates and a z value to associate with the fill of each tile. However, unlike geom_tile, a full grid is not required as geom_raster is able to interpolate over the grid. The interpolation can also smooth out the grid surface. This interpolation does make geom_raster slower than geom_tile.\n\n\nShow attributes\n\n\n\n\n\n\n\n\n\nParameter\ngeom_raster\n\n\n\n\naesthetics\n\n\n\nx - variable to map to the x-axis\n✔\n\n\ny - variable to map to the other axis\n✔\n\n\ngroup - plot separate series without aesthetic differences\n✔\n\n\nalpha - transparency\n✔\n\n\ncolour - colour of the points/lines\n✔\n\n\nfill - inner colour of points/shapes\n✔\n\n\nlinetype - type of lines used to construct points/lines\n✔\n\n\nsize - thickness of the line\n✔\n\n\nweight - weightings of values\n✔\n\n\n\n\n\n\nadditional parameters\n\n\n\nhjust - line join style\n0.5\n\n\nvjust - line join style\n0.5\n\n\ninterpolate - line join style\nFALSE\n\n\n\n\n\n\nComputed variables\n\n\n\n\n\n\n\n\n\n\nFeature\n\n\ngeom\n\n\nstat\n\n\nposition\n\n\nAesthetic parameters / Notes\n\n\nExample plot\n\n\n\n\n\n\nraster plot\n\n\n_raster\n\n\n_identity\n\n\nidentity\n\n\nx,yheatmap of 2d density.\n\n\n\n\n\n\n\n\n\n\n\n\nggplot(faithfuld, aes(y = eruptions, x = waiting)) +\n    geom_raster(aes(fill = density)) \n\n\n\n\n\n\n\n\ngeom_contour constructs contour maps given x,y coordinates and a z value from which to calculate each contour.\n\n\nShow attributes\n\n\n\n\n\n\n\n\n\n\nParameter\ngeom_contour\nstat_contour\n\n\n\n\naesthetics\n\n\n\n\nx - variable to map to the x-axis\n✔\n✔\n\n\ny - variable to map to the y axis\n✔\n✔\n\n\nz - variable to map to the z axis\n✔\n✔\n\n\ngroup - plot separate series without aesthetic differences\n✔\n✔\n\n\nalpha - transparency\n✔\n✔\n\n\ncolour - colour of the points/lines\n✔\n✔\n\n\nfill - inner colour of points/shapes\n✔\n✔\n\n\nlinetype - type of lines used to construct points/lines\n✔\n✔\n\n\nsize - thickness of the line\n✔\n✔\n\n\nweight - weightings of values\n✔\n✔\n\n\n\n\n\n\n\nadditional parameters\n\n\n\n\nbins - number of contour bins\nNULL\nNULL\n\n\nbinwidth - width of contour bins\nNULL\nNULL\n\n\nbreaks - numer of contour bins (alternative to bins)\nNULL\nNULL\n\n\nlineend - line end style\n“butt”\n“butt”\n\n\nlinejoin - line join style\n“round”\n“round”\n\n\nlinemitre - line mitre style\n10\n10\n\n\n\n\n\n\n\nComputed variables\n\n\n\n\nlevel - bin boundaries\n✔\n\n\n\nlevel_low, level_high, level_mid - bin boundaries per band\n✔\n\n\n\nnlevel - height of contour, scaled to max of 1\n✔\n\n\n\npiece - contour piece\n✔\n\n\n\n\n\n\n\n\n\n\nFeature\n\n\ngeom\n\n\nstat\n\n\nposition\n\n\nAesthetic parameters / Notes\n\n\nExample plot\n\n\n\n\n\n\ncontour plot\n\n\n_contour\n\n\n_identity\n\n\nidentity\n\n\nx,ycontour plot of 2d density in relation to eruption and waiting times.\n\n\n\n\n\n\n\n\n\n\n\n\nggplot(faithfuld, aes(y = eruptions, x = waiting)) +\n    geom_contour(aes(z = density)) \n\n\n\n\n\n\n\n\ngeom_contour constructs contour maps given x,y coordinates and a z value from which to calculate each contour.\n\n\nShow attributes\n\n\n\n\n\n\n\n\n\n\nParameter\ngeom_contour_filled\nstat_contour_filled\n\n\n\n\naesthetics\n\n\n\n\nx - variable to map to the x-axis\n✔\n✔\n\n\ny - variable to map to the y axis\n✔\n✔\n\n\nz - variable to map to the z axis\n✔\n✔\n\n\ngroup - plot separate series without aesthetic differences\n✔\n✔\n\n\nalpha - transparency\n✔\n✔\n\n\ncolour - colour of the points/lines\n✔\n✔\n\n\nfill - inner colour of points/shapes\n✔\n✔\n\n\nlinetype - type of lines used to construct points/lines\n✔\n✔\n\n\nsize - thickness of the line\n✔\n✔\n\n\nweight - weightings of values\n✔\n✔\n\n\n\n\n\n\n\nadditional parameters\n\n\n\n\nbins - number of contour bins\nNULL\nNULL\n\n\nbinwidth - width of contours\nNULL\nNULL\n\n\nbreaks - sets contour breaks (alternative to bins)\nNULL\nNULL\n\n\nlineend - line end style\n“butt”\n“butt”\n\n\nlinejoin - line join style\n“round”\n“round”\n\n\nlinemitre - line mitre style\n10\n10\n\n\n\n\n\n\n\nComputed variables\n\n\n\n\nlevel - bin boundaries\n✔\n\n\n\nnlevel - height of filled_contour, scaled to max of 1\n✔\n\n\n\npiece - filled_contour piece\n✔\n\n\n\n\n\n\n\n\n\n\nFeature\n\n\ngeom\n\n\nstat\n\n\nposition\n\n\nAesthetic parameters / Notes\n\n\nExample plot\n\n\n\n\n\n\nfilled_contour plot\n\n\n_filled_contour\n\n\n_identity\n\n\nidentity\n\n\nx,yfilled contour plot of 2d density in relation to eruption and waiting times.\n\n\n\n\n\n\n\n\n\n\n\n\nggplot(faithfuld, aes(y = eruptions, x = waiting)) +\n    geom_contour_filled(aes(z = density))"
  },
  {
    "objectID": "05_grammar_of_graphics.html#visualising-uncertainty",
    "href": "05_grammar_of_graphics.html#visualising-uncertainty",
    "title": "The grammar of graphics (ggplot2)",
    "section": "2.4 Visualising uncertainty",
    "text": "2.4 Visualising uncertainty\n\nErrorbars Lineranges Pointranges Ribbons \n\n\ngeom_errorbar draws error bars based on upper and lower levels of y associated with each level of x.\n\n\nShow attributes\n\n\n\n\n\n\n\n\n\nParameter\ngeom_errorbar\n\n\n\n\naesthetics\n\n\n\nx - variable to map to the x-axis\n✔\n\n\ny - variable to map to the y axis\n✔\n\n\ngroup - plot separate series without aesthetic differences\n✔\n\n\nalpha - transparency\n✔\n\n\ncolour - colour of the points/lines\n✔\n\n\nfill - inner colour of points/shapes\n✔\n\n\nlinetype - type of lines used to construct points/lines\n✔\n\n\nsize - thickness of the line\n✔\n\n\nweight - weightings of values\n✔\n\n\n\n\n\n\nadditional parameters\n\n\n\nwidth - width of the caps on the bars\n1\n\n\n\n\n\n\nComputed variables\n\n\n\n\n\n\n\n\n\n\nFeature\n\n\ngeom\n\n\nstat\n\n\nposition\n\n\nAesthetic parameters / Notes\n\n\nExample plot\n\n\n\n\n\n\nerror bars\n\n\n_errorbar\n\n\n_identity\n\n\nidentity\n\n\nx,y\n\n\n\n\n\n\n\n\n\n\n\n\nwarpbreaks.sum &lt;- warpbreaks %&gt;%\n    group_by(wool) %&gt;%\n    summarise(mean_se(breaks))\nggplot(warpbreaks.sum, aes(y = y, x = wool, ymin = ymin, ymax = ymax)) +\n    geom_errorbar() \n\n\n\n\n\nerror bars\n\n\n_errorbar\n\n\n_identity\n\n\nidentity\n\n\nx,y\n\n\n\n\n\n\n\n\n\n\n\n\nwarpbreaks.sum &lt;- warpbreaks %&gt;%\n    group_by(wool) %&gt;%\n    summarise(mean_se(breaks))\nggplot(warpbreaks.sum, aes(y = y, x = wool, ymin = ymin, ymax = ymax)) +\n    geom_errorbar(width = 0.25) \n\n\n\n\n\nerror bars\n\n\n_errorbar\n\n\n_identity\n\n\nidentity\n\n\nx,y\n\n\n\n\n\n\n\n\n\n\n\n\nwarpbreaks.sum &lt;- warpbreaks %&gt;%\n    group_by(wool) %&gt;%\n    summarise(mean_se(breaks))\nggplot(warpbreaks.sum, aes(y = y, x = wool, ymin = ymin, ymax = ymax)) +\n    geom_crossbar(width = 0.25) \n\n\n\n\n\nerror bars\n\n\n_errorbar\n\n\n_identity\n\n\nidentity\n\n\nx,y\n\n\n\n\n\n\n\n\n\n\n\n\nwarpbreaks.sum &lt;- warpbreaks %&gt;%\n    group_by(wool, tension) %&gt;%\n    summarise(mean_se(breaks))\nggplot(warpbreaks.sum, aes(y = y, x = tension, ymin = ymin, ymax = ymax)) +\n    geom_errorbar(aes(colour = wool),\n                  position = position_dodge(width = 0.5),\n                  width = 0.25) \n\n\n\n\n\n\n\n\ngeom_lineranges draws uncertainty bars based on upper and lower levels of y associated with each level of x.\n\n\nShow attributes\n\n\n\n\n\n\n\n\n\nParameter\ngeom_linerange\n\n\n\n\naesthetics\n\n\n\nx - variable to map to the x-axis\n✔\n\n\ny - variable to map to the y axis\n✔\n\n\ngroup - plot separate series without aesthetic differences\n✔\n\n\nalpha - transparency\n✔\n\n\ncolour - colour of the points/lines\n✔\n\n\nfill - inner colour of points/shapes\n✔\n\n\nlinetype - type of lines used to construct points/lines\n✔\n\n\nsize - thickness of the line\n✔\n\n\nweight - weightings of values\n✔\n\n\n\n\n\n\nadditional parameters\n\n\n\n\n\n\n\nComputed variables\n\n\n\n\n\n\n\n\n\n\nFeature\n\n\ngeom\n\n\nstat\n\n\nposition\n\n\nAesthetic parameters / Notes\n\n\nExample plot\n\n\n\n\n\n\nline range\n\n\n_linerange\n\n\n_identity\n\n\nidentity\n\n\nx,y\n\n\n\n\n\n\n\n\n\n\n\n\nwarpbreaks.sum &lt;- warpbreaks %&gt;%\n    group_by(wool) %&gt;%\n    summarise(mean_se(breaks))\nggplot(warpbreaks.sum, aes(y = y, x = wool, ymin = ymin, ymax = ymax)) +\n    geom_linerange() \n\n\n\n\n\nline ranges\n\n\n_lineranges\n\n\n_identity\n\n\nidentity\n\n\nx,y\n\n\n\n\n\n\n\n\n\n\n\n\nwarpbreaks.sum &lt;- warpbreaks %&gt;%\n    group_by(wool, tension) %&gt;%\n    summarise(mean_se(breaks))\nggplot(warpbreaks.sum, aes(y = y, x = tension, ymin = ymin, ymax = ymax)) +\n    geom_linerange(aes(colour = wool),\n                  position = position_dodge(width = 0.5)) \n\n\n\n\n\n\n\n\ngeom_lineranges draws uncertainty bars based on upper and lower levels of y associated with each level of x.\n\n\nShow attributes\n\n\n\n\n\n\n\n\n\nParameter\ngeom_pointrange\n\n\n\n\naesthetics\n\n\n\nx - variable to map to the x-axis\n✔\n\n\ny - variable to map to the y axis\n✔\n\n\ngroup - plot separate series without aesthetic differences\n✔\n\n\nalpha - transparency\n✔\n\n\ncolour - colour of the points/lines\n✔\n\n\nfill - inner colour of points/shapes\n✔\n\n\nlinetype - type of lines used to construct points/lines\n✔\n\n\nsize - thickness of the line\n✔\n\n\nweight - weightings of values\n✔\n\n\n\n\n\n\nadditional parameters\n\n\n\nflatten - a multiplicative factor to increase the point size\n1\n\n\n\n\n\n\nComputed variables\n\n\n\n\n\n\n\n\n\n\nFeature\n\n\ngeom\n\n\nstat\n\n\nposition\n\n\nAesthetic parameters / Notes\n\n\nExample plot\n\n\n\n\n\n\npoint range\n\n\n_pointrange\n\n\n_identity\n\n\nidentity\n\n\nx,y\n\n\n\n\n\n\n\n\n\n\n\n\nwarpbreaks.sum &lt;- warpbreaks %&gt;%\n    group_by(wool) %&gt;%\n    summarise(mean_se(breaks))\nggplot(warpbreaks.sum, aes(y = y, x = wool, ymin = ymin, ymax = ymax)) +\n    geom_pointrange() \n\n\n\n\n\npoint ranges\n\n\n_pointranges\n\n\n_identity\n\n\nidentity\n\n\nx,y\n\n\n\n\n\n\n\n\n\n\n\n\nwarpbreaks.sum &lt;- warpbreaks %&gt;%\n    group_by(wool) %&gt;%\n    summarise(mean_se(breaks))\nggplot(warpbreaks.sum, aes(y = y, x = wool, ymin = ymin, ymax = ymax)) +\n    geom_pointrange(fatten = 5) \n\n\n\n\n\npoint ranges\n\n\n_pointranges\n\n\n_identity\n\n\nidentity\n\n\nx,y\n\n\n\n\n\n\n\n\n\n\n\n\nwarpbreaks.sum &lt;- warpbreaks %&gt;%\n    group_by(wool, tension) %&gt;%\n    summarise(mean_se(breaks))\nggplot(warpbreaks.sum, aes(y = y, x = tension, ymin = ymin, ymax = ymax)) +\n    geom_pointrange(aes(colour = wool),\n                  position = position_dodge(width = 0.5)) \n\n\n\n\n\n\n\n\ngeom_ribbon draws uncertainty envelopes based on upper and lower levels of y associated with each level of x.\nsee ribbons"
  },
  {
    "objectID": "05_grammar_of_graphics.html#other-features-1",
    "href": "05_grammar_of_graphics.html#other-features-1",
    "title": "The grammar of graphics (ggplot2)",
    "section": "2.5 Other features",
    "text": "2.5 Other features\n\nStraightlines Segments Text \n\n\ngeom_vline and geom_hline draw vertical and horizontal lines respectively. These are particularly useful for:\n\nmarking cross-hairs in ordination plots\nproviding extended guides along either axes.\n\ngeom_abline is used for adding linear regression lines in the form of y = bx + a where b is the slope and a is the intercept (this is where the ab in abline comes from).\n\n\nShow attributes\n\n\n\n\n\n\n\n\n\n\n\nParameter\ngeom_vline\ngeom_hline\ngeom_abline\n\n\n\n\naesthetics\n\n\n\n\n\nxintercept - x-axis coordinate crossed by vline\n✔\n\n\n\n\nyintercept - y-axis coordinate crossed by hline\n\n✔\n\n\n\nintercept - y-axis coordinate crossed by abline\n\n\n✔\n\n\nslope - slope (gradient) of abline\n\n\n✔\n\n\ngroup - plot separate series without aesthetic differences\n✔\n\n\n\n\nalpha - transparency\n✔\n\n\n\n\ncolour - colour of the points/lines\n✔\n\n\n\n\nfill - inner colour of points/shapes\n✔\n\n\n\n\nlinetype - type of lines used to construct points/lines\n✔\n\n\n\n\nsize - thickness of the line\n✔\n\n\n\n\nweight - weightings of values\n✔\n\n\n\n\n\n\n\n\n\n\nadditional parameters\n\n\n\n\n\n\n\n\n\n\n\nComputed variables\n\n\n\n\n\n\n\n\n\n\n\n\nFeature\n\n\ngeom\n\n\nstat\n\n\nposition\n\n\nAesthetic parameters / Notes\n\n\nExample plot\n\n\n\n\n\n\nstraight lines\n\n\n_vline\n\n\n_identity\n\n\nidentity\n\n\nx,y\n\n\n\n\n\n\n\n\n\n\n\n\nggplot(filter(CO2, Plant == first(Plant))) +\n    geom_vline(xintercept = 500, linetype = 'dashed') +\n    geom_point(aes(x = conc, y = uptake)) \n\n\n\n\n\nstraight lines\n\n\n_hline\n\n\n_identity\n\n\nidentity\n\n\nx,y\n\n\n\n\n\n\n\n\n\n\n\n\nggplot(filter(CO2, Plant == first(Plant))) +\n    geom_hline(yintercept = 25, linetype = 'dashed') +\n    geom_point(aes(x = conc, y = uptake)) \n\n\n\n\n\nstraight lines\n\n\n_abline\n\n\n_identity\n\n\nidentity\n\n\nx,y\n\n\n\n\n\n\n\n\n\n\n\n\nggplot(filter(CO2, Plant == first(Plant))) +\n    geom_abline(slope = 0.01, intercept = 30, linetype = 'dashed') +\n    geom_point(aes(x = conc, y = uptake)) \n\n\n\n\n\n\n\n\ngeom_segment draws segments (separate lines) joining pairs of coordinates. These can be useful to represent vectors (e.g. wind speed and direction on a map) or movement, differences etc (particularly if given an arrow head).\n\n\nShow attributes\n\n\n\n\n\n\n\n\n\nParameter\ngeom_segment\n\n\n\n\naesthetics\n\n\n\nx - x-axis coordinates for the start of lines\n✔\n\n\ny - y-axis coordinates for the start of lines\n✔\n\n\nxend - x-axis coordinates for the end of lines\n✔\n\n\nyend - y-axis coordinates for the end of lines\n✔\n\n\ngroup - plot separate series without aesthetic differences\n✔\n\n\nalpha - transparency\n✔\n\n\ncolour - colour of the points/lines\n✔\n\n\nfill - inner colour of points/shapes\n✔\n\n\nlinetype - type of lines used to construct points/lines\n✔\n\n\nsize - thickness of the line\n✔\n\n\nweight - weightings of values\n✔\n\n\n\n\n\n\nadditional parameters\n\n\n\narrow - specification of arrow heads\nNULL\n\n\narrow.fill - fill colour of arrow head\nNULL\n\n\nlineend - style of line end\n“butt”\n\n\nlinejoin - style of line join\n“round”\n\n\n\n\n\n\nComputed variables\n\n\n\n\n\n\n\n\n\n\nFeature\n\n\ngeom\n\n\nstat\n\n\nposition\n\n\nAesthetic parameters / Notes\n\n\nExample plot\n\n\n\n\n\n\nline segements\n\n\n_segement\n\n\n_identity\n\n\nidentity\n\n\nx,y\n\n\n\n\n\n\n\n\n\n\n\n\nBOD.lm &lt;- lm(demand ~ Time, data = BOD)\nBOD$fitted &lt;- fitted(BOD.lm)\nBOD$resid &lt;- resid(BOD.lm)\nggplot(BOD)+\n    geom_segment(aes(x=Time,y=demand, xend=Time,yend=fitted),\n                 arrow = arrow(length=unit(0.5, \"cm\"), ends = \"first\")) \n\n\n\n\n\n\n\n\nsee text"
  },
  {
    "objectID": "05_grammar_of_graphics.html#types-of-coordinate-systems",
    "href": "05_grammar_of_graphics.html#types-of-coordinate-systems",
    "title": "The grammar of graphics (ggplot2)",
    "section": "3.1 Types of coordinate systems",
    "text": "3.1 Types of coordinate systems\n\nCartesiancoordinates Polarcoordinates Flipcoordinates Fixedcoordinates Transformedcoordinates \n\n\n\n\nShow attributes\n\n\n\n\n\n\n\n\n\nParameter\ngeom_segment\n\n\n\n\nxlim - limits for the x axis\nNULL\n\n\nylim - limits for the y axis\nNULL\n\n\nexpand - whether to add a small expansion to the axes to ensure geoms and axes do not overlapp\nTRUE\n\n\nexpand - whether or not to provide a warning when the default coordinate system is being replaced\nFALSE\n\n\nclip - whether or not to clip plotting to within the plotting margins (“on”) or to extend into the margins\n“on”\n\n\n\n\n\n\n\n\n\nFeature\n\n\ncoord\n\n\nNotes\n\n\nExample plot\n\n\n\n\n\n\nCartesian coordinates\n\n\n_cartesian\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nggplot(data = BOD, aes(x = Time, y = demand)) +\n    geom_line() +\n    coord_cartesian()\n\n\n\n\n\n\n\n\n\n\nShow attributes\n\n\n\n\n\n\n\n\n\nParameter\ngeom_segment\n\n\n\n\ntheta - map angle to either ‘x’ or ‘y’\n‘x’\n\n\nstart - offset (applied clockwise by default) from 12 o’clock in radians\n0\n\n\ndirection - which direction (‘clockwise’: 1 or ‘anticlockwise’: -1)\n1\n\n\nclip - whether or not to clip plotting to within the plotting margins (“on”) or to extend into the margins\n“on”\n\n\n\n\n\n\n\n\n\nFeature\n\n\ncoord\n\n\nNotes\n\n\nExample plot\n\n\n\n\n\n\nPolar coordinates\n\n\n_polar\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nggplot(data = BOD, aes(x = Time, y = demand)) +\n    geom_line() +\n    coord_polar()\n\n\n\n\n\n\n\n\n\n\nShow attributes\n\n\n\n\n\n\n\n\n\nParameter\ngeom_segment\n\n\n\n\nxlim - limits for the x axis\nNULL\n\n\nylim - limits for the y axis\nNULL\n\n\nexpand - whether to add a small expansion to the axes to ensure geoms and axes do not overlapp\nTRUE\n\n\nexpand - whether or not to provide a warning when the default coordinate system is being replaced\nFALSE\n\n\nclip - whether or not to clip plotting to within the plotting margins (“on”) or to extend into the margins\n“on”\n\n\n\n\n\n\n\n\n\nFeature\n\n\ncoord\n\n\nNotes\n\n\nExample plot\n\n\n\n\n\n\nFlip coordinates\n\n\n_flip\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nggplot(data = BOD, aes(x = Time, y = demand)) +\n    geom_line() +\n    coord_flip()\n\n\n\n\n\n\n\n\n\n\nShow attributes\n\n\n\n\n\n\n\n\n\nParameter\ngeom_segment\n\n\n\n\nratio - aspect ratio (y/x)\n1\n\n\nxlim - limits for the x axis\nNULL\n\n\nylim - limits for the y axis\nNULL\n\n\nexpand - whether to add a small expansion to the axes to ensure geoms and axes do not overlapp\nTRUE\n\n\nexpand - whether or not to provide a warning when the default coordinate system is being replaced\nFALSE\n\n\nclip - whether or not to clip plotting to within the plotting margins (“on”) or to extend into the margins\n“on”\n\n\n\n\n\n\n\n\n\nFeature\n\n\ncoord\n\n\nNotes\n\n\nExample plot\n\n\n\n\n\n\nFixed coordinates\n\n\n_fixed\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nggplot(data = BOD, aes(x = Time, y = demand)) +\n    geom_line() +\n    coord_fixed()\n\n\n\n\n\nFixed ratio of coordinates\n\n\n_fixed\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nggplot(data = BOD, aes(x = Time, y = demand)) +\n    geom_line() +\n    coord_fixed(ratio = 0.5)\n\n\n\n\n\n\n\n\n\n\nShow attributes\n\n\n\n\n\n\n\n\n\nParameter\ngeom_segment\n\n\n\n\nx - the transformation to apply to the x-axis\n“identity”\n\n\ny - the transformation to apply to the y-axis\n“identity”\n\n\nxlim - limits for the x axis\nNULL\n\n\nylim - limits for the y axis\nNULL\n\n\nexpand - whether or not to provide a warning when the default coordinate system is being replaced\nFALSE\n\n\nclip - whether or not to clip plotting to within the plotting margins (“on”) or to extend into the margins\n“on”\n\n\n\n\n\n\n\n\n\nFeature\n\n\ncoord\n\n\nNotes\n\n\nExample plot\n\n\n\n\n\n\nTransformed coordinates\n\n\n_trans\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nggplot(data = BOD, aes(x = Time, y = demand)) +\n    geom_line() +\n    coord_trans(x = \"log10\")\n\n\n\n\n\nTrans ratio of coordinates\n\n\n_trans\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nggplot(data = BOD, aes(x = Time, y = demand)) +\n    geom_line() +\n    coord_trans(x = scales::exp_trans(2))"
  },
  {
    "objectID": "05_grammar_of_graphics.html#altering-axes-scales-via-the-coordinate-system",
    "href": "05_grammar_of_graphics.html#altering-axes-scales-via-the-coordinate-system",
    "title": "The grammar of graphics (ggplot2)",
    "section": "3.2 Altering axes scales via the coordinate system",
    "text": "3.2 Altering axes scales via the coordinate system\n\n3.2.1 Zooming\nModifying scales with coords_ affects the zoom on the graph. That is, it defines the extent and nature of the axes coordinates. By contrast, altering limits via scale_ routines will alter the scope of data included in a manner analogous to operating on a subset of the data.\nTo illustrate this, lets produce a linear smoother for the BOD data. To help us appreciate the differences between coords_ and scale_ when altering one axis (x in this case), we will ensure that all each plot has the same range of the other axis (y) and that the aspect ratio for the axes are all the same.\n\ng &lt;- ggplot(data = BOD, aes(x = Time, y = demand)) +\n    geom_smooth(method = \"lm\") +\n    geom_point()\n\n\n\nShow default plot\n\n\ng + coord_fixed(ratio = 0.1, ylim = c(-5, 35))\n\n\n\n\n\n\n\n\n\nScale via coords scale\n\ng + coord_fixed(ratio = 0.1,\n                ylim = c(-5, 35),\n                xlim = c(2, 6))\n\n\n\n\n\n\n\n\nScale via scale scale\n\ng + coord_fixed(ratio = 0.1,\n                ylim = c(-5, 35)) +\n    scale_x_continuous(limits = c(2, 6))\n\n\n\n\n\n\n\n\nNotice that the left hand figure (that restricts the x-axis scale) simply zooms in on the plot thereby cutting some of the data off. By contrast, scale_ (right hand figure) removes data that are outside the range and thus also alters the output of the smoother (linear model).\n\n\n3.2.2 Geom re-scaling\nIn addition to altering the zoom of the axes, axes (coordinate system) scales can be transformed to other scales via the coord_trans function. Such transformations of the coordinate system take place after statistics have been calculated and geoms derived. Therefore the shape of geoms are altered.\nTo illustrate the difference between coord_trans and scale_, lets create a fabricated data set of 50 points in which y is an exponential function of x (with noise).\n\nset.seed(1)\nn&lt;-50\ndat &lt;- data.frame(x = exp((1:n+rnorm(n,sd=2))/10), y = 1:n+rnorm(n,sd=2))\n\ng &lt;- ggplot(data = dat, aes(x = x, y = y))\n\n\n\n\n\n\nLinear scales\n\n\ncoord_trans\n\n\nscales_\n\n\n\n\n\n\n\n\n\n\n\n\ng + geom_point()\n\n\n\n\n\n\n\n\n\ng + geom_point() +\n    coord_trans(x=\"log10\")\n\n\n\n\n\n\n\n\n\ng + geom_point() +\n    scale_x_continuous(trans=\"log10\")\n\n\n\n\n\n\n\n\n\n\n\ng + geom_point() +\n    geom_smooth(method=\"lm\")\n\n\n\n\n\n\n\n\n\ng + geom_point() +\n    geom_smooth(method=\"lm\") +\n    coord_trans(x=\"log10\") \n\n\n\n\n\n\n\n\n\ng + geom_point() +\n    geom_smooth(method=\"lm\") +\n    scale_x_continuous(trans=\"log10\") \n\n\n\n\n\n\nIn the above, the log10 transformer function was applied to either the coordinates or the axes scales. More information about this and other transformer functions is provided in the scales section."
  },
  {
    "objectID": "10_git.html",
    "href": "10_git.html",
    "title": "Git and version control",
    "section": "",
    "text": "Other useful tutorials or resources\n\nhttps://git-scm.com/book/en/v2\nhttps://www.atlassian.com/git/tutorials\nhttps://marklodato.github.io/visual-git-guide/index-en.html\nhttps://git-scm.com/docs/gittutorial\nhttps://marklodato.github.io/visual-git-guide/index-en.html\nhttps://try.github.io/levels/1/challenges/1\nhttps://onlywei.github.io/explain-git-with-d3/\nhttp://git-school.github.io/visualizing-git/\nhttps://github.com/sensorflo/git-draw\nThis tutorial will take a modular approach. The first section will provide an overview of the basic concepts of git. The second section will provide a quick overview of basic usage and the third and final section will cover intermediate level usage. In an attempt to ease understanding, the tutorial will blend together git commands and output, schematic diagrams and commentary in an attempt to ease understanding.\nThe following table surves as both a key and overview of the most common actions and git ‘verbs’."
  },
  {
    "objectID": "index.html#bash-shell-code",
    "href": "index.html#bash-shell-code",
    "title": "ReefCloud R/Statistics resources",
    "section": "2.2 Bash (shell) code",
    "text": "2.2 Bash (shell) code\nBash is a command-line shell that gives you access and control over your computer’s operating system. Whilst the majority of the tutorials in this series are focused on R, there are a couple of tutorials on other supporting topics (like version control) that might be interfaced via a shell (commands entered on a terminal). Furthermore, some software installation and/or configuration instructions might be in the form of shell commands.\nSuch commands are presented as:\n\npwd\n\n/home/runner/work/workshops/workshops/tut"
  },
  {
    "objectID": "10_git.html#initialize-local-repository",
    "href": "10_git.html#initialize-local-repository",
    "title": "Git and version control",
    "section": "5.1 Initialize local repository",
    "text": "5.1 Initialize local repository\n\n\nTerminalRStudioEmacs (magit)\n\n\nWe will start by creating a new directory (folder) which we will call Repo1 in which to place our repository. All usual directory naming rules apply since it is just a regular directory.\n\nmkdir ~/tmp/Repo1\n\nTo create (or initialize) a new local repository, issue the git init command in the root of the working directory you wish to contain the git repository. This can be either an empty directory or contain an existing directory/file structure. The git init command will add a folder called .git to the directory. This is a one time operation.\n\ncd ~/tmp/Repo1\ngit init \n\nhint: Using 'master' as the name for the initial branch. This default branch name\nhint: is subject to change. To configure the initial branch name to use in all\nhint: of your new repositories, which will suppress this warning, call:\nhint: \nhint:   git config --global init.defaultBranch &lt;name&gt;\nhint: \nhint: Names commonly chosen instead of 'master' are 'main', 'trunk' and\nhint: 'development'. The just-created branch can be renamed via this command:\nhint: \nhint:   git branch -m &lt;name&gt;\nInitialized empty Git repository in /home/runner/tmp/Repo1/.git/\n\n\nThe .git folder contains all the necessary metadata to manage the repository.\n\nls -al\n\ntotal 12\ndrwxr-xr-x 3 runner docker 4096 Jan 18 23:05 .\ndrwxr-xr-x 3 runner docker 4096 Jan 18 23:05 ..\ndrwxr-xr-x 7 runner docker 4096 Jan 18 23:05 .git\n\n\n\ntree -a --charset unicode\n\n.\n`-- .git\n    |-- HEAD\n    |-- branches\n    |-- config\n    |-- description\n    |-- hooks\n    |   |-- applypatch-msg.sample\n    |   |-- commit-msg.sample\n    |   |-- fsmonitor-watchman.sample\n    |   |-- post-update.sample\n    |   |-- pre-applypatch.sample\n    |   |-- pre-commit.sample\n    |   |-- pre-merge-commit.sample\n    |   |-- pre-push.sample\n    |   |-- pre-rebase.sample\n    |   |-- pre-receive.sample\n    |   |-- prepare-commit-msg.sample\n    |   |-- push-to-checkout.sample\n    |   |-- sendemail-validate.sample\n    |   `-- update.sample\n    |-- info\n    |   `-- exclude\n    |-- objects\n    |   |-- info\n    |   `-- pack\n    `-- refs\n        |-- heads\n        `-- tags\n\n10 directories, 18 files\n\n\n\nconfig\n\nthis file stores settings such as the location of a remote repository that this repository is linked to.\n\ndescription\n\nlists the name (and version) of a repository\n\nHEAD\n\nlists a reference to the current checked out commit.\n\nhooks\n\na directory containing scripts that are executed at various stages (e.g. pre-push.sample is an example of a script executed prior to pushing)\n\ninfo\n\ncontains a file exclude that lists exclusions (files not to be tracked). This is like .gitignore, except is not versioned.\n\nobjects\n\nthis directory contains SHA indexed files being tracked\n\nrefs\n\na master copy of all the repository refs\n\nlogs\n\ncontains a history of each branch\n\n\n\n\nThe repository that we are going to create in this demonstration could be considered to be a new standalone analysis. In Rstudio, this would be considered a project. So, we will initialise the git repository while we create a new Rstudio project. To do so:\n\nclick on the Project selector in the top right of the Rstudio window (as highlighted by the red ellipse in the image below.\n\nselect New Project from the dropdown menu\nselect New Directory form the Create Project panel\nselect New Project from the Project Type panel\nProvide a name for the new directory to be created and use the Browse button to locate a suitable position for this new directory. Ensure that the Create a git repository checkbox is checked\n\nClick the Create Project button\n\nIf successful, you should notice a couple of changes - these are highlighted in the following figure:\n\n\na new Git tab will appear in the top right panel\nthe contents of this newly created project/repository will appear in the Files tab of the bottom right panel\n\nIf the files and directories that begin with a . do not appear, click on the More file commands cog and make sure the Show Hidden Files option is ticked.\nThe newly created files/folders are:\n\n.git - this directory houses the repository information and should not generally be edited directly\n.gitignore - this file defines files/folders to be excluded from the repository. We will discuss this file more later\n.Rhistory - this file will accrue a history of the commands you have evaluated in R within this project\n.Rproj.user - this folder stores some project-specific temporary files\nRepo1.Rproj - contains the project specific settings\n\nNote that on the left side of the Rstudio window there are two panels - one called “Console”, the other called “Terminal”. The console window is for issuing R commands and the terminal window is for issuing system (bash, shell) commands. Throughout this tutorial, as an alternative to using the point and click Rstudio methods, you could instead issue the Terminal instructions into the “Terminal” panel. Indeed, there are some git commands that are not supported directly by Rstudio and can only be entered into the terminal\n\n\n\n\n\n\nNote, at this stage, no files are being tracked, that is, they are not part of the repository.\nTo assist in gaining a greater understanding of the workings of git, we will use a series of schematics diagrams representing the contents of four important sections of the repository. Typically, these figures will be contained within callout panels that expand/collapse upon clicking. However, for this first time, they will be standalone.\nIn the first figure below, the left hand panel represents the contents of the root directory (excluding the .git folder) - this is the workspace and is currently empty.\nThe three white panels represent three important parts of the inner structure of the .git folder. A newly initialized repository is relatively devoid of any specific metadata since there are no staged or committed files. In the root of the .git folder, there is a file called HEAD.\nThe figure is currently very sparse. However, as the repository grows, so the figure will become more complex.\n\n\n\n\n\nThe second figure provides the same information, yet via a network diagram. Again, this will not be overly meaningful until the repository contains some content."
  },
  {
    "objectID": "10_git.html#initializing-other-types-of-repositories",
    "href": "10_git.html#initializing-other-types-of-repositories",
    "title": "Git and version control",
    "section": "5.2 Initializing other types of repositories",
    "text": "5.2 Initializing other types of repositories\nThe above demonstrated how to initialise a new local repository from scratch. However, there are times when we instead want to:\n\ncreate a git repository from an existing directory or project\ncollaborate with someone on an existing repository\ncreate a remote repository\n\nThese situations are briefly demonstrated in the following sections.\n\n5.2.1 Initializing a shared (remote) repository\n\nThe main repository for sharing should not contain the working directory as such - only the .git tree and the .gitignore file. Typically the point of a remote repository is to act as a perminantly available repository from which multiple uses can exchange files. Consequently, those accessing this repository should only be able to interact with the .git metadata - they do not directly modify any files.\nSince a remote repository is devode of the working files and directories, it is referred to as bare.\n\nTerminalRstudio\n\n\nTo create a bare remote repository, issue the git init --bare command after logging in to the remote location.\n\ngit init --bare\n\n\n\nUse the instructions for the Terminal\n\n\n\n\n\n5.2.2 Cloning an existing repository\n\nTo get your own local copy of an existing repository, issue the git clone &lt;repo url&gt; command in the root of the working directory you wish to contain the git repository. The repo url points to the location of the existing repository to be cloned. This is also a one time operation and should be issued in an otherwise empty directory.\nThe repo url can be located on any accessible filesytem (local or remote). The cloning process also stores a link back to the original location of the repository (called origin). This provides a convenient way for the system to keep track of where the local repository should exchange files.\nMany git repositories are hosted on sites such as github, gitlab or bitbucket. Within an online git repository, these sites provide url links for cloning.\n\nTerminalRstudio\n\n\n\ngit clone \"url.git\"\n\nwhere \"url.git\" is the url of the hosted repository.\n\n\n\nclick on the Project selector in the top right of the Rstudio window (as highlighted by the red ellipse in the image below.\nselect New Project from the dropdown menu\nselect Version Control form the Create Project panel\nselect Git from the Create Project from Version Control panel\npaste in the address of the repository that you want to clone, optionally a name for this repository (if you do not like the original name) and use the Browse button to locate a suitable position for this new directory.\nClick the Create Project button\n\n\n\n\n\n\n5.2.3 Initializing a repository in an existing directory\n\nTerminalRstudio\n\n\nThis is the same as for a new directory.\n\ngit init\n\n\n\n\nclick on the Project selector in the top right of the Rstudio window (as highlighted by the red ellipse in the image below.\nselect New Project from the dropdown menu\nselect Existing Directory form the Create Project panel\nuse the Browse button to locate the existing directory\nClick the Create Project button"
  },
  {
    "objectID": "10_git.html#staging-files",
    "href": "10_git.html#staging-files",
    "title": "Git and version control",
    "section": "6.1 Staging files",
    "text": "6.1 Staging files\nWhen a file is first added to the staging area, a full copy of that file is added to the staging area (not just the file diffs as in other versioning systems).\n\nTerminalRstudio\n\n\nTo demonstrate lets create a file (a simple text file containing the string saying ‘File 1’) and add it to the staging area.\n\necho 'File 1' &gt; file1\n\nNow lets add this file to the staging area\n\ngit add file1\n\nTo see the status of the repository (that is, what files are being tracked), we issue the git status command\n\ngit status\n\nOn branch master\n\nNo commits yet\n\nChanges to be committed:\n  (use \"git rm --cached &lt;file&gt;...\" to unstage)\n    new file:   file1\n\n\nThis indicates that there is a single file (file1) in the staging area\n\n\nTo demonstrate lets create a file (a simple text file containing the string saying ‘File 1’) and add it to the staging area.\n\nClick the green “New File” button followed by the “Text File” option (or click the equivalent option from the “File” menu) \nType File 1 in the panel with the flashing cursor. This panel represents the contents of the yet to be named file that we are creating.\n\nClick the “Save” or “Save all” buttons (or select the equivalent items from the “File” menu) and name the file “file1”\nSwitch to the Git tab and you should notice a number of items (including the file we just created) in the panel. These are files that git is aware of, but not yet tracking. This panel acts as a status window. The yellow “?” symbol indicates that git considers these files “untracked”\n\nTo stage a file, click on the corresponding checkbox - the status symbol should change to a green “A” (for added)\n\n\n\n\n\nOur simple overview schematic represents the staging of file 1.\n\n\n\n\n\nA schematic of the internal working of git shows in .git/objects a blob has been created. This is a compressed version of file1. Its filename is a 40 digit SHA-1 checksum has representing the contents of the file1. To re-iterate, the blob name is a SHA-1 hash of the file contents (actually, the first two digits form a folder and the remaining 38 form the filename).\nWe can look at the contents of this blob using the git cat-file command. This command outputs the contents of a compressed object (blob, tree, commit) from either the objects name (or unique fraction thereof) or its tag (we will discuss tags later).\n\ngit cat-file blob 50fcd\n\nFile 1\n\n\nThe add (staging) process also created a index file. This file simply points to the blob that is part of the snapshot. The git internals schematic illustrates the internal changes in response to staging a file.\n\n\n\n\n\n\n\n\n\n\nAnother visual representation of the git"
  }
]